<HTML><HEAD><script async src="https://www.googletagmanager.com/gtag/js?id=UA-83731338-2"></script><script>  window.dataLayer = window.dataLayer || [];  function gtag(){dataLayer.push(arguments);}  gtag('js', new Date());  gtag('config', 'UA-83731338-2');</script><title>Random Reading from Stripe Sets</TITLE><META HTTP-EQUIV="CONTENT-TYPE" CONTENT="text/html; charset= iso-8859-1"><style>@import url(msdn_ie4.css);</style>
<link disabled rel="stylesheet" href="msdn_ie3.css"></HEAD>
<BODY BGCOLOR="#FFFFFF"><FONT FACE="Verdana, Arial, Helvetica" SIZE="2"><FORM NAME="x"><OBJECT CLASSID="clsid:9c2ac687-ceef-11cf-96d9-00a0c903b016" NAME="iv"></OBJECT></FORM>
<H3>Random Reading from Stripe Sets</H3><P CLASS="t">Reading and writing randomly throughout a disk is about the most laborious process required of disks. The constant seek activity consumes the disk and the processor. These issues were discussed in detail in the earlier section, "Random vs. Sequential Reading." This section describes how to test the effect of random reading on your volume set.</P>
<P></P>
<P CLASS="t"><B>Note</B></P>
<P>As in the previous section, the relative values for reads and writes are nearly indistinguishable, so data for writing is not shown here. You can, however, use the same methods to explore random writing performance on your disks.</P>
<P></P>
<P CLASS="t">As before, these reading tests were run on a stripe set of four physical disks. Disks 0, 1, and 2 are on a single disk adapter, and Disk 3 is on a separate adapter. Also, Performance Monitor is logging to Disk 3. In each test, the test tool is doing random, unbuffered reads of 64K records from a 60 MB file. The test begins reading only from Disk 0, and adds a disk with each iteration of the test to end with four stripes.</P>
<P CLASS="t">During the test, Performance Monitor was logging to Stripe_rand.log. This log is included on the Windows NT Resource Kit 4.0 CD, so you can follow along and chart additional counters.</P>
<P CLASS="t">Stripes sets are know for their seeking efficiency. They are created by associating free space in multiple physical disks. Code and data written to the stripe set is distributed evenly across all disks. Because each disk in the set has its own head stack assembly, the heads on each disk in the set can seek simultaneously. Some performance loss is expected when the disk is reading randomly, but it should not be as pronounced as on single disks or on unassociated disk configurations.</P>
<P CLASS="t">This following graph shows an overview of random reading performance for the disk set.</P>
<P><img src="xwr_n31.gif"></P>
<P CLASS="t">In this graph, the gray line is Disk Reads/Sec: Total, the thick, black line is Avg. Disk Bytes/Read: Total, the white line is Disk Read Bytes/Sec: Total and the thin, black line is Avg. Disk sec/Read: Total. The vertical maximum as been increased to 250 to incorporate all values.</P>
<P CLASS="t">The trend is much like that for sequential reads. As more stripes are added, the transfer rate (Disk Reads/sec) and throughput (Disk Read Bytes/sec) increase, and the queue (Avg. Disk sec/Read) diminishes.</P>
<P CLASS="t">The following figure compares the performance graphs of random and sequential reading by stripe sets. The graph on the left is sequential reading; the graph on the right is random reading. Both graphs in the figure show values for the _Total instance, representing all physical disks in the stripe set.</P>
<P><img src="xwr_n32.gif"></P>
<P CLASS="t">In both graphs, the gray line is Disk Reads/sec: Total, the thick, black line is Avg. Disk Bytes/Read: Total, the white line is Disk Read Bytes/Sec: Total and the thin, black line is Avg. Disk sec/Read: Total. The vertical maximum on both graphs has been set to 250 to incorporate all values.</P>
<P CLASS="t">This figure shows that although the patterns are similar, the values are slightly different. The transfer rate (Disk Reads/sec: Total) increases to more than 215 reads/sec in the random test. Throughput (Disk Read Bytes/sec: Total — the white line) runs lower on the random graph through almost every stage of the test.</P>
<P CLASS="t">The following tables compare the average values for sequential and random reading on the stripe set. To find these values, open a copy of Performance Monitor for each sample interval on the graph. Then use the time window to limit each one to a single sample interval, and display the disk reading counters in a report. These values were taken from four of such reports.</P>

<TABLE COLS="4" BORDER="0" CELLPADDING="7"><COLGROUP><COL WIDTH="87pt" VALIGN="TOP"><COL WIDTH="87pt" VALIGN="TOP"><COL WIDTH="87pt" VALIGN="TOP"><COL WIDTH="87pt" VALIGN="TOP"></COLGROUP><TBODY><TR><TD VALIGN="TOP"><P CLASS="th"><B><BR># Stripes</B></P></TD><TD VALIGN="TOP"><P CLASS="th"><B>Total Disk Read Bytes/sec (in  MB) Sequential</B></P></TD><TD VALIGN="TOP"><P CLASS="th"><B>Total Disk Read Bytes/sec (in  MB) Random</B></P></TD><TD VALIGN="TOP"><P CLASS="th"><B><BR>% Change</B></P></TD></TR><TR><TD COLSPAN="4" VALIGN="TOP"><P></P></TD></TR><TR><TD VALIGN="TOP"><P>1</P></TD><TD VALIGN="TOP"><P>4.52</P></TD><TD VALIGN="TOP"><P>2.95</P></TD><TD VALIGN="TOP"><P>53.2%</P></TD></TR><TR><TD VALIGN="TOP"><P>2</P></TD><TD VALIGN="TOP"><P>4.86</P></TD><TD VALIGN="TOP"><P>4.23</P></TD><TD VALIGN="TOP"><P>15%</P></TD></TR><TR><TD VALIGN="TOP"><P>3</P></TD><TD VALIGN="TOP"><P>4.82</P></TD><TD VALIGN="TOP"><P>5.31</P></TD><TD VALIGN="TOP"><P>-9%</P></TD></TR><TR><TD VALIGN="TOP"><P>4</P></TD><TD VALIGN="TOP"><P>11.75</P></TD><TD VALIGN="TOP"><P>9.91</P></TD><TD VALIGN="TOP"><P>18.5%</P></TD></TR></TBODY></TABLE>
<P CLASS="spacing"><BR></P><P></P>
<P CLASS="t"></P>

<TABLE COLS="4" BORDER="0" CELLPADDING="7"><COLGROUP><COL WIDTH="87pt" VALIGN="TOP"><COL WIDTH="87pt" VALIGN="TOP"><COL WIDTH="87pt" VALIGN="TOP"><COL WIDTH="87pt" VALIGN="TOP"></COLGROUP><TBODY><TR><TD VALIGN="TOP"><P CLASS="th"><B><BR># Stripes</B></P></TD><TD VALIGN="TOP"><P CLASS="th"><B>Total Disk Reads/sec (in  MB) Sequential</B></P></TD><TD VALIGN="TOP"><P CLASS="th"><B>Total Disk Reads/sec (in  MB) Random</B></P></TD><TD VALIGN="TOP"><P CLASS="th"><B><BR>% Change</B></P></TD></TR><TR><TD COLSPAN="4" VALIGN="TOP"><P></P></TD></TR><TR><TD VALIGN="TOP"><P>1</P></TD><TD VALIGN="TOP"><P>68.948</P></TD><TD VALIGN="TOP"><P>45.024</P></TD><TD VALIGN="TOP"><P>53%</P></TD></TR><TR><TD VALIGN="TOP"><P>2</P></TD><TD VALIGN="TOP"><P>148.223</P></TD><TD VALIGN="TOP"><P>128.669</P></TD><TD VALIGN="TOP"><P>15%</P></TD></TR><TR><TD VALIGN="TOP"><P>3</P></TD><TD VALIGN="TOP"><P>147.069</P></TD><TD VALIGN="TOP"><P>161.310</P></TD><TD VALIGN="TOP"><P>-8.8%</P></TD></TR><TR><TD VALIGN="TOP"><P>4</P></TD><TD VALIGN="TOP"><P>179.343</P></TD><TD VALIGN="TOP"><P>215.760</P></TD><TD VALIGN="TOP"><P>-17%</P></TD></TR></TBODY></TABLE>
<P CLASS="spacing"><BR></P><P></P>
<P CLASS="t">Note that the performance lost by reading randomly diminishes significantly as disks are added. On a single disk, throughput on random is 53% lower than on sequential reading. The difference drops to 15% with two disks and, on four disks, throughput is 17% greater on random reading than on sequential reading.</P>
<P CLASS="t">The affect on individual disks in the set follows the patterns evidenced by the sequential reads. The following graph shows the effect of adding disks to the set on the transfer rate of each disk.</P>
<P><img src="xwr_n32.gif"></P>
<P CLASS="t">Physical Disk: Disk Reads/sec is charted for the _Total instance and for Disks 0 through 3. The gray line is the _Total, the black line is Disk 0, the white line is Disk 1. The lines representing Disks 2 and 3 run along the bottom of the graph until they are added to the test. Then they are superimposed upon the line for Disk&nbsp;1.</P>
<P CLASS="t">The pattern continues. The transfer rate of the disk set increases with each disk added, but the work is distributed evenly to all disks in the set. The proportion of transfers for each disk declines accordingly.</P>
<P CLASS="t">The average values are shown in the following table.</P>

<TABLE COLS="7" BORDER="0" CELLPADDING="7"><COLGROUP><COL WIDTH="83pt" VALIGN="TOP"><COL WIDTH="57pt" VALIGN="TOP"><COL WIDTH="49pt" VALIGN="TOP"><COL WIDTH="49pt" VALIGN="TOP"><COL WIDTH="49pt" VALIGN="TOP"><COL WIDTH="56pt" VALIGN="TOP"><COL WIDTH="0pt" VALIGN="TOP"></COLGROUP><TBODY><TR><TD VALIGN="TOP"><P CLASS="th"><B>#Stripes</B></P></TD><TD COLSPAN="5" VALIGN="TOP"><P CLASS="th"><B>Disk Reads/sec</B></P></TD></TR><TR><TD COLSPAN="6" VALIGN="TOP"><P></P></TD></TR><TR><TD VALIGN="TOP"><P></P></TD><TD VALIGN="TOP"><P>Disk 0</P></TD><TD VALIGN="TOP"><P>Disk 1</P></TD><TD VALIGN="TOP"><P>Disk 2</P></TD><TD VALIGN="TOP"><P>Disk 3</P></TD><TD VALIGN="TOP"><P>Total</P></TD></TR><TR><TD COLSPAN="7" VALIGN="TOP"><P></P></TD></TR><TR><TD VALIGN="TOP"><P>1</P></TD><TD VALIGN="TOP"><P>45.024</P></TD><TD VALIGN="TOP"><P>0.000</P></TD><TD VALIGN="TOP"><P>0.000</P></TD><TD VALIGN="TOP"><P>0.000</P></TD><TD VALIGN="TOP"><P>45.024</P></TD></TR><TR><TD VALIGN="TOP"><P>2</P></TD><TD VALIGN="TOP"><P>64.379</P></TD><TD VALIGN="TOP"><P>64.290</P></TD><TD VALIGN="TOP"><P>0.000</P></TD><TD VALIGN="TOP"><P>0.010</P></TD><TD VALIGN="TOP"><P>128.669</P></TD></TR><TR><TD VALIGN="TOP"><P>3</P></TD><TD VALIGN="TOP"><P>54.449</P></TD><TD VALIGN="TOP"><P>53.289</P></TD><TD VALIGN="TOP"><P>53.572</P></TD><TD VALIGN="TOP"><P>0.000</P></TD><TD VALIGN="TOP"><P>161.310</P></TD></TR><TR><TD VALIGN="TOP"><P>4</P></TD><TD VALIGN="TOP"><P>86.646</P></TD><TD VALIGN="TOP"><P>43.504</P></TD><TD VALIGN="TOP"><P>42.905</P></TD><TD VALIGN="TOP"><P>42.705</P></TD><TD VALIGN="TOP"><P>215.760</P></TD></TR></TBODY></TABLE>
<P CLASS="spacing"><BR></P><P></P>
<P CLASS="t">As observed in the sequential reads, the increased workload is distributed equally among all disks. There appears to be slightly more variation in the values, but it is too small to measure accurately without a much larger sample pool. Again, the transfer rate on Disk 0 increases significantly when the fourth disk is added. It is probably doing its share of the reading and also updating the FAT table.</P>
<P CLASS="t">The following graph shows the throughput values for random reading on a stripe set. The chart shows Disk Read Bytes/sec for all disks in the stripe set.</P>
<P><img src="xwr_n33.gif"></P>
<P CLASS="t">In this graph, the gray line is the _Total instance for all disks, which increases as more disks are added to the stripe set. The heavy, black line is Disk 0, and the white line is Disk 1. The lines representing Disks 2 and 3 run along the bottom of the graph until they are added to the test. Then, they are superimposed upon the line for Disk 1.</P>
<P CLASS="t">This table shows the average values.</P>

<TABLE COLS="7" BORDER="0" CELLPADDING="7"><COLGROUP><COL WIDTH="60pt" VALIGN="TOP"><COL WIDTH="65pt" VALIGN="TOP"><COL WIDTH="60pt" VALIGN="TOP"><COL WIDTH="56pt" VALIGN="TOP"><COL WIDTH="63pt" VALIGN="TOP"><COL WIDTH="42pt" VALIGN="TOP"><COL WIDTH="0pt" VALIGN="TOP"></COLGROUP><TBODY><TR><TD VALIGN="TOP"><P CLASS="th"><B>#Stripes</B></P></TD><TD COLSPAN="5" VALIGN="TOP"><P CLASS="th"><B>Disk Read Bytes/sec (in  MB) </B></P></TD></TR><TR><TD VALIGN="TOP"><P></P></TD><TD COLSPAN="5" VALIGN="TOP"><P></P></TD></TR><TR><TD VALIGN="TOP"><P></P></TD><TD VALIGN="TOP"><P>Disk 0</P></TD><TD VALIGN="TOP"><P>Disk 1</P></TD><TD VALIGN="TOP"><P>Disk 2</P></TD><TD VALIGN="TOP"><P>Disk 3</P></TD><TD VALIGN="TOP"><P>Total</P></TD></TR><TR><TD COLSPAN="7" VALIGN="TOP"><P></P></TD></TR><TR><TD VALIGN="TOP"><P>1</P></TD><TD VALIGN="TOP"><P>2.95</P></TD><TD VALIGN="TOP"><P>0.00</P></TD><TD VALIGN="TOP"><P>0.00</P></TD><TD VALIGN="TOP"><P>0.00</P></TD><TD VALIGN="TOP"><P>2.95</P></TD></TR><TR><TD VALIGN="TOP"><P>2</P></TD><TD VALIGN="TOP"><P>2.09</P></TD><TD VALIGN="TOP"><P>2.15</P></TD><TD VALIGN="TOP"><P>0.00</P></TD><TD VALIGN="TOP"><P>0.00</P></TD><TD VALIGN="TOP"><P>4.23</P></TD></TR><TR><TD VALIGN="TOP"><P>3</P></TD><TD VALIGN="TOP"><P>1.79</P></TD><TD VALIGN="TOP"><P>1.76</P></TD><TD VALIGN="TOP"><P>1.76</P></TD><TD VALIGN="TOP"><P>0.00</P></TD><TD VALIGN="TOP"><P>5.31</P></TD></TR><TR><TD VALIGN="TOP"><P>4</P></TD><TD VALIGN="TOP"><P>5.68</P></TD><TD VALIGN="TOP"><P>1.45</P></TD><TD VALIGN="TOP"><P>1.45</P></TD><TD VALIGN="TOP"><P>1.4</P></TD><TD VALIGN="TOP"><P>9.91</P></TD></TR></TBODY></TABLE>
<P CLASS="spacing"><BR></P><P></P>
<P CLASS="t">As disks are added, total throughput for the disk set increases 3.36 times, from 2.95 MB/sec to 9.91 MB/sec, compared to a 2.6 times increase for sequential reading. FTDISK is clearly taking advantage of the stripe set.</P>
<P CLASS="t">It is clear from this data that stripe sets are a very efficient means of disk transfer, and that the difference is especially apparent on very seek-intensive tasks such as random reading.</P>
<P CLASS="t">Although it is not shown in these graphs, processor use remained at 100% for the duration of the sequential and random reading and writing tests on stripe sets. The improved productivity has a cost in processor time.</P></BODY></HTML>
