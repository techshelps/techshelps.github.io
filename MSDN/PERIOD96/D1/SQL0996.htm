<!DOCTYPE HTML PUBLIC "-//IETF//DTD HTML//EN">
<html>

<head>
<meta http-equiv="Content-Type"
content="text/html; charset=iso-8859-1">
<meta name="GENERATOR" content="Microsoft FrontPage 2.0">
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-83731338-2"></script><script>  window.dataLayer = window.dataLayer || [];  function gtag(){dataLayer.push(arguments);}  gtag('js', new Date());  gtag('config', 'UA-83731338-2');</script><title>VLDB Secrets (September)</title>

<meta name=href content="msdn_ie4.css">                
<style>@import url(msdn_ie4.css);</style>
<link disabled rel="stylesheet" href="msdn_ie3.css"></HEAD>

<BODY bgcolor="#FFFFFF">
<font face="verdana,arial,helvetica" size="2">

<H1>VLDB Secrets</h1>

<P>Kelly Gillespie</p>

<P><i>Can Microsoft SQL Server really handle very
large databases? SQL Server developer Kelly Gillespie interviewed
a number of sites with VLDB to find out. </i></p>

<P>I don't think anyone using vintage SQL Server 4.2
has databases in the 100-plus gigabyte range, but with SQL Server
6.0, we're seeing up to 200G and more on SQL Server. Not only has
the size of databases increased dramatically but so has the
number of simultaneous users. One Microsoft site I'll call Raptor
has SQL Server 6.0 with more than 3,700 users accessing a 10G
database. Now 10G certainly doesn't qualify as a very large
database (VLDB), but this gives you an idea of the demands you
can put on today's SQL Server. </p>

<P>How big can a SQL Server database become? Actually,
there's no fixed upper limit&#151;you're constrained by the disk
subsystem of the server. Until recently, the popular Compaq
Proliant family of servers were physically limited to about 300G
of disk space per server, but thanks to Compaq's new support for
9G 3_-inch drives, the limit on those systems is closer to 700G. </p>

<P>In this article, I'll discuss several topics that
will help you cope with VLDBs including selection of a server
platform and disk subsystem, how choice of indexes and table
schema affects performance, and a variety of techniques for
optimizing backups. </p>

<H2>Hardware platform</h2>

<P>It shouldn't come as a surprise that most VLDB sites
are running with SMP servers such as Compaq's Proliant with dual
or quad Pentium processors, but Digital's Alpha 2100 family has
recently become a leading contender in the platform fight for SQL
Server VLDBs. You can also expect Digital boxes to be among the
first to offer NT clustering support. </p>

<P>Aside from the CPU, the most important hardware
component is your disk subsystem. If you had to move a mountain
of dirt from point A to point B, would you rather use a teaspoon
or an enormous bulldozer? The same logic applies to your disk
subsystem &#151;you need to choose one that maximizes disk
spindles and disk controllers and gives you the widest stripe
set. </p>

<P>Some sites use only the cost-effective RAID 5 for
the data files&#151;RAID 5 is good for reads&#151;and opt for
faster, but more expensive, RAID 0 for the transaction log and
the disk dump device. However, one large SQL Server site with
several hundred gigabytes has resorted to using RAID 5 for both
the database and the transaction log in order to save on cost.</p>

<P>Carefully consider what RAID disk controller you
want to use. Some RAID controllers seem to lack stable drivers
for Windows NT. Once you've done obvious things like check
Microsoft's hardware compatibility list and investigated the
status of the latest drivers, I recommend posting a message on
the MSSQL forum on CompuServe or the Microsoft SQL Server
newsgroup on the Internet (comp.databases.ms-sqlserver) asking
other users about the quality of the RAID driver before
committing to any RAID vendor. Keep in mind that some otherwise
reputable vendors may use OEM RAID controllers that fall into
this category. However, I snooped around and learned that
Microsoft uses more than 3,400 Compaq Smart SCSI RAID
controllers, so Compaq should be a safe bet. The Raptor site also
uses Compaq Smart SCSI controllers on its Compaq Proliant quad
100 MHz Pentium server that's equipped with 1G of memory and 50G
of disk storage. </p>

<P>Once you get into a large RAID disk subsystem, it's
important to watch for symptoms that your system is bus bound.
Some of the newer Wide SCSI (20M/sec) and Wide Ultra SCSI
(40M/sec) RAID subsystems can gobble up your entire bus
bandwidth, which explains the importance of multiple buses
systems. </p>

<H2>Disk space factors</h2>

<P>A popular rule of thumb for disk storage is five
times the declared database size. For example, if you anticipate
a 20G database, you'd probably want to have about 100G of actual
disk space. Why so much? Some of it is used for the venerable bcp
(bulk copy program) to get the data into and out of the server,
some is used for SQL Server's own workspace including tempdb, and
some is typically used for one or more disk dump devices.</p>

<H2>Performance tuning</h2>

<P>A typical VLDB developer might wonder, &quot;I have
some money in my budget, so I can either upgrade the CPU or the
memory on my SQL Server or upgrade the disk subsystem. Which
should I do?&quot; The answer varies from site to site. You can
best determine what part of your server to improve by doing the
following:</p>

<ol>
    <li>From the command line, type DISKPERF -Y. This enables the
        collection of disk statistics. By default this is turned
        off, since it tends to degrade performance.</li>
    <li>Shut the server down and reboot.</li>
    <li>Let your SQL Server run with a normal load. Start PERFMON
        and let it run for 15 minutes. Look at System:%Total
        Processor Time. This is one simple number to look at and
        gives you the aggregate total usage for all CPUs in the
        system.</li>
    <li>Next look at Logical Disks and examine each one for your
        system. Compare the % Disk Time for each disk. Between
        the System: %Total Processor Time factor and the % Disk
        Time, you can determine of your server is CPU bound or
        I/O bound and address the weakest point.</li>
    <li>Disable statistics logging by typing DISKPERF -N</li>
</ol>

<P>It's easy to overlook the value of PERFMON. As Brain
Maniex of Maniex Consulting (415-508-8560) puts it, &quot;We use
PERFMON extensively to see where the bottlenecks are in our two
VLDB systems.&quot;</p>

<H2>Indexing and table schema</h2>

<P>Non-indexed operations can kill performance on VLDB
systems. If your query has to perform a full scan on a large
table, what would only take seconds on a small table can easily
become 20 hours or more. That's why it's crucially important to
scrutinize your access plan to minimize the number of I/Os. You
should also avoid overly broad queries such as a wildcard query
on lastnames using something like %lastname.</p>

<P>Of course, clustered index <i>creation</i> is no
piece of cake when you're using a VLDB. Don't forget&#151;we're
talking both time and space. A 10G table requires at least an
extra 12G of disk space llocated to the database just to allow a
clustered index to be created. And depending on what FILL FACTOR
you specify when creating the clustered index, it might be even
more. Your disk space requirements can become unwieldy when you
have multiple VLDB systems with each database requiring enormous
extra space to enable clustered index creation. Several sites
mentioned this as a drawback and have asked Microsoft to provide
a generic temp area that can be provided on the fly for clustered
index creation. This would enable multiple VLDBs to share free
space as needed.</p>

<H2>Loading data</h2>

<P>Never commit to a long bcp until you've run some
test data, and remember to drop your indexes on the target table.
SQL 6.0 supports parallelized bcp, so if you have an SMP system,
you might want to consider parallelizing your bcp into several
tables instead of one large table. For example, if you had an
enormous People table that takes 21 hours to load, you could
break the table into four tables with the last names of A to G in
the first table, and so on, and then use stored procedures to
access the appropriate table. By breaking the table up into four
tables, you would be able to run parallel sessions of bcp to load
data into each of the four tables. Also, running bcp on the
server is almost always faster than over the LAN.</p>

<P>One large SQL Server VLDB site that has about 20 SQL
Servers is moving towards splitting large databases across SQL
Servers dividing the data by geographic regions or by client last
name. However, a drawback to this approach is the lack of
anything short of a brute force method of accomplishing a cross
server join. The current method of having to read potentially
gigabytes of data into the client PC doing the join is
unacceptable. While SQL Server 6.5 will reportedly address the
cross server <i>update,</i> the cross server <i>join</i> remains
a missing piece. Microsoft is exploring how to address this
problem.</p>

<H2>Backing up your data</h2>

<P>Many sites prefer to use a disk dump instead of
backing up directly. They feel disk backup is &quot;safer&quot;
and that tape backup is &quot;finicky.&quot; One site I
interviewed backs up their 20 VLDB SQL Servers to tape every
night and encounters an average of one tape problem each night.
To get around this problem, some sites rely exclusively on disk
dumps or do both. If you think you might go the disk dump route,
be sure to plan for more disk space. In the case of a 10G
database, you'll need an additional 10G of disk space for each
copy of the disk dump.</p>

<P><b>FAT vs. NTFS</b></p>

<P>One VLDB site warned about prototyping on a SQL
Server system formatted with FAT and then switching to a
production server formatted with NTFS. They experienced somewhere
between a 10 and 20 percent drop in disk performance.&#151;Kelly
Gillespie</p>

<P><b>Sledge's Seven</b></p>

<P>Orryn Sledge, coauthor of the <i>Microsoft SQL
Server DBA Survival </i>Guide, offers these tips for VLDB:</p>

<ol>
    <li>If your data is presorted, use the WITH SORTED OPTION
        when creating CLUSTERED indexes since this can
        significantly reduce the time required to create an
        index.</li>
    <li>When performing updates, design the tables so that a
        direct update can occur instead of using update deferred.</li>
    <li>If you have to re-create a damaged database and are
        restoring from a dump, use the CREATE DATABASE ...FOR
        LOAD option. This will significantly reduce the time
        required to re-create a VLDB.</li>
    <li>Tune the lock escalation threshold. The default value of
        200 pages is usually way too low for big databases.
        Remember, too, that you can set the value as a percentage
        of the database size.</li>
    <li>If the database is strictly read only (that is, reporting
        database), set the read only option to true on the
        database. When read only = true, page locks won't be
        issued when processing the SELECT statement. In theory
        this should improve performance since page locks aren't
        incurred.</li>
    <li>Understand the optimizer and learn how to read a SHOWPLAN
        to make sure the proper indexes are being accessed.
        Consider breaking a complex query into smaller/less
        complex queries and then merging the result set.</li>
    <li>Run DBCC with the NOINDEX option to improve DBCC
        performance.&#151;Orryn Sledge</li>
</ol>

<P><i>Kelly Gillespie is an independent consultant
who works with SQL Server, Windows NT, CTI, and Lotus Notes. He's
always looking for a good challenge. 619-489-5295, CompuServe
76200,406.</i></p>

<P>&nbsp;</p>

<P align="center"><a
href="http://www.pinpub.com/sqlpro/"><img src="Pinnacle.gif"
border="0" width="216" height="72"></a></p>

<P align="center"><strong>To find out more about SQL
Server Professional and Pinnacle Publishing, <br>
visit their website at</strong> <a
href="http://www.pinpub.com/sqlpro/"><strong>http://www.pinpub.com/sqlpro/</strong></a><strong>
</strong></p>

<P align="center"><font size="1">Note: This is not a
Microsoft Corporation website. <br>
Microsoft is not responsible for its content.</font></p>

<P>This article is reproduced from the September 1996
issue of SQL Server Professional. Copyright 1996, by Pinnacle
Publishing, Inc., unless otherwise noted. All rights are
reserved. SQL Server Professional is an independently produced
publication of Pinnacle Publishing, Inc. No part of this article
may be used or reproduced in any fashion (except in brief
quotations used in critical articles and reviews) without prior
consent of Pinnacle Publishing, Inc. To contact Pinnacle
Publishing, Inc., please call (800)788-1900 or (206)251-1900.</p>
</font></body>
</html>
