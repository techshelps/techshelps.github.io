<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 3.2 Final//EN">
<HTML dir=ltr>
<HEAD>
<META HTTP-EQUIV="Content-Type" Content="text/html; charset=Windows-1252">
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-83731338-2"></script><script>  window.dataLayer = window.dataLayer || [];  function gtag(){dataLayer.push(arguments);}  gtag('js', new Date());  gtag('config', 'UA-83731338-2');</script><title>VIDCAP.CPP</title>
<link disabled rel=stylesheet href=../../../../../backsdk3.css>
<style type="text/css">
@import url(../../../../../backsdk4.css);
</style>
</HEAD>
<BODY BGCOLOR = #FFFFFF TEXT = #000000>
<h2><a name="_code_context2960"></a>VIDCAP.CPP</h2>
<pre><code>//==========================================================================; <br>// <br>//  THIS CODE AND INFORMATION IS PROVIDED "AS IS" WITHOUT WARRANTY OF ANY <br>//  KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE <br>//  IMPLIED WARRANTIES OF MERCHANTABILITY AND/OR FITNESS FOR A PARTICULAR <br>//  PURPOSE. <br>// <br>//  Copyright (c) 1992 - 1997  Microsoft Corporation.  All Rights Reserved. <br>// <br>//--------------------------------------------------------------------------; <br> <br>// <br>//  Video capture stream source filter <br>// <br> <br>// Uses the AVICap window to capture video data to pass downstream. <br>// By using the video callback it avoids AVICap sending data to a file <br>// - AVICap is merely capturing buffers for us to pass on. <br>// <br> <br>// Caveats <br>// <br>// ** Should reject going active when the user has format dialogs up. <br> <br>#include &lt;streams.h&gt; <br>#include &lt;initguid.h&gt; <br>#include &lt;olectl.h&gt; <br>#include &lt;mmsystem.h&gt; <br>#include &lt;vfw.h&gt; <br>#include &lt;string.h&gt; <br>#include &lt;stddef.h&gt;     // for offsetof macro <br> <br>#include "vidcap.h" <br> <br>// setup data <br> <br>const AMOVIESETUP_MEDIATYPE sudOpPinTypes = <br>{ &amp;MEDIATYPE_Video       // clsMajorType <br>, &amp;MEDIASUBTYPE_NULL };  // clsMinorType <br> <br>const AMOVIESETUP_PIN sudOpPin = <br>{ L"Output"          // strName <br>, FALSE              // bRendered <br>, TRUE               // bOutput <br>, FALSE              // bZero <br>, FALSE              // bMany <br>, &amp;CLSID_NULL        // clsConnectsToFilter <br>, NULL               // strConnectsToPin <br>, 1                  // nMediaTypes <br>, &amp;sudOpPinTypes };  // lpMediaType <br> <br>const AMOVIESETUP_FILTER sudVidCapax = <br>{ &amp;CLSID_VidCap              // clsID <br>, L"Video Capture (AVICap)"  // strName <br>, MERIT_UNLIKELY             // dwMerit <br>, 1                          // nPins <br>, &amp;sudOpPin };               // lpPin <br> <br>// COM global table of objects available in this dll <br>CFactoryTemplate g_Templates[1] = { <br> <br>    { L"Video Capture (AVICap)" <br>    , &amp;CLSID_VidCap <br>    , CVidCap::CreateInstance <br>    , NULL <br>    , NULL } <br>}; <br>int g_cTemplates = sizeof(g_Templates) / sizeof(g_Templates[0]); <br> <br> <br>// exported entry points for registration and <br>// unregistration (in this case they only call <br>// through to default implmentations). <br>// <br>STDAPI DllRegisterServer() <br>{ <br>  HRESULT hr = AMovieDllRegisterServer2( TRUE ); <br>  if(SUCCEEDED(hr)) <br>  { <br>       <br>      // locate each installed VFW capture driver and register an <br>      // entry in the Video Capture entry that maps to this filter. We <br>      // expect other capture filters to register just once <br>      //  <br>      IFilterMapper2 *pFm2; <br>      HRESULT hr = CoCreateInstance( <br>          CLSID_FilterMapper2, NULL, CLSCTX_INPROC_SERVER, <br>          IID_IFilterMapper2, (void **)&amp;pFm2); <br>      if(SUCCEEDED(hr)) <br>      { <br>       <br>          for(UINT i = 0; i &lt; 10; i++) <br>          { <br>              TCHAR szName[100], szDesc[100]; <br>              if(capGetDriverDescription( <br>                  i, szName, sizeof(szName), szDesc, sizeof(szDesc))) <br>              { <br>                  // generate unique instance value (avicap - name). This <br>                  // should be something that doesn't change from machine <br>                  // to machine as it's used to persist this particular <br>                  // device (see documentation for <br>                  // IMoniker::GetDisplayName). Behind the scenes, this is <br>                  // the name of the registry key for this device. We'll <br>                  // use this name for both the instance name and the <br>                  // friendly-name <br>                  TCHAR szUniq[200]; <br>                  wsprintf(szUniq, "avicap SDK Sample - %s", szName); <br>                   <br>                  WCHAR wszUniq[200]; <br>                  MultiByteToWideChar(CP_ACP, 0, szUniq, -1, wszUniq, NUMELMS(wszUniq)); <br> <br>                  // RegisterFilter returns a moniker here. <br>                  IMoniker *pMoniker = 0; <br> <br>                  REGFILTER2 rf2; <br>                  rf2.dwVersion = 1; <br>                  rf2.dwMerit = MERIT_DO_NOT_USE; <br>                  rf2.cPins = 0; <br>                  rf2.rgPins = 0; <br>                   <br>               <br>                  hr = pFm2-&gt;RegisterFilter( <br>                      CLSID_VidCap, <br>                      wszUniq, <br>                      &amp;pMoniker, <br>                      &amp;CLSID_VideoInputDeviceCategory, <br>                      wszUniq, <br>                      &amp;rf2); <br> <br>                  if(SUCCEEDED(hr)) <br>                  { <br>                      // write out the device number. when the device <br>                      // is picked this filter needs to know which <br>                      // device to open. It does that by reading the <br>                      // AviCapIndex value. <br>                      IPropertyBag *pPropBag; <br>                      hr = pMoniker-&gt;BindToStorage( <br>                          0, 0, IID_IPropertyBag, (void **)&amp;pPropBag); <br>                      if(SUCCEEDED(hr)) <br>                      { <br>                          VARIANT var; <br>                          var.vt = VT_I4; <br>                          var.lVal = i; <br>                          hr = pPropBag-&gt;Write(L"AviCapIndex", &amp;var); <br> <br>                          pPropBag-&gt;Release(); <br>                      } <br>                      pMoniker-&gt;Release(); <br>                  } <br> <br>              } //capGetDriverDescription <br>           <br>              if(FAILED(hr)) <br>                  break; <br> <br>          } // for loop <br> <br>          pFm2-&gt;Release(); <br>      } // CoCreateInstance <br>       <br>  } // AMovieDllRegisterServer2 <br> <br>  return hr; <br>} <br> <br>STDAPI DllUnregisterServer() <br>{ <br>    HRESULT hr = AMovieDllRegisterServer2( FALSE ); <br>    if(SUCCEEDED(hr)) <br>    { <br>       <br>        // remove each entry <br> <br>        IFilterMapper2 *pFm2; <br>        HRESULT hr = CoCreateInstance( <br>            CLSID_FilterMapper2, NULL, CLSCTX_INPROC_SERVER, <br>            IID_IFilterMapper2, (void **)&amp;pFm2); <br>        if(SUCCEEDED(hr)) <br>        { <br>       <br>            for(UINT i = 0; i &lt; 10; i++) <br>            { <br>                TCHAR szName[100], szDesc[100]; <br>                if(capGetDriverDescription( <br>                    i, szName, sizeof(szName), szDesc, sizeof(szDesc))) <br>                { <br>                    // generate unique instance value (avicap - name). This <br>                    // should be something that doesn't change from machine <br>                    // to machine as it's used to persist this particular <br>                    // device (see documentation for <br>                    // IMoniker::GetDisplayName). Behind the scenes, this is <br>                    // the name of the registry key for this device. We'll <br>                    // use this name for both the instance name and the <br>                    // friendly-name <br>                    TCHAR szUniq[200]; <br>                    wsprintf(szUniq, "avicap SDK Sample - %s", szName); <br>                   <br>                    WCHAR wszUniq[200]; <br>                    MultiByteToWideChar(CP_ACP, 0, szUniq, -1, wszUniq, NUMELMS(wszUniq)); <br> <br>                    hr = pFm2-&gt;UnregisterFilter( <br>                        &amp;CLSID_VideoInputDeviceCategory, <br>                        wszUniq, <br>                        CLSID_VidCap); <br> <br>                } //capGetDriverDescription <br> <br>            } // for loop <br> <br>            pFm2-&gt;Release(); <br>        } // CoCreateInstance <br>       <br>    } // AMovieDllRegisterServer2 <br> <br>    return hr; <br>} <br> <br> <br>// <br>// CVidCap::Constructor <br>// <br>// don't create any pins yet, until we are told which device to use <br>// (through IPersistPropertyBag or CPersistStream) <br>CVidCap::CVidCap(TCHAR *pName, LPUNKNOWN lpunk, HRESULT *phr) <br>    : CSource(pName, lpunk, CLSID_VidCap), <br>      CPersistStream(lpunk, phr), <br>      m_pCapturePin(NULL), <br>      m_pOverlayPin(NULL), <br>      m_pPreviewPin(NULL), <br>      m_iVideoId(-1) <br>{ <br> <br>    CAutoLock l(&amp;m_cStateLock); <br> <br>    DbgLog((LOG_TRACE, 1, TEXT("CVidCap filter created"))); <br>} <br> <br> <br>// <br>// CVidCap::Destructor <br>// <br>CVidCap::~CVidCap(void) <br>{ <br>    DbgLog((LOG_TRACE, 1, TEXT("CVidCap filter destroyed")) ); <br> <br>    if (m_pCapturePin) <br>        delete m_pCapturePin; <br>    if (m_pOverlayPin) <br>        delete m_pOverlayPin; <br>    if (m_pPreviewPin) <br>        delete m_pPreviewPin; <br>} <br> <br> <br>// <br>// CreateInstance <br>// <br>// Called by CoCreateInstance to create a vidcap filter. <br>CUnknown * WINAPI CVidCap::CreateInstance(LPUNKNOWN lpunk, HRESULT *phr) <br>{ <br> <br>    CUnknown *punk = new CVidCap(TEXT("Video capture filter"), lpunk, phr); <br>    if (punk == NULL) { <br>        *phr = E_OUTOFMEMORY; <br>    } <br>    return punk; <br>} <br> <br> <br>// give out our interfaces <br>STDMETHODIMP CVidCap::NonDelegatingQueryInterface(REFIID riid, void ** ppv) <br>{ <br>    if (riid == IID_IAMVfwCaptureDialogs) { <br>        return GetInterface((LPUNKNOWN)(IAMVfwCaptureDialogs *)this, ppv); <br>    } else if (riid == IID_IPersistPropertyBag) { <br>        return GetInterface((IPersistPropertyBag *)this, ppv); <br>    } else if(riid == IID_IPersistStream) { <br>        return GetInterface((IPersistStream *)this, ppv); <br>    } <br> <br>   return CSource::NonDelegatingQueryInterface(riid, ppv); <br>} <br> <br> <br>// how many pins do we have? maybe 2, maybe 1, maybe 0 <br>// <br>int CVidCap::GetPinCount() <br>{ <br>   DbgLog((LOG_TRACE,5,TEXT("CVidCap::GetPinCount"))); <br> <br>   // we have a preview pin (one or the other) <br>   if (m_pOverlayPin || m_pPreviewPin) <br>return 2; <br>   else if (m_pCapturePin) <br>return 1; <br>   else <br>        return 0; <br>} <br> <br> <br>// Give out pointers to our pins.  We might have an overlay preview pin <br>// or a non-overlay preview pin <br>// <br>CBasePin * CVidCap::GetPin(int ii) <br>{ <br>   DbgLog((LOG_TRACE,5,TEXT("CVidCap::GetPin"))); <br> <br>   if (ii == 0 &amp;&amp; m_pCapturePin) <br>      return m_pCapturePin; <br>   if (ii == 1 &amp;&amp; m_pOverlayPin) <br>      return m_pOverlayPin; <br>   if (ii == 1 &amp;&amp; m_pPreviewPin) <br>      return m_pPreviewPin; <br>   return NULL; <br>} <br> <br> <br>// IPersistPropertyBag stuff <br>// <br>// Load is called to tell us what device to use.  There may be several <br>// capture cards on the system that we could use <br>STDMETHODIMP CVidCap::Load(LPPROPERTYBAG pPropBag, LPERRORLOG pErrorLog) <br>{ <br>    HRESULT hr; <br>    CAutoLock l(pStateLock()); <br> <br>    DbgLog((LOG_TRACE,1,TEXT("Load..."))); <br> <br>    // We already have some pins, thank you <br>    if (m_pCapturePin) <br>return E_UNEXPECTED; <br> <br>    // Default to capture device #0 <br>    if (pPropBag == NULL) { <br>        m_iVideoId = 0; <br>        DbgLog((LOG_TRACE,1,TEXT("Using default device ID=%d"), m_iVideoId)); <br>        CreatePins(&amp;hr); <br>return hr; <br>    } <br> <br>    // find out what device to use <br>    // different filters look in different places to find this info <br>    VARIANT var; <br>    var.vt = VT_I4; <br>    hr = pPropBag-&gt;Read(L"AviCapIndex", &amp;var, 0); <br>    if(SUCCEEDED(hr)) <br>    { <br>        hr = S_OK; <br>        m_iVideoId = var.lVal; <br>        DbgLog((LOG_TRACE,1,TEXT("Using device ID=%d"), m_iVideoId)); <br>        CreatePins(&amp;hr); <br>    } <br>    return hr; <br>} <br> <br> <br>STDMETHODIMP CVidCap::Save( <br>    LPPROPERTYBAG pPropBag, BOOL fClearDirty, <br>    BOOL fSaveAllProperties) <br>{ <br>    // E_NOTIMPL is not really a valid return code as any object implementing <br>    // this interface must support the entire functionality of the <br>    // interface. <br>    return E_NOTIMPL; <br>} <br> <br> <br>// have we been initialized yet?  (Has somebody called Load) <br>STDMETHODIMP CVidCap::InitNew() <br>{ <br>   if(m_pCapturePin) <br>   { <br>       ASSERT(m_iVideoId != -1); <br>       return HRESULT_FROM_WIN32(ERROR_ALREADY_INITIALIZED); <br>   } <br>   else <br>   { <br>       return S_OK; <br>   } <br>} <br> <br> <br>// CPersistStream stuff <br>// <br>// what is our class ID? <br>STDMETHODIMP CVidCap::GetClassID(CLSID *pClsid) <br>{ <br>    CheckPointer(pClsid, E_POINTER); <br>    *pClsid = CLSID_VidCap; <br>    return S_OK; <br>} <br> <br>// CSource expects all its pins to derive from CSourceStream. Since <br>// this sample doesn't do this, we implement QueryId and FindPin to <br>// provide matching implementations <br> <br>STDMETHODIMP CVidCap::FindPin( <br>    LPCWSTR Id, IPin ** ppPin) <br>{ <br>    return CBaseFilter::FindPin(Id, ppPin); <br>} <br> <br> <br>HRESULT CVidCap::WriteToStream(IStream *pStream) <br>{ <br>    ASSERT(m_iVideoId &gt;= -1 &amp;&amp; m_iVideoId &lt; 10); <br>    return pStream-&gt;Write(&amp;m_iVideoId, sizeof(LONG), 0); <br>} <br> <br> <br>// what device should we use?  Used to re-create a .GRF file that we <br>// are in <br>HRESULT CVidCap::ReadFromStream(IStream *pStream) <br>{ <br>    if(m_pCapturePin) <br>    { <br>        ASSERT(m_iVideoId != -1); <br>        return HRESULT_FROM_WIN32(ERROR_ALREADY_INITIALIZED); <br>    } <br> <br>    ASSERT(m_iVideoId == -1); <br> <br>    LONG iVideoId; <br>    HRESULT hr = pStream-&gt;Read(&amp;iVideoId, sizeof(LONG), 0); <br>    if(FAILED(hr)) <br>        return hr; <br> <br>    m_iVideoId = iVideoId; <br>    DbgLog((LOG_TRACE,1,TEXT("Using device ID=%d"), m_iVideoId)); <br> <br>    hr = S_OK; <br>    CreatePins(&amp;hr); <br>    return hr; <br>} <br> <br> <br>// How long is our data?  Just a long int (m_iVideoId) <br>int CVidCap::SizeMax() <br>{ <br>    return sizeof(LONG); <br>} <br> <br> <br>// Now we can create our output pins, after a device is chosen <br>// <br>void CVidCap::CreatePins(HRESULT *phr) <br>{ <br>    if (FAILED(*phr)) <br>        return; <br> <br>    CAutoLock l(pStateLock()); <br> <br>    if (m_pCapturePin) <br>        *phr = HRESULT_FROM_WIN32(ERROR_ALREADY_INITIALIZED); <br> <br>    ASSERT(m_iVideoId != -1);// no device chosen yet?! <br> <br>    // Our capture pin MUST be called L"Capture" <br>    m_pCapturePin = new CVidStream(NAME("Video capture stream"), <br>phr, this, m_iVideoId, L"Capture"); <br>    if (m_pCapturePin == NULL) { <br>        *phr = E_OUTOFMEMORY; <br>        return; <br>    } <br> <br>    if (FAILED(*phr)) { <br>delete m_pCapturePin; <br>m_pCapturePin = NULL; <br>        return; <br>    } <br> <br>    // We can do overlay, so let's make a preview pin that does overlay <br>    // Otherwise, do a preview pin that will fake up a preview <br>    if (m_pCapturePin-&gt;m_HasOverlay) <br>m_pOverlayPin = CreateOverlayPin(phr); <br>    else <br>m_pPreviewPin = CreatePreviewPin(phr); <br>} <br> <br> <br>// tell CBaseStreamControl what clock to use <br>// <br>STDMETHODIMP CVidCap::SetSyncSource(IReferenceClock *pClock) <br>{ <br>    if (m_pCapturePin) <br>m_pCapturePin-&gt;SetSyncSource(pClock); <br>    if (m_pPreviewPin) <br>m_pPreviewPin-&gt;SetSyncSource(pClock); <br>    return CSource::SetSyncSource(pClock); <br>} <br> <br> <br>// tell CBaseStreamControl what sink to use <br>// <br>STDMETHODIMP CVidCap::JoinFilterGraph(IFilterGraph * pGraph, LPCWSTR pName) <br>{ <br>    HRESULT hr = CSource::JoinFilterGraph(pGraph, pName); <br>    if (hr == S_OK &amp;&amp; m_pCapturePin) <br>m_pCapturePin-&gt;SetFilterGraph(m_pSink); <br>    if (hr == S_OK &amp;&amp; m_pPreviewPin) <br>m_pPreviewPin-&gt;SetFilterGraph(m_pSink); <br>    return hr; <br>} <br> <br> <br>// we don't send any data during PAUSE, so to avoid hanging renderers, we <br>// need to return VFW_S_CANT_CUE when paused <br>// <br>STDMETHODIMP CVidCap::GetState(DWORD dwMSecs, FILTER_STATE *State) <br>{ <br>    UNREFERENCED_PARAMETER(dwMSecs); <br>    CheckPointer(State,E_POINTER); <br>    ValidateReadWritePtr(State,sizeof(FILTER_STATE)); <br> <br>    *State = m_State; <br>    if (m_State == State_Paused) <br>return VFW_S_CANT_CUE; <br>    else <br>        return S_OK; <br>} <br> <br> <br>// Run <br>// <br>// Activate the pin, letting it know that we are moving to State_Running <br>// <br>STDMETHODIMP CVidCap::Run(REFERENCE_TIME tStart) { <br>    CAutoLock l(pStateLock()); <br> <br>    DbgLog((LOG_TRACE,2,TEXT("::Run"))); <br> <br>    HRESULT hr; <br> <br>    m_tStart = tStart;  // remember the stream time offset <br> <br>    hr = CSource::Run(tStart); <br> <br>    // Tell CBaseStreamControl what's going on <br>    m_pCapturePin-&gt;NotifyFilterState(State_Running, tStart); <br>    if (m_pPreviewPin) <br>        m_pPreviewPin-&gt;NotifyFilterState(State_Running, tStart); <br> <br>    if (SUCCEEDED(hr)) { <br>// start us running <br>m_pCapturePin-&gt;Run(); <br>// overlay pin wants to know too <br>if (m_pOverlayPin &amp;&amp; m_pOverlayPin-&gt;IsConnected()) <br>    m_pOverlayPin-&gt;ActiveRun(tStart); <br>// preview pin wants to know too <br>if (m_pPreviewPin &amp;&amp; m_pPreviewPin-&gt;IsConnected()) <br>    m_pPreviewPin-&gt;ActiveRun(tStart); <br>    } <br> <br>    return S_OK; <br>} <br> <br> <br>// <br>// Pause <br>// <br>// Activate the pin, letting it know that Paused will <br>// be the next state <br>STDMETHODIMP CVidCap::Pause(void) { <br>    CAutoLock l(pStateLock()); <br> <br>    BOOL fWasStopped = FALSE; <br> <br>    if (m_State == State_Paused) { <br>        return S_OK; <br>    } <br> <br>    DbgLog((LOG_TRACE,2,TEXT("::Pause"))); <br> <br>    // The video renderer will start blocking Deliver() when it goes from <br>    // run to pause (or any filter could potentially do that) making us <br>    // hang, so we need to tell it to release the sample by flushing <br>    // it before we tell the thread to pause, or the thread will be hung <br>    // and never get our message <br>    if (m_State == State_Running) { <br>        m_pCapturePin-&gt;DeliverBeginFlush(); <br>        m_pCapturePin-&gt;DeliverEndFlush(); <br> <br>// our overlay pin wants to know when we stop running <br>if (m_pOverlayPin) <br>    m_pOverlayPin-&gt;ActivePause(); <br>// our preview pin wants to know when we stop running <br>if (m_pPreviewPin) <br>    m_pPreviewPin-&gt;ActivePause(); <br>    } <br> <br>    // we're streaming the graph now, so we better close our temporary <br>    // window, so we can open it for real later, with the real # of buffers <br>    if (m_State == State_Stopped &amp;&amp; m_pCapturePin-&gt;m_hwCapCapturing) { <br>        m_pCapturePin-&gt;DestroyCaptureWindow(m_pCapturePin-&gt;m_hwCapCapturing); <br>        m_pCapturePin-&gt;m_hwCapCapturing = NULL; <br>    } <br> <br>    // the capture pin is in fact going to start streaming... tell the <br>    // preview pin to release the hardware <br>    if (m_State == State_Stopped &amp;&amp; m_pCapturePin-&gt;IsConnected()) { <br>fWasStopped = TRUE; <br>if (m_pPreviewPin) <br>    m_pPreviewPin-&gt;CapturePinActive(TRUE); <br>    } <br> <br>    // need to change state before sending the pause request <br>    // or the thread will not be created when we try to signal it. <br>    HRESULT hr = CSource::Pause(); <br>    if (FAILED(hr)) { <br>// error, never mind <br>if (fWasStopped &amp;&amp; m_pPreviewPin) <br>    m_pPreviewPin-&gt;CapturePinActive(FALSE); <br>        return hr; <br>    } <br> <br>    // the source stream base class seems to freak out if we pause it when not <br>    // connected <br>    if (m_pCapturePin-&gt;IsConnected()) { <br>        // Tell CBaseStreamControl what's going on <br>        m_pCapturePin-&gt;NotifyFilterState(State_Paused, 0); <br>if (m_pPreviewPin) <br>            m_pPreviewPin-&gt;NotifyFilterState(State_Paused, 0); <br> <br>        hr = m_pCapturePin-&gt;Pause(); <br>// error, never mind <br>if (FAILED(hr) &amp;&amp; fWasStopped &amp;&amp; m_pPreviewPin) <br>    m_pPreviewPin-&gt;CapturePinActive(FALSE); <br>return hr; <br>    } <br> <br>    return NOERROR; <br>} <br> <br> <br>// <br>// Stop <br>// <br>// Pass the current state to the pins Inactive method <br>STDMETHODIMP CVidCap::Stop(void) { <br>    HRESULT hr; <br>    CAutoLock l(pStateLock()); <br> <br>    DbgLog((LOG_TRACE,2,TEXT("::Stop"))); <br> <br>    // Shame on the base classes, they don't take care of this, and it's very <br>    // important for us that we go through pause on our way to stop <br>    if (m_State == State_Running) { <br>hr = Pause(); <br>if (FAILED(hr)) <br>    return hr; <br>    } <br> <br>    // Tell stream control we're stopped, so he will stop blocking the thread <br>    // that captures the video (if we're in discarding mode).  Calling  <br>    // CSource::Stop below will hang if the AVICAP capture thread is blocked, <br>    // because it's going to destroy that thread. <br>    m_pCapturePin-&gt;NotifyFilterState(State_Stopped, 0); <br>    if (m_pPreviewPin) <br>        m_pPreviewPin-&gt;NotifyFilterState(State_Stopped, 0); <br> <br>    hr = CSource::Stop(); <br> <br>    // tell our preview pin that it can have the h/w if it wants it. <br>    // we're through <br>    if (m_pPreviewPin) <br>m_pPreviewPin-&gt;CapturePinActive(FALSE); <br> <br>    m_tStart = CRefTime(0L); <br> <br>    return hr; <br>} <br> <br> <br>// create the preview pin we use if we have overlay hardware <br>// <br>CVidOverlay * CVidCap::CreateOverlayPin(HRESULT * phr) <br>{ <br>   DbgLog((LOG_TRACE,2,TEXT("CreateOverlayPin"))); <br> <br>   WCHAR wszPinName[16]; <br>   lstrcpyW(wszPinName, L"Preview"); <br> <br>   CVidOverlay * pOverlay = new CVidOverlay(NAME("Video Overlay Stream"), <br>this, phr, wszPinName); <br>   if (!pOverlay) <br>      *phr = E_OUTOFMEMORY; <br> <br>   // if initialization failed, delete the stream array <br>   // and return the error <br>   // <br>   if (FAILED(*phr) &amp;&amp; pOverlay) <br>      delete pOverlay, pOverlay = NULL; <br> <br>   return pOverlay; <br>} <br> <br> <br>// create the preview pin we use if we DO NOT have overlay hardware <br>// <br>CVidPreview * CVidCap::CreatePreviewPin(HRESULT * phr) <br>{ <br>   DbgLog((LOG_TRACE,2,TEXT("CreatePreviewPin"))); <br> <br>   WCHAR wszPinName[16]; <br>   lstrcpyW(wszPinName, L"Preview"); <br> <br>   CVidPreview * pPreview = new CVidPreview(NAME("Video Preview Stream"), <br>this, phr, wszPinName); <br>   if (!pPreview) <br>      *phr = E_OUTOFMEMORY; <br> <br>   // if initialization failed, delete the stream array <br>   // and return the error <br>   // <br>   if (FAILED(*phr) &amp;&amp; pPreview) <br>      delete pPreview, pPreview = NULL; <br> <br>   return pPreview; <br>} <br> <br> <br> <br>// <br>// IAMVfwCaptureDialogs  implementation <br>// <br> <br>// Does this driver support a particular dialog box? <br>// <br>HRESULT CVidCap::HasDialog(int iDialog) <br>{ <br>    if (iDialog == VfwCaptureDialog_Source) <br>return (m_pCapturePin-&gt;m_SupportsVideoSourceDialog ? S_OK : S_FALSE); <br>    else if (iDialog == VfwCaptureDialog_Format) <br>return (m_pCapturePin-&gt;m_SupportsVideoFormatDialog ? S_OK : S_FALSE); <br>    else if (iDialog == VfwCaptureDialog_Display) <br>return (m_pCapturePin-&gt;m_SupportsVideoDisplayDialog ? S_OK : S_FALSE); <br>    else <br>return E_INVALIDARG; <br>} <br> <br> <br>// Show a particular dialog box of the driver <br>// <br>HRESULT CVidCap::ShowDialog(int iDialog, HWND hwnd) <br>{ <br>    HRESULT hr; <br> <br>    // we can't hold any critical sections while the dialog box is up <br> <br>    // before bringing up a dialog that could change our format, make <br>    // sure we're not streaming <br>    if (m_State != State_Stopped) { <br>return E_UNEXPECTED; <br>    } <br> <br>    // !!! If the filter starts streaming while the dialog is up, this <br>    // could cause problems! We aren't protecting against this <br> <br>    // open the device temporarily - if we don't put the hwnd in our <br>    // m_hwCapCapturing variable, GetMediaType below won't get the <br>    // format set by the dialog box <br>    if (m_pCapturePin-&gt;m_hwCapCapturing == NULL) <br>        m_pCapturePin-&gt;m_hwCapCapturing = m_pCapturePin-&gt;CreateCaptureWindow(0); <br>    if (m_pCapturePin-&gt;m_hwCapCapturing == NULL) <br>        return E_FAIL; <br> <br>    if (iDialog == VfwCaptureDialog_Source) <br>hr = capDlgVideoSource(m_pCapturePin-&gt;m_hwCapCapturing) == TRUE ? <br>NOERROR : E_FAIL; <br>    else if (iDialog == VfwCaptureDialog_Format) <br>hr = capDlgVideoFormat(m_pCapturePin-&gt;m_hwCapCapturing) == TRUE ? <br>NOERROR : E_FAIL; <br>    else if (iDialog == VfwCaptureDialog_Display) <br>hr = capDlgVideoDisplay(m_pCapturePin-&gt;m_hwCapCapturing) == TRUE ? <br>NOERROR : E_FAIL; <br>    else { <br>hr = E_INVALIDARG; <br>    } <br> <br>    // bringing up the Format Dialog can change the format we are capturing <br>    // with. <br>    if (hr == NOERROR &amp;&amp; iDialog == VfwCaptureDialog_Format) { <br>        DbgLog((LOG_TRACE,1,TEXT("Dialog changed our output format"))); <br> <br>// now get the new format chosen in the dialog.  First of all, <br> // forget any remembered type in m_mt, so that GetMediaType will <br>// quiz the driver for the format set by the dialog <br>m_pCapturePin-&gt;m_mt.SetType(&amp;GUID_NULL); <br>CMediaType cmt; <br>m_pCapturePin-&gt;GetMediaType(&amp;cmt); <br>// now put the media type back in case this new type doesn't take <br>if (m_pCapturePin-&gt;IsConnected()) <br>    m_pCapturePin-&gt;m_mt.SetType(&amp;MEDIATYPE_Video); <br> <br>        // If we are connected to somebody, make sure they like it <br>        if (m_pCapturePin-&gt;IsConnected()) <br>    hr = m_pCapturePin-&gt;GetConnected()-&gt;QueryAccept(&amp;cmt); <br> <br>if (hr == NOERROR) { <br>    hr = m_pCapturePin-&gt;SetMediaType(&amp;cmt); <br>            // Now reconnect us so the graph starts using the new format <br>    if (hr == NOERROR) <br>                m_pCapturePin-&gt;Reconnect(TRUE); <br>} <br>    } <br> <br>    // leave the driver open so we can connect quickly.  We'll close the driver <br>    // before we start streaming <br> <br>    return hr; <br>} <br> <br> <br>// used to send secret messages to a capture driver. Use at your own risk <br>// <br>HRESULT CVidCap::SendDriverMessage(int iDialog, int uMsg, long dw1, long dw2) <br>{ <br>return E_NOTIMPL;// too scary <br>} <br> <br> <br> <br> <br>// * <br>// * Implements CVidStream - manages the output pin <br>// * <br> <br> <br>// <br>// CVidStream::Constructor <br>// <br>// keep the driver index to open. <br>// Well behaved filters are supposed to only hold resources (like opening <br>// the capture driver) when they are streaming, so we will open the <br>// capture driver temporarily only (until we are streaming), and then close <br>// it again right away.  Drivers usually have no memory across opens, so <br>// we'll have to remember what format we want to capture with and when we <br>// finally open it for real, send that format to the driver, as it will <br>// have long forgotten. <br>// !!! If we really cared about performance, we wouldn't open and close <br>// the driver so much.  That takes forever.  Also, we do extra memory copies <br>// that slow things down.  But this is only a sample driver <br>// <br>CVidStream::CVidStream(TCHAR            *pObjectName <br>                      , HRESULT         *phr <br>                      , CVidCap         *pParentFilter <br>                      , unsigned int    uiDriverIndex <br>                      , LPCWSTR          pPinName <br>                      ) <br>    :CSourceStream(pObjectName, phr, pParentFilter, pPinName), <br>     m_uiDriverIndex(uiDriverIndex), <br>     m_plFilled(NULL), <br>     m_hwCapCapturing(NULL), <br>     m_fSetFormatCalled(FALSE), <br>     m_dwMicroSecPerFrame(66667),      // default to 15 fps <br>     m_uiFramesCaptured(0), <br>     m_uiFramesSkipped(0), <br>     m_llTotalFrameSize(0), <br>     m_uiFramesDelivered(0) <br>    { <br> <br>    CAutoLock lock(m_pFilter-&gt;pStateLock()); <br> <br>    // for IAMBufferNegotiation - no suggestions so far <br>    m_propSuggested.cBuffers = -1; <br>    m_propSuggested.cbBuffer = -1; <br>    m_propSuggested.cbAlign = -1; <br>    m_propSuggested.cbPrefix = -1; <br> <br>    // open the driver temporarily <br>    m_hwCapCapturing = CreateCaptureWindow(0); <br>    if (m_hwCapCapturing == NULL) { <br>        *phr = E_FAIL; <br>        return; <br>    } <br> <br>    // get the name and version of the driver <br> <br>#ifdef UNICODE <br>    capDriverGetName(m_hwCapCapturing, m_szName, sizeof(m_szName)); <br>    capDriverGetVersion(m_hwCapCapturing, m_szVersion, sizeof(m_szVersion)); <br>#else <br>    char sz[giDriverNameStrLen]; <br>    capDriverGetName(m_hwCapCapturing, sz, sizeof(sz)); <br>    MultiByteToWideChar(CP_ACP, 0, <br>                            sz, -1, <br>                            m_szName, giDriverNameStrLen); <br> <br>    capDriverGetVersion(m_hwCapCapturing, sz, sizeof(sz)); <br>    MultiByteToWideChar(CP_ACP, 0, <br>                            sz, -1, <br>                            m_szVersion, giDriverVerStrLen); <br>#endif <br>    // Establish what dialogs this driver can display. <br> <br>    CAPDRIVERCAPS DriverCaps; <br>    capDriverGetCaps(m_hwCapCapturing, &amp;DriverCaps, sizeof(DriverCaps) ); <br>    m_SupportsVideoSourceDialog  = DriverCaps.fHasDlgVideoSource; <br>    m_SupportsVideoDisplayDialog = DriverCaps.fHasDlgVideoDisplay; <br>    m_SupportsVideoFormatDialog  = DriverCaps.fHasDlgVideoFormat; <br>    m_HasOverlay  = DriverCaps.fHasOverlay; <br>#if 0 <br>    m_SuppliesPalettes = DriverCaps.fDriverSuppliesPalettes; <br>#endif <br> <br>    // leave the driver open so we can connect quickly.  We'll close the driver <br>    // before we start streaming <br> <br>    DbgLog( (LOG_TRACE, 1, TEXT("CVidStream created") ) ); <br>} <br> <br> <br>// <br>// CVidStream::Destructor <br>// <br>// we should be inactive before this is called. <br>CVidStream::~CVidStream(void) { <br> <br>    CAutoLock lock(m_pFilter-&gt;pStateLock()); <br> <br>    ASSERT(!m_pFilter-&gt;IsActive()); <br> <br>    if (m_hwCapCapturing) <br>DestroyCaptureWindow(m_hwCapCapturing); <br> <br>    DbgLog( (LOG_TRACE, 1, TEXT("CVidStream destroyed") ) ); <br> <br>} <br> <br> <br>// set the new media type <br>// <br>HRESULT CVidStream::SetMediaType(const CMediaType* pmt) <br>{ <br>    DbgLog((LOG_TRACE,2,TEXT("SetMediaType %x %dbit %dx%d"), <br>HEADER(pmt-&gt;Format())-&gt;biCompression, <br>HEADER(pmt-&gt;Format())-&gt;biBitCount, <br>HEADER(pmt-&gt;Format())-&gt;biWidth, <br>HEADER(pmt-&gt;Format())-&gt;biHeight)); <br> <br>    ASSERT(((CVidCap *)m_pFilter)-&gt;m_State == State_Stopped); <br> <br>    // We are being told the frame rate to use.  It is in the VIDEOINFOHEADER <br>    if (((VIDEOINFOHEADER *)(pmt-&gt;pbFormat))-&gt;AvgTimePerFrame) { <br>m_dwMicroSecPerFrame = (DWORD)(((VIDEOINFOHEADER *)(pmt-&gt;pbFormat))-&gt; <br>AvgTimePerFrame / 10); <br>        DbgLog((LOG_TRACE,2,TEXT("SetMediaType: New frame rate is %d us per frame"), <br>m_dwMicroSecPerFrame)); <br>    } <br> <br>    // !!! The bit rate to use is in the VIDEOINFOHEADER too, but we can't <br>    // obey it... we have no programmatic way of setting it, only through <br>    // a dialog box <br> <br>    // now reconnect our preview pin to use the same format as us <br>    Reconnect(FALSE); <br> <br>    // this will remember the media type in m_mt, and when we open the <br>    // driver for real, we'll send it this format to use <br>    return CSourceStream::SetMediaType(pmt); <br>} <br> <br> <br>// stop remembering what media type we are supposed to use once we start <br>// streaming - all bets are off until we connect again... unless somebody <br>// called SetFormat... we will always use that format from now on <br>// <br>HRESULT CVidStream::BreakConnect() <br>{ <br>    if (m_fSetFormatCalled == FALSE) <br>        m_mt.SetType(&amp;GUID_NULL); </code></pre>
<p>
</p>
<pre><code>return CSourceStream::BreakConnect(); <br>} <br> <br> <br>// <br>// CheckMediaType <br>// <br>// Queries the video driver to see if the format is acceptable <br>// The only way to query if we support a given format is to set the driver <br>// to use that format and see if it succeeds or fails.  So we better only <br>// accept queries until we start streaming, because then we'd actually <br>// affect the capture! <br>// <br>HRESULT CVidStream::CheckMediaType(const CMediaType *pmt) { <br> <br>    DbgLog((LOG_TRACE,3,TEXT("CheckMediaType"))); <br> <br>    CAutoLock l(&amp;m_cSharedState); <br>    CAutoLock lock(m_pFilter-&gt;pStateLock()); <br> <br>    // bad idea to set the capture format while capturing... <br>    if (((CVidCap *)m_pFilter)-&gt;m_State != State_Stopped) <br>return E_UNEXPECTED; <br> <br>    if (pmt == NULL || pmt-&gt;Format() == NULL) { <br>        DbgLog((LOG_TRACE,3,TEXT("Rejecting: type/format is NULL"))); <br>return E_INVALIDARG; <br>    } <br> <br>    // we only support MEDIATYPE_Video <br>    if (*pmt-&gt;Type() != MEDIATYPE_Video) { <br>        DbgLog((LOG_TRACE,3,TEXT("Rejecting: not VIDEO"))); <br>return E_INVALIDARG; <br>    } <br> <br>    // check this is a VIDEOINFOHEADER type <br>    if (*pmt-&gt;FormatType() != FORMAT_VideoInfo) { <br>        DbgLog((LOG_TRACE,3,TEXT("Rejecting: format not VIDINFO"))); <br>        return E_INVALIDARG; <br>    } <br> <br>    RECT rcS = ((VIDEOINFOHEADER *)pmt-&gt;Format())-&gt;rcSource; <br>    RECT rcT = ((VIDEOINFOHEADER *)pmt-&gt;Format())-&gt;rcTarget; <br>    if (!IsRectEmpty(&amp;rcT) &amp;&amp; (rcT.left != 0 || rcT.top != 0 || <br>HEADER(pmt-&gt;Format())-&gt;biWidth != rcT.right || <br>HEADER(pmt-&gt;Format())-&gt;biHeight != rcT.bottom)) { <br>        DbgLog((LOG_TRACE,3,TEXT("Rejecting: can't use funky rcTarget"))); <br>        return VFW_E_INVALIDMEDIATYPE; <br>    } <br>    // We don't know what this would be relative to... reject everything <br>    if (!IsRectEmpty(&amp;rcS)) { <br>        DbgLog((LOG_TRACE,3,TEXT("Rejecting: can't use funky rcSource"))); <br>        return VFW_E_INVALIDMEDIATYPE; <br>    } <br> <br>    // open the driver temporarily <br>    if (m_hwCapCapturing == NULL) <br>        m_hwCapCapturing = CreateCaptureWindow(0); <br>    if (m_hwCapCapturing == NULL) <br>        return E_FAIL; <br> <br>    // the only way we can see if the driver supports a given format is to <br>    // try and set it to use that format. <br>    LPBITMAPINFOHEADER lpbiCheck = HEADER(pmt-&gt;Format()); <br>    DWORD dw = capSetVideoFormat(m_hwCapCapturing, lpbiCheck, <br>lpbiCheck-&gt;biSize + <br>((lpbiCheck-&gt;biBitCount &gt; 8 || lpbiCheck-&gt;biClrUsed) ? <br>(lpbiCheck-&gt;biClrUsed * sizeof(PALETTEENTRY)) : <br>2 ^ lpbiCheck-&gt;biBitCount * sizeof(PALETTEENTRY))); <br> <br>    // leave the driver open so we can connect quickly.  We'll close the driver <br>    // before we start streaming <br> <br>    return (dw == TRUE ? NOERROR : VFW_E_INVALIDMEDIATYPE); <br>} <br> <br> <br>// <br>// GetMediaType <br>// <br>// Queries the video driver and places an appropriate media type in *pmt <br>// If we have remembered a type that we are supposed to be using, <br>// return that one <br>// <br>HRESULT CVidStream::GetMediaType(CMediaType *pmt) { <br> <br>    CAutoLock l(&amp;m_cSharedState); <br> <br>    // We've been told by somebody to use a particular media type. <br>    // That's what we'll return <br>    if (m_mt.IsValid()) { <br>*pmt = m_mt; <br>return NOERROR; <br>    } <br> <br>    // We may or may not be streaming and have the driver open already <br>    if (m_hwCapCapturing == NULL) <br>        m_hwCapCapturing = CreateCaptureWindow(0); <br>    if (m_hwCapCapturing == NULL) <br>        return E_FAIL; <br> <br>    pmt-&gt;SetType(&amp;MEDIATYPE_Video); <br>    pmt-&gt;SetFormatType(&amp;FORMAT_VideoInfo); <br> <br>    DWORD dwFormatSize; <br>    VIDEOINFOHEADER *pvi; <br> <br>    dwFormatSize = capGetVideoFormatSize(m_hwCapCapturing); <br> <br>    ASSERT(dwFormatSize &gt; 0); <br> <br>    // Find out how big we need to allocate the buffer <br>#define AllocBufferSize (max(sizeof(VIDEOINFOHEADER) + sizeof(TRUECOLORINFO), \ <br>dwFormatSize+offsetof(VIDEOINFOHEADER,bmiHeader))) <br> <br>    // Set up the format section of the mediatype to be the right size <br>    pvi = (VIDEOINFOHEADER *) pmt-&gt;AllocFormatBuffer(AllocBufferSize); <br>#undef AllocBufferSize <br>    if (pvi == NULL) { <br>        return E_OUTOFMEMORY; <br>    } <br> <br>    // make sure all fields are initially zero <br>    ZeroMemory((void *)pvi, sizeof(VIDEOINFOHEADER)); <br> <br>    // make a note of the current fps we're doing <br>    pvi-&gt;AvgTimePerFrame = m_dwMicroSecPerFrame * 10; <br> <br>    // grab the BITMAPINFOHEADER straight in <br>    // will leave the memory after the last palette entry as zeros. <br>    capGetVideoFormat(m_hwCapCapturing, &amp;(pvi-&gt;bmiHeader), dwFormatSize); <br> <br>    const GUID SubTypeGUID = GetBitmapSubtype(&amp;pvi-&gt;bmiHeader); <br>    pmt-&gt;SetSubtype(&amp;SubTypeGUID); <br>    pmt-&gt;SetSampleSize(GetSampleSize(&amp;pvi-&gt;bmiHeader)); <br>    pmt-&gt;SetTemporalCompression(FALSE); <br> <br>    // leave the driver open so we can connect quickly.  We'll close the driver <br>    // before we start streaming <br> <br>    return NOERROR; <br>} <br> <br> <br>// <br>// OnThreadCreate <br>// <br>// Start streaming &amp; reset time samples are stamped with. <br>HRESULT CVidStream::OnThreadCreate(void) { <br> <br>    CAutoLock l(&amp;m_cSharedState); <br> <br>    m_ThreadState = Stopped; <br> <br>    // we are starting to stream now.  Open the capture driver FOR REAL! <br>    // Use however many buffers we're supposed to use <br>    ASSERT(m_hwCapCapturing == NULL); <br>    m_hwCapCapturing = CreateCaptureWindow(m_propActual.cBuffers); <br>    if (m_hwCapCapturing == NULL) { <br>            return E_FAIL; <br>    } <br> <br>    // m_mt is the format we connected with.  Tell the driver to use <br>    // that format as its capture format <br>    LPBITMAPINFOHEADER lpbi = HEADER(m_mt.Format()); <br>    DWORD dwSize = lpbi-&gt;biSize + <br>((lpbi-&gt;biBitCount &gt; 8 || lpbi-&gt;biClrUsed) ? <br>(lpbi-&gt;biClrUsed * sizeof(PALETTEENTRY)) : <br>(2 ^ lpbi-&gt;biBitCount * sizeof(PALETTEENTRY))); <br>    DWORD dw = capSetVideoFormat(m_hwCapCapturing, lpbi, dwSize); <br>    ASSERT(dw == TRUE);// we were promised this would work! <br> <br>    m_plFilled = new CVideoBufferList( m_mt.lSampleSize <br>                                     , m_dwMicroSecPerFrame <br>                                     , (CVidCap *)m_pFilter <br>     , m_propActual.cBuffers <br>                                     ); <br>    if (m_plFilled == NULL) { <br>        return E_OUTOFMEMORY; <br>    } <br> <br>    // IAMDroppedFrames:  every time you start streaming, reset your stats <br>    m_uiFramesCaptured = 0; <br>    m_uiFramesSkipped = 0; <br>    m_llTotalFrameSize = 0; <br>    m_uiFramesDelivered = 0; <br> <br>    return NOERROR; <br>} <br> <br> <br>// Inactive - overridden to replace the call to CAMThread::Close with <br>// different code that will dispatch messages waiting for the thread to <br>// die.  (explained below) <br>// <br>HRESULT CVidStream::Inactive(void) { <br> <br>    CAutoLock lock(m_pFilter-&gt;pStateLock()); <br> <br>    HRESULT hr; <br> <br>    // do nothing if not connected - its ok not to connect to <br>    // all pins of a source filter <br>    if (!IsConnected()) { <br>        return NOERROR; <br>    } <br> <br>    // !!! need to do this before trying to stop the thread, because <br>    // we may be stuck waiting for our own allocator!!! <br> <br>    hr = CBaseOutputPin::Inactive();  // call this first to Decommit the allocator <br>    if (FAILED(hr)) { <br>return hr; <br>    } <br> <br>    if (ThreadExists()) { <br>hr = Stop(); <br> <br>if (FAILED(hr)) { <br>    return hr; <br>} <br> <br>hr = Exit(); <br>if (FAILED(hr)) { <br>    return hr; <br>} <br> <br>        // when our main thread shuts down the capture thread, the capture <br>        // thread will destroy the capture window it made, and this will cause <br>// USER to send messages to our main thread, and if we're blocked <br>// waiting for the capture thread to go away, we will deadlock <br>// preventing user from sending us the messages, and thus our thread <br>// will never go away.  We need to dispatch messages while waiting <br>        if (m_hThread) { <br>    // !!! It's more efficient to use MsgWaitForMultipleObjects, I know. <br>            while (WaitForSingleObject(m_hThread, 50) == WAIT_TIMEOUT) { <br>        MSG msg; <br>        while (PeekMessage(&amp;msg, NULL, 0, 0, PM_REMOVE)) { <br>    TranslateMessage(&amp;msg); <br>    DispatchMessage(&amp;msg); <br>        } <br>    } <br>            CloseHandle(m_hThread); <br>            m_hThread = 0; <br>        } <br>    } <br> <br>    // hr = CBaseOutputPin::Inactive();  // call this first to Decommit the allocator <br>    //if (FAILED(hr)) { <br>    //return hr; <br>    //} <br> <br>    return NOERROR; <br>} <br> <br> <br>// <br>// OnThreadDestroy <br>// <br>// Free the list of completed buffers and stop streaming <br>// Attempts to stop streaming and destroy the window, even in error <br>// cases. <br>HRESULT CVidStream::OnThreadDestroy(void) { <br> <br>    CAutoLock l(&amp;m_cSharedState); <br> <br>    ASSERT(m_ThreadState == Stopped); <br> <br>    // no longer streaming.  close the driver <br>    BOOL fWindowGone = DestroyCaptureWindow(m_hwCapCapturing); <br>    m_hwCapCapturing = NULL; <br> <br>    delete m_plFilled, m_plFilled = NULL; <br> <br>    DbgLog((LOG_TRACE, 1, TEXT("Frames Captured: %d"), m_uiFramesCaptured)); <br>    DbgLog((LOG_TRACE, 1, TEXT("Frames Skipped: %d"), m_uiFramesSkipped)); <br>    DbgLog((LOG_TRACE, 1, TEXT("Frames Delivered: %d"), m_uiFramesDelivered)); <br> <br>    if (!fWindowGone) { <br>        return E_UNEXPECTED; <br>    } else { <br>        return NOERROR; <br>    } <br>} <br> <br> <br>// <br>// DecideBufferSize <br>// <br>// Get an allocator that we have been asked to get (through <br>// IAMBufferNegotiation) or that we will be happy with <br>// Check that the allocator can give us appropriately sized buffers <br>// Always called after format negotiation. <br>// <br>HRESULT CVidStream::DecideBufferSize(IMemAllocator *pAlloc, <br>                                     ALLOCATOR_PROPERTIES *pProperties) <br>{ <br>    CAutoLock lock(m_pFilter-&gt;pStateLock()); <br>    CAutoLock l(&amp;m_cSharedState); <br>    ASSERT(pAlloc); <br>    ASSERT(pProperties); <br>    HRESULT hr = NOERROR; <br> <br>    // use the app's numbers, if we were given some through IAMBufferNegotiation <br>    // otherwise, use some default <br> <br>    if (m_propSuggested.cBuffers &gt; 0) <br>        pProperties-&gt;cBuffers = m_propSuggested.cBuffers; <br>    else <br>        pProperties-&gt;cBuffers = 32;// !!!or whatever <br> <br>    if (m_propSuggested.cbBuffer &gt; 0) <br>        pProperties-&gt;cbBuffer = m_propSuggested.cbBuffer; <br>    else <br>        pProperties-&gt;cbBuffer = m_mt.lSampleSize; <br> <br>    if (m_propSuggested.cbAlign &gt; 0) <br>        pProperties-&gt;cbAlign = m_propSuggested.cbAlign; <br> <br>    if (m_propSuggested.cbPrefix &gt; 0) <br>        pProperties-&gt;cbPrefix = m_propSuggested.cbPrefix; <br> <br>    ASSERT(pProperties-&gt;cbBuffer); <br> <br>    // Ask the allocator to reserve us some sample memory, NOTE the function <br>    // can succeed (that is return NOERROR) but still not have allocated the <br>    // memory that we requested, so we must check we got whatever we wanted <br> <br>    ALLOCATOR_PROPERTIES Actual; <br>    hr = pAlloc-&gt;SetProperties(pProperties,&amp;Actual); <br>    if (SUCCEEDED(hr)) { <br> <br>        // Is this allocator unsuitable <br>        if (Actual.cbBuffer &lt; pProperties-&gt;cbBuffer) { <br>            hr = E_FAIL; <br>        } <br> <br>// remember what properties the allocator is using... somebody <br>// might ask later <br>m_propActual = Actual; <br>    } <br>    return hr; <br>} <br> <br> <br>// <br>// GetSampleSize <br>// <br>// Given a BITMAPINFOHEADER, calculates the sample size needed. <br>long CVidStream::GetSampleSize(LPBITMAPINFOHEADER pbmi) { <br> <br>    long lSize; <br> <br>    if (pbmi-&gt;biSizeImage &gt; 0) { <br> <br>        lSize = pbmi-&gt;biSizeImage; <br> <br>    } <br>    else {      // biSizeImage is allowed to be zero for uncompressed formats, <br>                // so do the maths ourselves... <br> <br>        lSize = (pbmi-&gt;biWidth * <br>                 pbmi-&gt;biHeight * <br>                 pbmi-&gt;biBitCount) / 8 + 1; <br>        if (lSize &lt; 0) { // biHeight was negative <br>            lSize *= -1; <br>        } <br>    } <br> <br>    // round up to nearest DWORD <br>    int rem = lSize % sizeof(DWORD); <br>    if (rem) <br>        lSize += sizeof(DWORD) - rem; <br> <br>    return lSize; <br>} <br> <br> <br>// <br>// CreateCaptureWindow <br>// <br>// Create a hidden AVICap window, and make sure it is configured appropriately <br>// Returns NULL on failure. <br>// successful calls should be balanced with calls to DestroyCaptureWindow() <br>// Creates the AVICap window with (up to) lBufferCount no. of buffers. <br>// use lBufferCount = 0, when you only wish to interrgoate the the driver, or <br>// specify a number of buffers, if you actually want to capture. <br>// <br>HWND CVidStream::CreateCaptureWindow(long lBufferCount) <br>{ <br> <br>    CAutoLock lock(&amp;m_cSharedState); <br> <br>    BOOL bErr;  //return code of capXXX calls <br> <br>    HWND hwndCapture;   // The window to return <br> <br>    hwndCapture = capCreateCaptureWindow(NULL,       // No name <br>                                         0,          // no style. <br>                                                     // defaults to invisible <br>                                         0, 0, 150, 150, // an arbitrary size <br>                                         0,          // no parent <br>                                         0);         // don't care about the id <br> <br>    if (!hwndCapture) { <br>        DbgLog((LOG_ERROR|LOG_TRACE, 1, TEXT("Window could not be created") )); <br>        return NULL; <br>    } <br> <br>    bErr = capDriverConnect(hwndCapture, m_uiDriverIndex); <br>    if (!bErr) { <br>        DestroyWindow(hwndCapture); <br>        DbgLog((LOG_ERROR|LOG_TRACE, 1, TEXT("Driver failed to connect") ) ); <br>        return NULL; <br>    } <br>    DbgLog((LOG_TRACE, 2, TEXT("Driver Connected") )); <br> <br>    CAPTUREPARMS cp; <br>    capCaptureGetSetup(hwndCapture, &amp;cp, sizeof(cp) ); // get the current defaults <br> <br>    cp.dwRequestMicroSecPerFrame = m_dwMicroSecPerFrame; // Set desired frame rate <br>    cp.fMakeUserHitOKToCapture   = FALSE; <br>    cp.fYield                    = TRUE;                 // we want capture on a <br>                                                         // background thread. <br>    cp.wNumVideoRequested        = (WORD) lBufferCount;  // we may get less than <br>                                                         // this - no problem <br>    cp.fCaptureAudio             = FALSE; <br>    cp.vKeyAbort                 = 0;                    // If no key is provided, <br>                                                         // it won't stop... <br>    cp.fAbortLeftMouse           = FALSE; <br>    cp.fAbortRightMouse          = FALSE; <br>    cp.fLimitEnabled             = FALSE;                // we want to stop <br>    cp.fMCIControl               = FALSE; <br> <br>    capCaptureSetSetup(hwndCapture, &amp;cp, sizeof(cp) ); <br> <br>    capSetCallbackOnVideoStream(hwndCapture, &amp;VideoCallback); <br>    capSetCallbackOnFrame(hwndCapture, &amp;VideoCallback);  // also use for single <br>                                                         // frame capture <br> <br>#if 0 <br>    CAPSTATUS    cs; <br>    ZeroMemory(&amp;cs, sizeof(cs)); <br>    capGetStatus(hwndCapture, &amp;cs, sizeof(cs)); <br> <br>    // try to see if the driver uses palettes <br>    if (((cs.hPalCurrent != NULL) || (cs.fUsingDefaultPalette))) { <br>m_UsesPalettes = TRUE; <br>    } else { <br>        m_UsesPalettes = FALSE; <br>    } <br>    if (m_UsesPalettes &amp;&amp; m_SuppliesPalettes) { <br>capPaletteAuto(hwndCapture, 10, 236); <br>    } <br>#endif <br> <br>    SetWindowLong(hwndCapture, GWL_USERDATA, (LONG) this); <br> <br>    return hwndCapture; <br>} <br> <br> <br>// <br>// DestroyCaptureWindow() <br>// <br>// Disconnect the driver before destroying the window. <br>BOOL CVidStream::DestroyCaptureWindow(HWND hwnd) <br>{ <br> <br>    ASSERT(hwnd != NULL); <br> <br>    // !!! why is this failing? <br>    BOOL bDriverDisconnected = capDriverDisconnect(hwnd); <br>    DbgLog(( LOG_ERROR|LOG_TRACE, 2 <br>           , TEXT("Driver disconnect: %x"), bDriverDisconnected) ); <br> <br>    BOOL bWindowGone = DestroyWindow(hwnd); <br>    DbgLog((LOG_ERROR|LOG_TRACE, 2, TEXT("Window destroy: %x"), bWindowGone) ); <br> <br>    return (bDriverDisconnected &amp;&amp; bWindowGone); <br>} <br> <br> <br>// <br>// VideoCallback <br>// <br>// The AVICap Video callback. Keep a copy of the buffer we are given <br>// May be called after the worker thread, or even the pin has gone away, <br>// depending on AVICap's internal timing. Therefore be very careful with the <br>// pointers we use. <br>// <br>LRESULT CALLBACK CVidStream::VideoCallback(HWND hwnd, LPVIDEOHDR lpVHdr) <br>{ <br> <br>    CVidStream *pThis = (CVidStream *) GetWindowLong(hwnd, GWL_USERDATA); <br> <br>    ASSERT(pThis); <br> <br>    if (pThis-&gt;m_plFilled == NULL) {    // The filled list has gone away. <br>                                        // ignore this buffer <br>        return (LRESULT) TRUE; <br>    } <br>    else { <br>        pThis-&gt;m_plFilled-&gt;Add(lpVHdr); <br>    } <br> <br>    //DbgLog((LOG_TRACE,5,TEXT("Got a buffer back!"))); <br> <br>    return (LRESULT) TRUE; <br>} <br> <br> <br> <br>// Override to handle quality messages <br>STDMETHODIMP CVidStream::Notify(IBaseFilter * pSender, Quality q) <br>{ <br>    // if q.Late.RefTime.QuadPart &gt;0 then skip ahead that much. <br>    // thereafter adjust the time per frame by a factor of <br>    // 1000/q.Proportion (watch for truncation of fractions <br>    // do the multiply first! <br> <br>    // Not Yet Implemented :-) <br> <br>    return NOERROR; <br>} <br> <br>// CSource expects all its pins to derive from CSourceStream. Since <br>// this sample doesn't do this, we implment QueryId here and FindPin <br>// on the filter to provide matching implementations <br> <br>STDMETHODIMP CVidStream::QueryId( <br>    LPWSTR * Id) <br>{ <br>    return CBaseOutputPin::QueryId(Id); <br>} <br> <br> <br> <br> <br>// <br>// DoBufferProcessingLoop <br>// <br>// Replace the loop in CSourceStream with something of my own, so that I can <br>// wait for buffers &amp; commands. <br>HRESULT CVidStream::DoBufferProcessingLoop(void) { <br> <br>    DbgLog((LOG_TRACE,2,TEXT("*** Entering DoBufferProcessingLoop"))); <br> <br>    HANDLE haWaitObjects[2]; <br>    { <br>        CAutoLock l(&amp;m_cSharedState); <br> <br>        haWaitObjects[0] = GetRequestHandle();  // command handle first so that <br>                                                // it has priority over buffers <br>        haWaitObjects[1] = m_plFilled-&gt;GetWaitHandle(); <br>    } <br> <br>    for (;;) { <br> <br>        // wait for commands or buffers.  This thread created the capture <br>// window, so we have to dispatch messages frequently on this thread <br>// or any other thread sending any message to the capture window will <br>// hang <br>// !!! It's more efficient to use MsgWaitForMultipleObjects, I know <br>        DWORD dwWaitObject <br>            = WaitForMultipleObjects(2, haWaitObjects, FALSE, 50); <br> <br>if (dwWaitObject == WAIT_TIMEOUT) { <br>    MSG msg; <br>    while (PeekMessage(&amp;msg, NULL, 0, 0, PM_REMOVE)) { <br>TranslateMessage(&amp;msg); <br>DispatchMessage(&amp;msg); <br>    } <br>} else if (dwWaitObject == WAIT_OBJECT_0) {    // thread command request <br> <br>    Command com; <br> <br>            EXECUTE_ASSERT(CheckRequest(&amp;com)); <br>            switch (com) { <br>            case CMD_RUN: <br> <br>com = GetRequest(); <br> <br>                if (m_ThreadState != Running) { <br>                    DbgLog((LOG_TRACE,1,TEXT("*** STARTING CAPTURE"))); <br>    // !!! This function may take a while to initialize  <br>    // capture, so we may not start seeing frames for 1/3 of <br>    // a second or so.  Unfortunately, unless we want a dialog <br>    // box to pop up saying "press OK to start" there's no good <br>    // way of starting capture at any known point in time <br>                    capCaptureSequenceNoFile(m_hwCapCapturing); <br>                } <br>                m_ThreadState = Running; <br>                Reply(NOERROR); <br>                break; <br> <br>            case CMD_PAUSE: <br> <br>                DbgLog((LOG_TRACE,1,TEXT("CMD_PAUSE"))); <br> <br>com = GetRequest(); <br> <br>                switch (m_ThreadState) { <br>                case Stopped: <br>    // first thing sent will be a discontinuity <br>    m_plFilled-&gt;m_fLastSampleDiscarded = TRUE; <br> <br>    // init our time stamping variables <br>    m_plFilled-&gt;m_rtLastStartTime = -1; <br>    m_plFilled-&gt;m_llLastFrame = -1; <br>    m_plFilled-&gt;m_llFrameOffset = 0; <br>    m_plFilled-&gt;m_fReRun = FALSE; <br> <br>    m_ThreadState = Paused; // mark that we are paused <br>                    break; <br>                case Running: <br>                    DbgLog((LOG_TRACE,1,TEXT("*** STOPPING CAPTURE"))); <br>    // we just went from RUN to PAUSE.  If we go to <br>    // RUN again without STOPping first, we will be in <br>    // a situation where the graph was run-&gt;pause-&gt;run <br>    m_plFilled-&gt;m_fReRun = TRUE; <br>                    capCaptureStop(m_hwCapCapturing); <br>                    break; <br>                default: <br>                    // null op <br>                    break; <br>                } <br>                m_ThreadState = Paused; <br>                Reply(NOERROR); <br>                break; <br> <br>            case CMD_STOP: <br> <br>                if (m_ThreadState == Running) { <br>                    DbgLog((LOG_TRACE,1,TEXT("*** STOPPING CAPTURE"))); <br>                    capCaptureStop(m_hwCapCapturing); <br>                } <br>                m_ThreadState = Stopped; <br>                //DbgLog((LOG_TRACE, 1, TEXT("Seen Stop command"))); <br>                // don't reply here as that is done by CSourceStream <br>                return NOERROR; <br> <br>            default: <br> <br>                ASSERT(!"Unexpected thread command"); <br>com = GetRequest(); <br>                break; <br>            } <br> <br>        } else if (dwWaitObject == (WAIT_OBJECT_0 + 1)) { // m_plFilled <br> <br>            // Process the buffer we've just been signalled on <br>            IMediaSample *pSample; <br> <br>            // get a buffer to put this video data in <br>            HRESULT hr = GetDeliveryBuffer(&amp;pSample,NULL,NULL,0); <br>            if (FAILED(hr)) { <br>                continue; <br>            } <br> <br>            hr = FillBuffer(pSample); <br> <br>    // !!! If this fails, we're supposed to stop delivering <br>            Deliver(pSample); <br> <br>            pSample-&gt;Release(); <br> <br>        } else {  // get out - otherwise we will infinite loop... <br> <br>            DbgLog((LOG_TRACE, 1 <br>                   , TEXT("Unexpected buffer/command wait return: %d") <br>                   , dwWaitObject)); <br>            return E_UNEXPECTED; <br>        } <br>    } <br> <br>    ASSERT(m_ThreadState == Stopped); <br> <br>    return NOERROR; <br>} <br> <br> <br>// <br>// FillBuffer <br>// <br>// Take the buffer from the head of the video buffer list. <br>// We will only be called when there is such a buffer <br>// <br>HRESULT CVidStream::FillBuffer(IMediaSample *pSample) { <br> <br>    CAutoLock l(&amp;m_cSharedState); <br> <br>    HRESULT hr = m_plFilled-&gt;RemoveHeadIntoSample(pSample); <br> <br>    return hr; <br>} <br> <br> <br> <br>// <br>// NonDelegatingQueryInterface <br>// <br>// Expose all of our interfaces on the pin <br>// <br>STDMETHODIMP CVidStream::NonDelegatingQueryInterface(REFIID riid, void ** ppv) <br>{ <br>    CheckPointer(ppv,E_POINTER); <br> <br>    if (riid == IID_IAMStreamControl) { <br>return GetInterface((LPUNKNOWN)(IAMStreamControl *)this, ppv); <br>    } else if (riid == IID_IAMStreamConfig) { <br>return GetInterface((LPUNKNOWN)(IAMStreamConfig *)this, ppv); <br>    } else if (riid == IID_IAMVideoCompression) { <br>return GetInterface((LPUNKNOWN)(IAMVideoCompression *)this, ppv); <br>    } else if (riid == IID_IAMDroppedFrames) { <br>return GetInterface((LPUNKNOWN)(IAMDroppedFrames *)this, ppv); <br>    } else if (riid == IID_IAMBufferNegotiation) { <br>return GetInterface((LPUNKNOWN)(IAMBufferNegotiation *)this, ppv); <br>    } else if (riid == IID_IKsPropertySet) { <br>return GetInterface((LPUNKNOWN)(IKsPropertySet *)this, ppv); <br>    } <br> <br>    return CSourceStream::NonDelegatingQueryInterface(riid, ppv); <br>} <br> <br> <br>// * <br>// * CVideoBufferList <br>// * <br> <br> <br>// <br>// CVideoBufferList::Constructor <br>// <br>CVideoBufferList::CVideoBufferList( int iBufferSize <br>                                  , DWORD dwMicroSecPerFrame <br>                                  , CVidCap *pFilter <br>                                  , int iBuffers <br>                                  ) <br>    :m_dwMicroSecPerFrame(dwMicroSecPerFrame), <br>     m_FirstBuffer(TRUE), <br>     m_pFilter(pFilter), <br>     m_evList(TRUE), <br>     m_iPreviewCount(0), <br>     m_lFilled(NAME("Pending, full, buffers"), <br>               DEFAULTCACHE),   // default cache <br>     m_lFree(NAME("Empty buffers"), <br>               DEFAULTCACHE)    // default cache <br>{ <br>    for (int i=0; i &lt; iBuffers; i++) { <br> <br>        CBuffer *pBuffer = new CBuffer(iBufferSize); <br>        if (pBuffer == NULL) { <br>            return; <br>        } <br>        m_lFree.AddTail(pBuffer); <br> <br>    } <br>} <br> <br> <br>// <br>// CVideoBufferList::Destructor <br>// <br>CVideoBufferList::~CVideoBufferList() { <br> <br>    while (m_lFree.GetCount() &gt; 0) {            // free buffers on the free list... <br> <br>        CBuffer *pBuff = m_lFree.RemoveHead(); <br>        delete pBuff; <br>    } <br> <br> <br>    DbgLog((LOG_TRACE, 1 <br>           , TEXT("Filled frames not sent before stop issued: %d") <br>           , m_lFilled.GetCount())); <br> <br>    while (m_lFilled.GetCount() &gt; 0) { //... then free buffers on filled list <br>                                       // - we don't care about the data they hold. <br> <br>        CBuffer *pBuff = m_lFilled.RemoveHead(); <br>        delete pBuff; <br>    } <br>} <br> <br> <br>// <br>// Add <br>// <br>// Add a video buffer to this list. gets a free buffer from m_lFree, copies <br>// the video data into it and then puts it on m_lFilled. <br>// if m_lFree is empty, fail silently, effectively skipping the buffer. <br>HRESULT CVideoBufferList::Add(LPVIDEOHDR lpVHdr) { <br> <br>    CAutoLock lck(&amp;m_ListCrit); <br>    CRefTime rt; <br> <br>    //DbgLog((LOG_TRACE,4,TEXT("driver time: %dms"), lpVHdr-&gt;dwTimeCaptured)); <br> <br>    // Time stamp this sample with the graph's clock time when this sample <br>    // is captured. (no clock? use the driver time) <br>    // !!! hopefully the driver latency isn't too bad! It should really be <br>    // compensated for <br>    if (FAILED(m_pFilter-&gt;StreamTime(rt)))// current time <br>        rt = CRefTime((LONG)lpVHdr-&gt;dwTimeCaptured);    // init with ms <br> <br>    // now ask IAMStreamControl if we need to bother delivering this sample <br>    // I don't have a sample around right now, so I'll make up one.  All it <br>    // needs is the time stamp. <br>    // !!! this is kinda hacky <br>    CMemAllocator all(TEXT("Test"), NULL, NULL); <br>    CMediaSample Sample(NULL, &amp;all, NULL); <br>    CRefTime rtEnd = rt + CRefTime((LONGLONG)m_dwMicroSecPerFrame * 10); <br>    Sample.SetTime((REFERENCE_TIME *)&amp;rt, (REFERENCE_TIME *)&amp;rtEnd); <br>    int iStreamState = m_pFilter-&gt;m_pCapturePin-&gt;CheckStreamState(&amp;Sample); <br>    if (iStreamState == m_pFilter-&gt;m_pCapturePin-&gt;STREAM_FLOWING) { <br>  // DbgLog((LOG_TRACE,3,TEXT("*VIDCAP ON"))); <br>    } else { <br>  // DbgLog((LOG_TRACE,3,TEXT("*VIDCAP OFF"))); <br>  m_fLastSampleDiscarded = TRUE;// next one is discontinuity <br>    } <br> <br>    // we are faking up a preview pin and supposed to send it a frame to <br>    // give out every once in a while when we have free time and copying <br>    // the data for preview will NOT HURT CAPTURE PERFORMANCE.  Well, if <br>    // our capture pin is currently off, we have nothing to lose.  If <br>    // we have no frames on the filled list pending delivery, we'll assume <br>    // we have spare time and can afford to send a preview frame.  In any <br>    // case, send a preview frame at least once every 30 frames. (!!!) <br>    // !!! Ideally, we don't necessarily want to send this frame as a preview, <br>    // it may be many seconds old if we have lots of buffering, we want to <br>    // send the most recently captured frame.  I don't do that here. <br>    if (m_pFilter-&gt;m_pPreviewPin) { <br>if (iStreamState == m_pFilter-&gt;m_pCapturePin-&gt;STREAM_DISCARDING || <br>m_lFilled.GetCount() == 0 || m_iPreviewCount++ == 30) { <br>    m_iPreviewCount = 0;// reset <br>    m_pFilter-&gt;m_pPreviewPin-&gt;ReceivePreviewFrame(lpVHdr-&gt;lpData, <br>lpVHdr-&gt;dwBufferLength); <br>} <br>    } <br> <br>    // what frame number is this (based on the time captured)?  Round <br>    // such that if frames 1 and 2 are expected at 33 and 66ms, anything <br>    // from 17 to 49 will be considered frame 1. <br>    // <br>    // frame = (us + 1/2(us per frame)) / (us / frame) <br>    // <br>    // then we add an offset if we so desire <br>    // <br>    LONGLONG llFrame = ((lpVHdr-&gt;dwTimeCaptured * 1000 + <br>m_dwMicroSecPerFrame / 2) / m_dwMicroSecPerFrame) <br>+ m_llFrameOffset; <br> <br>    // NOTE:  If the graph is RUN-&gt;PAUSE-&gt;RUN again we need to <br>    // continue sending frame numbers (in the MediaTime) where we <br>    // left off before pausing.  BUT... the driver has been stopped <br>    // and started and is numbering the frames back at zero again! <br>    // So we need to notice that the graph has been paused and re-run <br>    // without stopping in between, and then add as an offset to all <br>    // future frame numbers, the last frame number sent before the <br>    // pause. <br>    if (m_fReRun &amp;&amp; llFrame &lt; m_llLastFrame) { <br>m_llFrameOffset = m_llLastFrame; <br>llFrame += m_llFrameOffset; <br>m_fReRun = FALSE; <br>    } <br> <br>    // the time stamps we get from the drivers are not always accurate, <br>    // and we may think we see frame 0, 2, 2, 3, 5, 5, 6, 7, but if <br>    // we just pretended the first 2 was frame 1 and the first 5 was <br>    // frame 4, we wouldn't skip any frames or send the same frame <br>    // twice <br>    if (llFrame == m_llLastFrame + 2) <br>llFrame -= 1; <br> <br>    // we're supposed to deliver this frame, and we can <br>    if (iStreamState == m_pFilter-&gt;m_pCapturePin-&gt;STREAM_FLOWING &amp;&amp; <br>m_lFree.GetCount() &gt; 0) { <br> <br>// Never send something backwards in time from the last thing <br>// sent.  This can happen with live sources if you run, then <br>// pause, then run the graph again.  The first time stamp after <br>// the second run might have a time less than the last time stamp <br>// delivered before the pause.  Also, because the graph is run <br>// 50ms or so before time 0, it's possible for a frame captured <br>// right away to have a time stamp less than zero.  We don't want <br>// to deliver such samples, but we don't want to consider them <br>// dropped frames either.  We just pretend they never existed. </code></pre>
<p>
</p>
<pre><code>if (rt &gt;= 0 &amp;&amp; rt &gt;= m_rtLastStartTime) { <br> <br>    // Just like above, where we didn't deliver or skip any frame <br>    // whose time stampes seemed to go backwards in time, we can't <br>    // deliver a frame whose MediaTime stamps don't increase <br>    // monotonically.  We don't want to deliver a duplicate media time <br>    // that we already sent, but we don't want to consider them <br>    // dropped frames either.  We just pretend they never existed. <br>    if (llFrame &gt; m_llLastFrame) { <br> <br>// oops, this frame number is more than one frame later than <br>// the last frame; we've skipped some frames, probably due <br>// to starving the driver who couldn't capture in time <br>if (llFrame &gt; m_llLastFrame + 1) { <br>            m_pFilter-&gt;m_pCapturePin-&gt;m_uiFramesSkipped +=  <br>(DWORD)(llFrame - m_llLastFrame - 1); <br>} <br> <br>                CBuffer *pBuff = m_lFree.RemoveHead(); <br>                pBuff-&gt;CopyBuffer(lpVHdr, rt, llFrame); <br> <br>        // remember how to set the sample flags later <br>        pBuff-&gt;m_fSyncPoint = lpVHdr-&gt;dwFlags &amp; VHDR_KEYFRAME; <br>        // !!! Technically speaking, you should set a discontinuity <br>        // after you drop (skip) a frame, too, but I'm probably dealing <br>        // with all keyframes and it doesn't matter so much if a frame <br>        // is skipped <br>        pBuff-&gt;m_fDiscontinuity = m_fLastSampleDiscarded; <br> <br>                m_lFilled.AddTail(pBuff); <br>                if (m_lFilled.GetCount() == 1) { <br>                    m_evList.Set(); <br>                } <br>                m_pFilter-&gt;m_pCapturePin-&gt;m_uiFramesCaptured++; <br>         m_fLastSampleDiscarded = FALSE; <br> <br>        // remember the last Time and MediaTime we used <br>        m_rtLastStartTime = rt; <br>        m_llLastFrame = llFrame; <br>    } <br>} <br> <br>    // we're supposed to deliver this frame, but we can't... it's skipped <br>    } else if (iStreamState == m_pFilter-&gt;m_pCapturePin-&gt;STREAM_FLOWING) { <br> <br>        m_pFilter-&gt;m_pCapturePin-&gt;m_uiFramesSkipped++; <br> <br>    // we are discarding this frame.  Don't count it as captured or skipped <br>    // We must make a note that we've seen this frame, so we don't think that <br>    // we skipped all the frames we didn't send because stream control was off <br>    } else { <br>m_llLastFrame = llFrame; <br>    } <br> <br>    return NOERROR; <br>} <br> <br> <br>// <br>// RemoveHeadIntoSample <br>// <br>// Copy the head of the filled list into the supplied IMediaSample. <br>// Fail with E_UNEXPECTED if called on an empty m_lFilled; <br>// return S_FALSE if you don't want the sample delivered <br>// <br>HRESULT CVideoBufferList::RemoveHeadIntoSample(IMediaSample *pSample) <br>{ <br>    HRESULT hr; <br>    CAutoLock lck(&amp;m_ListCrit); <br> <br>    if (m_lFilled.GetCount() &lt; 1) { <br>        hr = E_UNEXPECTED; <br>    } else { <br> <br>        CBuffer *pBuff = m_lFilled.RemoveHead(); <br>        if (m_lFilled.GetCount() == 0) { <br>            m_evList.Reset(); <br>        } <br> <br>        BYTE *pSampleBuffer; <br>        hr = pSample-&gt;GetPointer(&amp;pSampleBuffer); <br>        if (SUCCEEDED(hr)) { <br> <br>    LONG lSampleSize = pBuff-&gt;GetSize(); <br>            ASSERT(pBuff-&gt;GetSize() &lt;= pSample-&gt;GetSize()); <br> <br>    // Copy the captured data <br>            CopyMemory((void *)pSampleBuffer, pBuff-&gt;GetPointer(), lSampleSize); <br> <br>            // set all the sample flags <br>    pSample-&gt;SetActualDataLength(lSampleSize); <br>          pSample-&gt;SetSyncPoint(pBuff-&gt;m_fSyncPoint); <br>          pSample-&gt;SetDiscontinuity(pBuff-&gt;m_fDiscontinuity); <br>          pSample-&gt;SetPreroll(FALSE); <br> <br> <br>            FILTER_STATE State; <br>            m_pFilter-&gt;GetState(0, &amp;State); <br> <br>            CRefTime rtStart; <br> <br>    // set the time stamp of this sample <br>     rtStart = pBuff-&gt;GetCaptureTime(); <br>            CRefTime rtEnd = rtStart + CRefTime((LONGLONG)m_dwMicroSecPerFrame * <br>10); <br>            DbgLog((LOG_TRACE,4,TEXT("Sample Time: %dms %dms"), <br>rtStart.Millisecs(), rtEnd.Millisecs())); <br>            ASSERT(rtStart &lt;= rtEnd); <br>            pSample-&gt;SetTime((REFERENCE_TIME*)&amp;rtStart, <br>                             (REFERENCE_TIME*)&amp;rtEnd); <br> <br>    // also set the media time... which is supposed to be the <br>    // frame number <br>     LONGLONG llFrame = pBuff-&gt;GetCaptureFrame(); <br>    LONGLONG llFrameE = llFrame + 1; <br>            pSample-&gt;SetMediaTime(&amp;llFrame, &amp;llFrameE); <br>            DbgLog((LOG_TRACE,4,TEXT("Media Time: %d"),llFrame)); <br> <br>            m_pFilter-&gt;m_pCapturePin-&gt;m_uiFramesDelivered++; <br>            m_pFilter-&gt;m_pCapturePin-&gt;m_llTotalFrameSize += lSampleSize; <br>            m_lFree.AddTail(pBuff); <br>        } <br>    } <br> <br>    return hr; <br>} <br> <br> <br>// <br>// CBuffer::Constructor <br>// <br>//Get a new buffer of the maximum size we will handle <br>CVideoBufferList::CBuffer::CBuffer(int iBufferSize) { <br> <br>    m_pData = new BYTE[iBufferSize]; <br> <br>    // Set the two length fields to the maximum size <br>    m_iCaptureDataLength = m_iDataLength = iBufferSize; <br> <br>} <br> <br> <br>// <br>// CVideoDataBuffer::Destructor <br>// <br>CVideoBufferList::CBuffer::~CBuffer() { <br> <br>    delete m_pData; <br>} <br> <br> <br>// <br>// CopyBuffer <br>// <br>// Copy the supplied data in lpVHdr-&gt;lpData to this Buffer <br>// rt is the time stamp <br>void CVideoBufferList::CBuffer::CopyBuffer(LPVIDEOHDR lpVHdr, CRefTime&amp; rt, LONGLONG llFrame) { <br> <br>    ASSERT((DWORD) m_iDataLength &gt;= lpVHdr-&gt;dwBufferLength); <br> <br>    m_rt = rt;// time stamp <br>    m_llFrame = llFrame;// frame number <br> <br>    // Copy the captured video buffer, and remember its length <br>    CopyMemory(m_pData, lpVHdr-&gt;lpData, (m_iCaptureDataLength = lpVHdr-&gt;dwBufferLength)); <br> <br>} <br> <br> <br> <br>// Reconnect our pin.  We would like to change our output format <br>// Sometimes extra filters have to be placed in between, like when you <br>// switch from 8 bit to 16 bit RGB and you have to put a colour converter <br>// between you and the renderer you were connected to.  In this case, <br>// reconnect won't work, you have to explicitly intelligently connect <br>// them yourself. <br>// <br>void CVidStream::Reconnect(BOOL fCapturePinToo) <br>{ <br>    if (IsConnected() &amp;&amp; fCapturePinToo) { <br>        DbgLog((LOG_TRACE,1,TEXT("Need to reconnect our streaming pin"))); <br>        CMediaType cmt; <br>GetMediaType(&amp;cmt); <br>if (S_OK == GetConnected()-&gt;QueryAccept(&amp;cmt)) { <br>            ((CVidCap *)m_pFilter)-&gt;m_pGraph-&gt;Reconnect(this); <br>} else { <br>            // This will fail if we switch from 8 bit to 16 bit RGB connected <br>            // to a renderer that needs a colour converter inserted to do 16 bit <br>    // Oh boy.  We're going to have to get clever and insert some <br>    // filters between us to help us reconnect <br>            DbgLog((LOG_TRACE,1,TEXT("Whoa! We *really* need to reconnect!"))); <br>    IPin *pCon = GetConnected(); <br>    pCon-&gt;AddRef();// or it will go away in Disconnect <br>    ((CVidCap *)m_pFilter)-&gt;m_pGraph-&gt;Disconnect(GetConnected()); <br>    ((CVidCap *)m_pFilter)-&gt;m_pGraph-&gt;Disconnect(this); <br>    IGraphBuilder *pFG; <br>    HRESULT hr = ((CVidCap *)m_pFilter)-&gt;m_pGraph-&gt;QueryInterface( <br>IID_IGraphBuilder, (void **)&amp;pFG); <br>    if (hr == NOERROR) { <br>        hr = pFG-&gt;Connect(this, pCon); <br>pFG-&gt;Release(); <br>    } <br>    pCon-&gt;Release(); <br>    if (hr != NOERROR) <br>                DbgLog((LOG_ERROR,1,TEXT("*** RECONNECT FAILED! ***"))); <br>    // !!! We need to notify application that graph is different <br> } <br> // when this pin gets reconnected it will call us again to do the <br> // other two pins <br> return; <br>    } <br> <br>    // Now reconnect the overlay pin <br>    CVidOverlay *pOverlayPin = ((CVidCap *)m_pFilter)-&gt;m_pOverlayPin; <br>    if (pOverlayPin &amp;&amp; pOverlayPin-&gt;IsConnected()) { <br>        DbgLog((LOG_TRACE,1,TEXT("Need to reconnect our overlay pin"))); <br>        CMediaType cmt; <br>pOverlayPin-&gt;GetMediaType(0, &amp;cmt); <br>if (S_OK == pOverlayPin-&gt;GetConnected()-&gt;QueryAccept(&amp;cmt)) { <br>    ((CVidCap *)m_pFilter)-&gt;m_pGraph-&gt;Reconnect(pOverlayPin); <br>} else { <br>    // Huh? <br>    ASSERT(FALSE); <br>} <br>    } <br> <br>    // Now reconnect the non-overlay preview pin <br>    CVidPreview *pPreviewPin = ((CVidCap *)m_pFilter)-&gt;m_pPreviewPin; <br>    if (pPreviewPin &amp;&amp; pPreviewPin-&gt;IsConnected()) { <br>        DbgLog((LOG_TRACE,1,TEXT("Need to reconnect our preview pin"))); <br>        CMediaType cmt; <br>pPreviewPin-&gt;GetMediaType(0, &amp;cmt); <br>if (S_OK == pPreviewPin-&gt;GetConnected()-&gt;QueryAccept(&amp;cmt)) { <br>    ((CVidCap *)m_pFilter)-&gt;m_pGraph-&gt;Reconnect(pPreviewPin); <br>} else { <br>    // Oh boy.  We're going to have to get clever and insert some <br>    // filters between us to help us reconnect <br>            DbgLog((LOG_TRACE,1,TEXT("Whoa! We *really* need to reconnect!"))); <br>    IPin *pCon = pPreviewPin-&gt;GetConnected(); <br>    pCon-&gt;AddRef();// or it will go away in Disconnect <br>    ((CVidCap *)m_pFilter)-&gt;m_pGraph-&gt;Disconnect( <br>pPreviewPin-&gt;GetConnected()); <br>    ((CVidCap *)m_pFilter)-&gt;m_pGraph-&gt;Disconnect(pPreviewPin); <br>    IGraphBuilder *pFG; <br>    HRESULT hr = ((CVidCap *)m_pFilter)-&gt;m_pGraph-&gt;QueryInterface( <br>IID_IGraphBuilder, (void **)&amp;pFG); <br>    if (hr == NOERROR) { <br>        hr = pFG-&gt;Connect(pPreviewPin, pCon); <br>pFG-&gt;Release(); <br>    } <br>    pCon-&gt;Release(); <br>    if (hr != NOERROR) <br>                DbgLog((LOG_ERROR,1,TEXT("*** RECONNECT FAILED! ***"))); <br>    // !!! We need to notify application that graph is different <br>} <br>    } <br>} <br> <br> <br> <br> <br>//============================================================================= <br> <br>// <br>// IAMStreamConfig stuff <br>// <br> <br> <br>// Tell the capture card to capture a specific format.  If it isn't connected, <br>// then it will use that format to connect when it does.  If already connected, <br>// then it will reconnect with the new format. <br>// <br>HRESULT CVidStream::SetFormat(AM_MEDIA_TYPE *pmt) <br>{ <br>    HRESULT hr; <br> <br>    if (pmt == NULL) <br>return E_POINTER; <br> <br>    // To make sure we're not in the middle of start/stop streaming <br>    CAutoLock lock(m_pFilter-&gt;pStateLock()); <br>    CAutoLock l(&amp;m_cSharedState); <br> <br>    DbgLog((LOG_TRACE,2,TEXT("IAMStreamConfig::SetFormat %x %dbit %dx%d"), <br>HEADER(pmt-&gt;pbFormat)-&gt;biCompression, <br>HEADER(pmt-&gt;pbFormat)-&gt;biBitCount, <br>HEADER(pmt-&gt;pbFormat)-&gt;biWidth, <br>HEADER(pmt-&gt;pbFormat)-&gt;biHeight)); <br> <br>    if (((CVidCap *)m_pFilter)-&gt;m_State != State_Stopped) <br>return E_UNEXPECTED; <br> <br>    // If this is the same format as we already are using, don't bother <br>    CMediaType mt; <br>    GetMediaType(&amp;mt); <br>    if (mt == *pmt) { <br>return NOERROR; <br>    } <br> <br>    // see if we like this type <br>    if ((hr = CheckMediaType((CMediaType *)pmt)) != NOERROR) { <br>DbgLog((LOG_TRACE,2,TEXT("SetFormat rejected"))); <br>return hr; <br>    } <br> <br>    // If we are connected to somebody, make sure they like it <br>    // !!! A video renderer might reject going to 16 bit from 8 bit, but <br>    // reconnecting would still work, by pulling in a colour converter <br>    if (IsConnected()) { <br>hr = GetConnected()-&gt;QueryAccept(pmt); <br>if (hr != NOERROR) { <br>    DbgLog((LOG_TRACE,2,TEXT("SetFormat rejected by the other pin"))); <br>    return E_INVALIDARG; <br>} <br>    } <br> <br>    // OK, we're using it <br>    hr = SetMediaType((CMediaType *)pmt); <br> <br>    // Changing the format means reconnecting if necessary <br>    if (hr == NOERROR) { <br>m_fSetFormatCalled = TRUE;// from now on, this is the format <br>// we must use <br>        Reconnect(TRUE); <br>    } <br> <br>    return hr; <br>} <br> <br> <br>// What format is the capture card capturing right now? <br>// The caller must free it with DeleteMediaType(*ppmt) <br>// <br>HRESULT CVidStream::GetFormat(AM_MEDIA_TYPE **ppmt) <br>{ <br>    DbgLog((LOG_TRACE,3,TEXT("IAMStreamConfig::GetFormat"))); <br> <br>    if (ppmt == NULL) <br>return E_POINTER; <br> <br>    *ppmt = (AM_MEDIA_TYPE *)CoTaskMemAlloc(sizeof(AM_MEDIA_TYPE)); <br>    if (*ppmt == NULL) <br>return E_OUTOFMEMORY; <br>    ZeroMemory(*ppmt, sizeof(AM_MEDIA_TYPE)); <br>    HRESULT hr = GetMediaType((CMediaType *)*ppmt); <br>    if (hr != NOERROR) { <br>CoTaskMemFree(*ppmt); <br>*ppmt = NULL; <br>return hr; <br>    } <br>    return NOERROR; <br>} <br> <br> <br>// <br>// <br>HRESULT CVidStream::GetNumberOfCapabilities(int *piCount, int *piSize) <br>{ <br>    DbgLog((LOG_TRACE,3,TEXT("IAMStreamConfig::GetNumberOfCapabilities"))); <br> <br>    if (piCount == NULL || piSize == NULL) <br>return E_POINTER; <br> <br>    *piCount = 0; <br>    *piSize = 0; <br> <br>    return NOERROR; <br>} <br> <br> <br>// find out some capabilities of this capture device <br>// <br>HRESULT CVidStream::GetStreamCaps(int i, AM_MEDIA_TYPE **ppmt, LPBYTE pSCC) <br>{ <br>    DbgLog((LOG_TRACE,3,TEXT("IAMStreamConfig::GetStreamCaps"))); <br> <br>    // sorry, I have no clue what to say <br>    return E_NOTIMPL; <br>} <br> <br> <br>//============================================================================= <br> <br>// IAMVideoCompression stuff <br> <br>// Get some information about the driver <br>// <br>HRESULT CVidStream::GetInfo(LPWSTR pszVersion, int *pcbVersion, LPWSTR pszDescription, int *pcbDescription, long *pDefaultKeyFrameRate, long *pDefaultPFramesPerKey, double *pDefaultQuality, long *pCapabilities) <br>{ <br>    DbgLog((LOG_TRACE,3,TEXT("IAMVideoCompression::GetInfo"))); <br> <br>    // we can't do anything programmatically <br>    if (pCapabilities) <br>        *pCapabilities = 0; <br>    if (pDefaultKeyFrameRate) <br>        *pDefaultKeyFrameRate = 0; <br>    if (pDefaultPFramesPerKey) <br>        *pDefaultPFramesPerKey = 0; <br>    if (pDefaultQuality) <br>        *pDefaultQuality = 0; <br> <br>    // we can give them a driver name and version <br>    if (pszVersion &amp;&amp; pcbVersion) <br>lstrcpynW(pszVersion, m_szVersion, *pcbVersion / 2); <br>    if (pszDescription &amp;&amp; pcbDescription) <br>lstrcpynW(pszDescription, m_szName, *pcbDescription / 2); <br> <br>    // return the number of bytes this unicode string is, incl. NULL char <br>    if (pcbVersion) <br>*pcbVersion = lstrlenW(m_szVersion) * 2 + 2; <br>    if (pcbDescription) <br>*pcbDescription = lstrlenW(m_szName) * 2 + 2; <br> <br>    return NOERROR; <br>} <br> <br> <br>//============================================================================= <br> <br>/* IAMDroppedFrames stuff */ <br> <br>// How many frames did we drop? <br>// <br>HRESULT CVidStream::GetNumDropped(long *plDropped) <br>{ <br>    DbgLog((LOG_TRACE,5,TEXT("IAMDroppedFrames::GetNumDropped - %d dropped"), <br>(int)m_uiFramesSkipped)); <br> <br>    if (plDropped == NULL) <br>return E_POINTER; <br> <br>    *plDropped = (long)m_uiFramesSkipped; <br>    return NOERROR; <br>} <br> <br> <br>// How many frames did we not drop? <br>// <br>HRESULT CVidStream::GetNumNotDropped(long *plNotDropped) <br>{ <br>    DbgLog((LOG_TRACE,5,TEXT("IAMDroppedFrames::GetNumNotDropped - %d not dropped"), <br>(int)m_uiFramesDelivered)); <br> <br>    if (plNotDropped == NULL) <br>return E_POINTER; <br> <br>    *plNotDropped = (long)m_uiFramesDelivered; <br>    return NOERROR; <br>} <br> <br> <br>// Which frames did we drop (give me up to lSize of them - we got lNumCopied) <br>// <br>HRESULT CVidStream::GetDroppedInfo(long lSize, long *plArray, long *plNumCopied) <br>{ <br>    DbgLog((LOG_TRACE,5,TEXT("IAMDroppedFrames::GetDroppedInfo"))); <br> <br>    return E_NOTIMPL;// !!! Do this someday? <br> <br>#if 0 <br>    if (lSize &lt;= 0) <br>return E_INVALIDARG; <br>    if (plArray == NULL || plNumCopied == NULL) <br>return E_POINTER; <br> <br>    *plNumCopied = min(lSize, NUM_DROPPED); <br>    *plNumCopied = (long)min(*plNumCopied, m_capstats.dwlNumDropped); <br> <br>    LONG l; <br>    for (l = 0; l &lt; *plNumCopied; l++) { <br>plArray[l] = (long)m_capstats.dwlDropped[l]; <br>    } <br> <br>    return NOERROR; <br>#endif <br>} <br> <br> <br>HRESULT CVidStream::GetAverageFrameSize(long *plAverageSize) <br>{ <br>    DbgLog((LOG_TRACE,5,TEXT("IAMDroppedFrames::GetAverageFrameSize - %d"), <br>m_uiFramesDelivered ? <br>(long)(m_llTotalFrameSize / m_uiFramesDelivered) <br>: 0)); <br> <br>    if (plAverageSize == NULL) <br>return E_POINTER; <br> <br>    *plAverageSize = m_uiFramesDelivered ? <br>(long)(m_llTotalFrameSize / m_uiFramesDelivered) <br>: 0; <br> <br>    return NOERROR; <br>} <br> <br> <br>/////////////////////////////// <br>// IAMBufferNegotiation methods <br>/////////////////////////////// <br> <br>// Somebody wants us to use allocator properties like these when we <br>// connect <br>// <br>HRESULT CVidStream::SuggestAllocatorProperties(const ALLOCATOR_PROPERTIES *pprop) <br>{ <br>    DbgLog((LOG_TRACE,2,TEXT("SuggestAllocatorProperties"))); <br> <br>    // to make sure we're not in the middle of connecting <br>    CAutoLock lock(m_pFilter-&gt;pStateLock()); <br>    CAutoLock l(&amp;m_cSharedState); <br> <br>    // sorry, too late, we've made up our mind already <br>    if (IsConnected()) <br>return E_UNEXPECTED; <br> <br>    m_propSuggested = *pprop; <br> <br>    DbgLog((LOG_TRACE,2,TEXT("cBuffers-%d  cbBuffer-%d  cbAlign-%d  cbPrefix-%d"), <br>pprop-&gt;cBuffers, pprop-&gt;cbBuffer, pprop-&gt;cbAlign, pprop-&gt;cbPrefix)); <br> <br>    return NOERROR; <br>} <br> <br> <br>// what properties is the allocator using right now? <br>// <br>HRESULT CVidStream::GetAllocatorProperties(ALLOCATOR_PROPERTIES *pprop) <br>{ <br>    DbgLog((LOG_TRACE,2,TEXT("GetAllocatorProperties"))); <br> <br>    // to make sure we're not in the middle of connecting <br>    CAutoLock lock(m_pFilter-&gt;pStateLock()); <br>    CAutoLock l(&amp;m_cSharedState); <br> <br>    // we are not connected... we have no allocator! <br>    if (!IsConnected()) <br>return E_UNEXPECTED; <br> <br>    if (pprop == NULL) <br>return E_POINTER; <br> <br>    // tell them what they've won, Johnny <br>    *pprop = m_propActual; <br> <br>    return NOERROR; <br>} <br> <br> <br>// <br>// PIN CATEGORIES - let the world know that we are a CAPTURE pin <br>// <br> <br>HRESULT CVidStream::Set(REFGUID guidPropSet, DWORD dwPropID, LPVOID pInstanceData, DWORD cbInstanceData, LPVOID pPropData, DWORD cbPropData) <br>{ <br>    return E_NOTIMPL; <br>} <br> <br>// To get a property, the caller allocates a buffer which the called <br>// function fills in.  To determine necessary buffer size, call Get with <br>// pPropData=NULL and cbPropData=0. <br>HRESULT CVidStream::Get(REFGUID guidPropSet, DWORD dwPropID, LPVOID pInstanceData, DWORD cbInstanceData, LPVOID pPropData, DWORD cbPropData, DWORD *pcbReturned) <br>{ <br>    if (guidPropSet != AMPROPSETID_Pin) <br>return E_PROP_SET_UNSUPPORTED; <br> <br>    if (dwPropID != AMPROPERTY_PIN_CATEGORY) <br>return E_PROP_ID_UNSUPPORTED; <br> <br>    if (pPropData == NULL &amp;&amp; pcbReturned == NULL) <br>return E_POINTER; <br> <br>    if (pcbReturned) <br>*pcbReturned = sizeof(GUID); <br> <br>    if (pPropData == NULL) <br>return S_OK; <br> <br>    if (cbPropData &lt; sizeof(GUID)) <br>return E_UNEXPECTED; <br> <br>    *(GUID *)pPropData = PIN_CATEGORY_CAPTURE; <br>    return S_OK; <br>} <br> <br> <br>// QuerySupported must either return E_NOTIMPL or correctly indicate <br>// if getting or setting the property set and property is supported. <br>// S_OK indicates the property set and property ID combination is <br>HRESULT CVidStream::QuerySupported(REFGUID guidPropSet, DWORD dwPropID, DWORD *pTypeSupport) <br>{ <br>    if (guidPropSet != AMPROPSETID_Pin) <br>return E_PROP_SET_UNSUPPORTED; <br> <br>    if (dwPropID != AMPROPERTY_PIN_CATEGORY) <br>return E_PROP_ID_UNSUPPORTED; <br> <br>    if (pTypeSupport) <br>*pTypeSupport = KSPROPERTY_SUPPORT_GET; <br>    return S_OK; <br>} </code></pre>
<p>&nbsp;</p></body>
</HTML>
