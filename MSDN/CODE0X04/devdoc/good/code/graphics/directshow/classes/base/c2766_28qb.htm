<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 3.2 Final//EN">
<HTML dir=ltr>
<HEAD>
<META HTTP-EQUIV="Content-Type" Content="text/html; charset=Windows-1252">
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-83731338-2"></script><script>  window.dataLayer = window.dataLayer || [];  function gtag(){dataLayer.push(arguments);}  gtag('js', new Date());  gtag('config', 'UA-83731338-2');</script><title>VTRANS.CPP</title>
<link disabled rel=stylesheet href=../../../../../../backsdk3.css>
<style type="text/css">
@import url(../../../../../../backsdk4.css);
</style>
</HEAD>
<BODY BGCOLOR = #FFFFFF TEXT = #000000>
<h2><a name="_code_context2783"></a>VTRANS.CPP</h2>
<pre><code>//==========================================================================; <br>// <br>//  THIS CODE AND INFORMATION IS PROVIDED "AS IS" WITHOUT WARRANTY OF ANY <br>//  KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE <br>//  IMPLIED WARRANTIES OF MERCHANTABILITY AND/OR FITNESS FOR A PARTICULAR <br>//  PURPOSE. <br>// <br>//  Copyright (c) 1992 - 1997  Microsoft Corporation.  All Rights Reserved. <br>// <br>//--------------------------------------------------------------------------; <br> <br>#include &lt;streams.h&gt; <br>#include &lt;measure.h&gt; <br>// #include &lt;vtransfr.h&gt;         // now in precomp file streams.h <br> <br>CVideoTransformFilter::CVideoTransformFilter <br>    ( TCHAR *pName, LPUNKNOWN pUnk, REFCLSID clsid) <br>    : CTransformFilter(pName, pUnk, clsid) <br>    , m_itrLate(0) <br>    , m_nKeyFramePeriod(0)      // No QM until we see at least 2 key frames <br>    , m_nFramesSinceKeyFrame(0) <br>    , m_bSkipping(FALSE) <br>    , m_tDecodeStart(0) <br>    , m_itrAvgDecode(300000)    // 30mSec - probably allows skipping <br>    , m_bQualityChanged(FALSE) <br>{ <br>#ifdef PERF <br>    RegisterPerfId(); <br>#endif //  PERF <br>} <br> <br> <br>CVideoTransformFilter::~CVideoTransformFilter() <br>{ <br>  // nothing to do <br>} <br> <br> <br>// Reset our quality management state <br> <br>HRESULT CVideoTransformFilter::StartStreaming() <br>{ <br>    m_itrLate = 0; <br>    m_nKeyFramePeriod = 0;       // No QM until we see at least 2 key frames <br>    m_nFramesSinceKeyFrame = 0; <br>    m_bSkipping = FALSE; <br>    m_tDecodeStart = 0; <br>    m_itrAvgDecode = 300000;     // 30mSec - probably allows skipping <br>    m_bQualityChanged = FALSE; <br>    m_bSampleSkipped = FALSE; <br>    return NOERROR; <br>} <br> <br> <br>// Overriden to reset quality management information <br> <br>HRESULT CVideoTransformFilter::EndFlush() <br>{ <br>    { <br>        //  Synchronize <br>        CAutoLock lck(&amp;m_csReceive); <br> <br>        // Reset our stats <br>        // <br>        // Note - we don't want to call derived classes here, <br>        // we only want to reset our internal variables and this <br>        // is a convenient way to do it <br>        CVideoTransformFilter::StartStreaming(); <br>    } <br>    return CTransformFilter::EndFlush(); <br>} <br> <br> <br>// Receive() <br>// <br>// Accept a sample from upstream, decide whether to process it <br>// or drop it.  If we process it then get a buffer from the <br>// allocator of the downstream connection, transform it into the <br>// new buffer and deliver it to the downstream filter. <br>// If we decide not to process it then we do not get a buffer. <br> <br>HRESULT CVideoTransformFilter::Receive(IMediaSample *pSample) <br>{ <br>    // If the next filter downstream is the video renderer, then it may <br>    // be able to operate in DirectDraw mode which saves copying the data <br>    // and gives higher performance.  In that case the buffer which we <br>    // get from GetDeliveryBuffer will be a DirectDraw buffer, and <br>    // drawing into this buffer draws directly onto the display surface. <br>    // This means that any waiting for the correct time to draw occurs <br>    // during GetDeliveryBuffer, and that once the buffer is given to us <br>    // the video renderer will count it in its statistics as a frame drawn. <br>    // This means that any decision to drop the frame must be taken before <br>    // calling GetDeliveryBuffer. <br> <br>    ASSERT(CritCheckIn(&amp;m_csReceive)); <br>    AM_MEDIA_TYPE *pmtOut, *pmt; <br>#ifdef DEBUG <br>    FOURCCMap fccOut; <br>#endif <br>    HRESULT hr; <br>    ASSERT(pSample); <br>    IMediaSample * pOutSample; <br> <br>    // If no output pin to deliver to then no point sending us data <br>    ASSERT (m_pOutput != NULL) ; <br> <br>    if (ShouldSkipFrame(pSample)) { <br>        MSR_NOTE(m_idSkip); <br>        m_bSampleSkipped = TRUE; <br>        return NOERROR; <br>    } <br> <br>    // Set up the output sample <br>    hr = InitializeOutputSample(pSample, &amp;pOutSample); <br> <br>    if (FAILED(hr)) { <br>        return hr; <br>    } <br> <br>    m_bSampleSkipped = FALSE; <br> <br> <br>    // The source filter may dynamically ask us to start transforming from a <br>    // different media type than the one we're using now.  If we don't, we'll <br>    // draw garbage. (typically, this is a palette change in the movie, <br>    // but could be something more sinister like the compression type changing, <br>    // or even the video size changing) <br> <br>#define rcS1 ((VIDEOINFOHEADER *)(pmt-&gt;pbFormat))-&gt;rcSource <br>#define rcT1 ((VIDEOINFOHEADER *)(pmt-&gt;pbFormat))-&gt;rcTarget <br> <br>    pSample-&gt;GetMediaType(&amp;pmt); <br>    if (pmt != NULL &amp;&amp; pmt-&gt;pbFormat != NULL) { <br> <br>// spew some debug output <br>ASSERT(!IsEqualGUID(pmt-&gt;majortype, GUID_NULL)); <br>#ifdef DEBUG <br>        fccOut.SetFOURCC(&amp;pmt-&gt;subtype); <br>LONG lCompression = HEADER(pmt-&gt;pbFormat)-&gt;biCompression; <br>LONG lBitCount = HEADER(pmt-&gt;pbFormat)-&gt;biBitCount; <br>LONG lStride = (HEADER(pmt-&gt;pbFormat)-&gt;biWidth * lBitCount + 7) / 8; <br>lStride = (lStride + 3) &amp; ~3; <br>        DbgLog((LOG_TRACE,3,TEXT("*Changing input type on the fly to"))); <br>        DbgLog((LOG_TRACE,3,TEXT("FourCC: %lx Compression: %lx BitCount: %ld"), <br>fccOut.GetFOURCC(), lCompression, lBitCount)); <br>        DbgLog((LOG_TRACE,3,TEXT("biHeight: %ld rcDst: (%ld, %ld, %ld, %ld)"), <br>HEADER(pmt-&gt;pbFormat)-&gt;biHeight, <br>rcT1.left, rcT1.top, rcT1.right, rcT1.bottom)); <br>        DbgLog((LOG_TRACE,3,TEXT("rcSrc: (%ld, %ld, %ld, %ld) Stride: %ld"), <br>rcS1.left, rcS1.top, rcS1.right, rcS1.bottom, <br>lStride)); <br>#endif <br> <br>// now switch to using the new format.  I am assuming that the <br>// derived filter will do the right thing when its media type is <br>// switched and streaming is restarted. <br> <br>StopStreaming(); <br>m_pInput-&gt;CurrentMediaType() = *pmt; <br>DeleteMediaType(pmt); <br>// not much we can do if this fails <br>hr = StartStreaming(); <br>    } <br> <br>    // The renderer may ask us to on-the-fly to start transforming to a <br>    // different format.  If we don't obey it, we'll draw garbage <br> <br>#define rcS ((VIDEOINFOHEADER *)(pmtOut-&gt;pbFormat))-&gt;rcSource <br>#define rcT ((VIDEOINFOHEADER *)(pmtOut-&gt;pbFormat))-&gt;rcTarget <br> <br>    pOutSample-&gt;GetMediaType(&amp;pmtOut); <br>    if (pmtOut != NULL &amp;&amp; pmtOut-&gt;pbFormat != NULL) { <br> <br>// spew some debug output <br>ASSERT(!IsEqualGUID(pmtOut-&gt;majortype, GUID_NULL)); <br>#ifdef DEBUG <br>        fccOut.SetFOURCC(&amp;pmtOut-&gt;subtype); <br>LONG lCompression = HEADER(pmtOut-&gt;pbFormat)-&gt;biCompression; <br>LONG lBitCount = HEADER(pmtOut-&gt;pbFormat)-&gt;biBitCount; <br>LONG lStride = (HEADER(pmtOut-&gt;pbFormat)-&gt;biWidth * lBitCount + 7) / 8; <br>lStride = (lStride + 3) &amp; ~3; <br>        DbgLog((LOG_TRACE,3,TEXT("*Changing output type on the fly to"))); <br>        DbgLog((LOG_TRACE,3,TEXT("FourCC: %lx Compression: %lx BitCount: %ld"), <br>fccOut.GetFOURCC(), lCompression, lBitCount)); <br>        DbgLog((LOG_TRACE,3,TEXT("biHeight: %ld rcDst: (%ld, %ld, %ld, %ld)"), <br>HEADER(pmtOut-&gt;pbFormat)-&gt;biHeight, <br>rcT.left, rcT.top, rcT.right, rcT.bottom)); <br>        DbgLog((LOG_TRACE,3,TEXT("rcSrc: (%ld, %ld, %ld, %ld) Stride: %ld"), <br>rcS.left, rcS.top, rcS.right, rcS.bottom, <br>lStride)); <br>#endif <br> <br>// now switch to using the new format.  I am assuming that the <br>// derived filter will do the right thing when its media type is <br>// switched and streaming is restarted. <br> <br>StopStreaming(); <br>m_pOutput-&gt;CurrentMediaType() = *pmtOut; <br>DeleteMediaType(pmtOut); <br>hr = StartStreaming(); <br> <br>if (SUCCEEDED(hr)) { <br>     // a new format, means a new empty buffer, so wait for a keyframe <br>    // before passing anything on to the renderer. <br>    // !!! a keyframe may never come, so give up after 30 frames <br>            DbgLog((LOG_TRACE,3,TEXT("Output format change means we must wait for a keyframe"))); <br>    m_nWaitForKey = 30; <br>} <br>    } <br> <br>    // Start timing the transform (and log it if PERF is defined) <br> <br>    if (SUCCEEDED(hr)) { <br>        m_tDecodeStart = timeGetTime(); <br>        MSR_START(m_idTransform); <br> <br>        // have the derived class transform the data <br>        hr = Transform(pSample, pOutSample); <br> <br>        // Stop the clock (and log it if PERF is defined) <br>        MSR_STOP(m_idTransform); <br>        m_tDecodeStart = timeGetTime()-m_tDecodeStart; <br>        m_itrAvgDecode = m_tDecodeStart*(10000/16) + 15*(m_itrAvgDecode/16); <br> <br>        // Maybe we're waiting for a keyframe still? <br>        if (m_nWaitForKey) <br>            m_nWaitForKey--; <br>        if (m_nWaitForKey &amp;&amp; pSample-&gt;IsSyncPoint() == S_OK) <br>    m_nWaitForKey = FALSE; <br> <br>        // if so, then we don't want to pass this on to the renderer <br>        if (m_nWaitForKey &amp;&amp; hr == NOERROR) { <br>            DbgLog((LOG_TRACE,3,TEXT("still waiting for a keyframe"))); <br>    hr = S_FALSE; <br>} <br>    } <br> <br>    if (FAILED(hr)) { <br>        DbgLog((LOG_TRACE,1,TEXT("Error from video transform"))); <br>    } else { <br>        // the Transform() function can return S_FALSE to indicate that the <br>        // sample should not be delivered; we only deliver the sample if it's <br>        // really S_OK (same as NOERROR, of course.) <br>        // Try not to return S_FALSE to a direct draw buffer (it's wasteful) <br>        // Try to take the decision earlier - before you get it. <br> <br>        if (hr == NOERROR) { <br>        hr = m_pOutput-&gt;Deliver(pOutSample); <br>        } else { <br>            // S_FALSE returned from Transform is a PRIVATE agreement <br>            // We should return NOERROR from Receive() in this case because returning S_FALSE <br>            // from Receive() means that this is the end of the stream and no more data should <br>            // be sent. <br>            if (S_FALSE == hr) { <br> <br>                //  We must Release() the sample before doing anything <br>                //  like calling the filter graph because having the <br>                //  sample means we may have the DirectDraw lock <br>                //  (== win16 lock on some versions) <br>                pOutSample-&gt;Release(); <br>                m_bSampleSkipped = TRUE; <br>                if (!m_bQualityChanged) { <br>                    m_bQualityChanged = TRUE; <br>                    NotifyEvent(EC_QUALITY_CHANGE,0,0); <br>                } <br>                return NOERROR; <br>            } <br>        } <br>    } <br> <br>    // release the output buffer. If the connected pin still needs it, <br>    // it will have addrefed it itself. <br>    pOutSample-&gt;Release(); <br>    ASSERT(CritCheckIn(&amp;m_csReceive)); <br> <br>    return hr; <br>} <br> <br> <br> <br>BOOL CVideoTransformFilter::ShouldSkipFrame( IMediaSample * pIn) <br>{ <br>    REFERENCE_TIME trStart, trStopAt; <br>    HRESULT hr = pIn-&gt;GetTime(&amp;trStart, &amp;trStopAt); <br> <br>    // Don't skip frames with no timestamps <br>    if (hr != S_OK) <br>return FALSE; <br> <br>    int itrFrame = (int)(trStopAt - trStart);  // frame duration <br> <br>    if(S_OK==pIn-&gt;IsSyncPoint()) { <br>        MSR_INTEGER(m_idFrameType, 1); <br>        if ( m_nKeyFramePeriod &lt; m_nFramesSinceKeyFrame ) { <br>            // record the max <br>            m_nKeyFramePeriod = m_nFramesSinceKeyFrame; <br>        } <br>        m_nFramesSinceKeyFrame = 0; <br>        m_bSkipping = FALSE; <br>    } else { <br>        MSR_INTEGER(m_idFrameType, 2); <br>        if (  m_nFramesSinceKeyFrame&gt;m_nKeyFramePeriod <br>           &amp;&amp; m_nKeyFramePeriod&gt;0 <br>           ) { <br>            // We haven't seen the key frame yet, but we were clearly being <br>            // overoptimistic about how frequent they are. <br>            m_nKeyFramePeriod = m_nFramesSinceKeyFrame; <br>        } <br>    } <br> <br> <br>    // Whatever we might otherwise decide, <br>    // if we are taking only a small fraction of the required frame time to decode <br>    // then any quality problems are actually coming from somewhere else. <br>    // Could be a net problem at the source for instance.  In this case there's <br>    // no point in us skipping frames here. <br>    if (m_itrAvgDecode*4&gt;itrFrame) { <br> <br>        // Don't skip unless we are at least a whole frame late. <br>        // (We would skip B frames if more than 1/2 frame late, but they're safe). <br>        if ( m_itrLate &gt; itrFrame ) { <br> <br>            // Don't skip unless the anticipated key frame would be no more than <br>            // 1 frame early.  If the renderer has not been waiting (we *guess* <br>            // it hasn't because we're late) then it will allow frames to be <br>            // played early by up to a frame. <br> <br>            // Let T = Stream time from now to anticipated next key frame <br>            // = (frame duration) * (KeyFramePeriod - FramesSinceKeyFrame) <br>            // So we skip if T - Late &lt; one frame  i.e. <br>            //   (duration) * (freq - FramesSince) - Late &lt; duration <br>            // or (duration) * (freq - FramesSince - 1) &lt; Late <br> <br>            // We don't dare skip until we have seen some key frames and have <br>            // some idea how often they occur and they are reasonably frequent. <br>            if (m_nKeyFramePeriod&gt;0) { <br>                // It would be crazy - but we could have a stream with key frames <br>                // a very long way apart - and if they are further than about <br>                // 3.5 minutes apart then we could get arithmetic overflow in <br>                // reference time units.  Therefore we switch to mSec at this point <br>                int it = (itrFrame/10000) <br>                         * (m_nKeyFramePeriod-m_nFramesSinceKeyFrame -  1); <br>                MSR_INTEGER(m_idTimeTillKey, it); <br> <br>                // For debug - might want to see the details - dump them as scratch pad <br>#ifdef VTRANSPERF <br>                MSR_INTEGER(0, itrFrame); <br>                MSR_INTEGER(0, m_nFramesSinceKeyFrame); <br>                MSR_INTEGER(0, m_nKeyFramePeriod); <br>#endif <br>                if (m_itrLate/10000 &gt; it) { <br>                    m_bSkipping = TRUE; <br>                    // Now we are committed.  Once we start skipping, we <br>                    // cannot stop until we hit a key frame. <br>                } else { <br>#ifdef VTRANSPERF <br>                    MSR_INTEGER(0, 777770);  // not near enough to next key <br>#endif <br>                } <br>            } else { <br>#ifdef VTRANSPERF <br>                MSR_INTEGER(0, 777771);  // Next key not predictable <br>#endif <br>            } <br>        } else { <br>#ifdef VTRANSPERF <br>            MSR_INTEGER(0, 777772);  // Less than one frame late <br>            MSR_INTEGER(0, m_itrLate); <br>            MSR_INTEGER(0, itrFrame); <br>#endif <br>        } <br>    } else { <br>#ifdef VTRANSPERF <br>        MSR_INTEGER(0, 777773);  // Decode time short - not not worth skipping <br>        MSR_INTEGER(0, m_itrAvgDecode); <br>        MSR_INTEGER(0, itrFrame); <br>#endif <br>    } <br> <br>    ++m_nFramesSinceKeyFrame; <br> <br>    if (m_bSkipping) { <br>        // We will count down the lateness as we skip each frame. <br>        // We re-assess each frame.  The key frame might not arrive when expected. <br>        // We reset m_itrLate if we get a new Quality message, but actually that's <br>        // not likely because we're not sending frames on to the Renderer.  In <br>        // fact if we DID get another one it would mean that there's a long <br>        // pipe between us and the renderer and we might need an altogether <br>        // better strategy to avoid hunting! <br>        m_itrLate = m_itrLate - itrFrame; <br>    } <br> <br>    MSR_INTEGER(m_idLate, (int)m_itrLate/10000 ); // Note how late we think we are <br>    if (m_bSkipping) { <br>        if (!m_bQualityChanged) { <br>            m_bQualityChanged = TRUE; <br>            NotifyEvent(EC_QUALITY_CHANGE,0,0); <br>        } <br>    } <br>    return m_bSkipping; <br>} <br> <br> <br>HRESULT CVideoTransformFilter::AlterQuality(Quality q) <br>{ <br>    // to reduce the amount of 64 bit arithmetic, m_itrLate is an int. <br>    // +, -, &gt;, == etc  are not too bad, but * and / are painful. <br>    if (m_itrLate&gt;300000000) { <br>        // Avoid overflow and silliness - more than 30 secs late is already silly <br>        m_itrLate = 300000000; <br>    } else { <br>        m_itrLate = (int)q.Late; <br>    } <br>    // We ignore the other fields <br> <br>    // We're actually not very good at handling this.  In non-direct draw mode <br>    // most of the time can be spent in the renderer which can skip any frame. <br>    // In that case we'd rather the renderer handled things. <br>    // Nevertheless we will keep an eye on it and if we really start getting <br>    // a very long way behind then we will actually skip - but we'll still tell <br>    // the renderer (or whoever is downstream) that they should handle quality. <br> <br>    return E_FAIL;     // Tell the renderer to do his thing. <br> <br>} <br> <br> <br> <br>// This will avoid several hundred useless warnings if compiled -W4 by MS VC++ v4 <br>#pragma warning(disable:4514) <br> </code></pre>
<p>&nbsp;</p></body>
</HTML>
