<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 3.2 Final//EN">
<HTML dir=ltr>
<HEAD>
<META HTTP-EQUIV="Content-Type" Content="text/html; charset=Windows-1252">
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-83731338-2"></script><script>  window.dataLayer = window.dataLayer || [];  function gtag(){dataLayer.push(arguments);}  gtag('js', new Date());  gtag('config', 'UA-83731338-2');</script><title>MPGAUDIO.CPP</title>
<link disabled rel=stylesheet href=../../../../../backsdk3.css>
<style type="text/css">
@import url(../../../../../backsdk4.css);
</style>
</HEAD>
<BODY BGCOLOR = #FFFFFF TEXT = #000000>
<h2><a name="_code_context2850"></a>MPGAUDIO.CPP</h2>
<pre><code>//==========================================================================; <br>// <br>//  THIS CODE AND INFORMATION IS PROVIDED "AS IS" WITHOUT WARRANTY OF ANY <br>//  KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE <br>//  IMPLIED WARRANTIES OF MERCHANTABILITY AND/OR FITNESS FOR A PARTICULAR <br>//  PURPOSE. <br>// <br>//  Copyright (c) 1992 - 1997  Microsoft Corporation.  All Rights Reserved. <br>// <br>//--------------------------------------------------------------------------; <br>// <br>/******************************Module*Header*******************************\ <br>* Module Name: MpgAudio.cpp <br>* <br>* Implements a prototype Mpeg Audio Software codec.  It just consume <br>* the passed in packets. <br>* <br>* <br>\**************************************************************************/ <br> <br>#include "MpgAudio.h" <br> <br>// define the GUIDs for streams and my CLSID in this file <br>#include &lt;initguid.h&gt; <br> <br>#include "MpegUids.h" <br> <br>// setup data <br> <br>const AMOVIESETUP_MEDIATYPE psudIpPinTypes[] = <br>{ { &amp;MEDIATYPE_Audio                // clsMajorType <br>  , &amp;MEDIASUBTYPE_MPEG1Packet  }    // clsMinorType <br>, { &amp;MEDIATYPE_Audio                // clsMajorType <br>  , &amp;MEDIASUBTYPE_MPEG1AudioPayload }    // clsMinorType <br>, { &amp;MEDIATYPE_Stream               // clsMajorType <br>  , &amp;MEDIASUBTYPE_MPEG1Audio   } }; // clsMinorType <br> <br>const AMOVIESETUP_MEDIATYPE sudOpPinTypes = <br>{ &amp;MEDIATYPE_Audio      // clsMajorType <br>, &amp;MEDIASUBTYPE_NULL }; // clsMinorType <br> <br>const AMOVIESETUP_PIN psudPins[] = <br>{ { L"Input"            // strName <br>  , FALSE               // bRendered <br>  , FALSE               // bOutput <br>  , FALSE               // bZero <br>  , FALSE               // bMany <br>  , &amp;CLSID_NULL         // clsConnectsToFilter <br>  , L"Output"           // strConnectsToPin <br>  , 3                   // nTypes <br>  , psudIpPinTypes }    // lpTypes <br>, { L"Output"           // strName <br>  , FALSE               // bRendered <br>  , TRUE                // bOutput <br>  , FALSE               // bZero <br>  , FALSE               // bMany <br>  , &amp;CLSID_NULL         // clsConnectsToFilter <br>  , L"Input"            // strConnectsToPin <br>  , 1                   // nTypes <br>  , &amp;sudOpPinTypes } }; // lpTypes <br> <br> <br> <br>const AMOVIESETUP_FILTER <br>sudMPEGAudio = { &amp;CLSID_CMpegFrameworkAudioCodec // clsID <br>               , L"MPEG Framework Audio Codec"   // strName <br>               , 0x00680000                      // dwMerit <br>               , 2                               // nPins <br>               , psudPins };                     // lpPin <br> <br> <br>/* ------------------------------------------------------------------------- <br>** list of class ids and creator functions for class factory <br>** ------------------------------------------------------------------------- <br>*/ <br>CFactoryTemplate g_Templates[] = { <br>    { L"MPEG Framework Audio Codec" <br>    , &amp;CLSID_CMpegFrameworkAudioCodec <br>    , CMpegAudioCodec::CreateInstance <br>    , NULL <br>    , &amp;sudMPEGAudio } <br>}; <br>int g_cTemplates = sizeof(g_Templates) / sizeof(g_Templates[0]); <br> <br> <br>/* ------------------------------------------------------------------------- <br>** Decoder strings <br>** ------------------------------------------------------------------------- <br>*/ <br>const TCHAR chAudioChannels[]      = TEXT("AudioChannels"); <br>const TCHAR chAudioFreqDivider[]   = TEXT("AudioFreqDivider"); <br>const TCHAR chAudioQuality[]       = TEXT("AudioQuality"); <br>const TCHAR chAudioQuarterInt[]    = TEXT("AudioQuarterInt"); <br>const TCHAR chAudioBits[]          = TEXT("AudioBits"); <br>const TCHAR chRegistryKey[] = <br>    TEXT("Software\\Microsoft\\Multimedia\\ActiveMovie Filters\\Sample MPEG Audio Decoder"); <br> <br> <br> <br>// --- CMpegAudioCodec ---------------------------------------- <br>CMpegAudioCodec::CMpegAudioCodec(TCHAR *pName, LPUNKNOWN pUnk, HRESULT *phr) <br>    : CTransformFilter(pName, pUnk, CLSID_CMpegAudioCodec), <br>    m_pAudioDecoder(NULL) <br>{ <br>    m_FreqDiv  = GetDecoderInteger(chAudioFreqDivider, 4); <br>    m_PrefChan = GetDecoderInteger(chAudioChannels, 1); <br>    m_Quality  = GetDecoderInteger(chAudioQuality, 0); <br>    m_QuarterInt = GetDecoderInteger(chAudioQuarterInt, 0); <br>    m_WordSize = GetDecoderInteger(chAudioBits, 16); <br>    if (m_QuarterInt) { <br>        m_FreqDiv = 4; <br>    } <br>} <br> <br>CMpegAudioCodec::~CMpegAudioCodec() <br>{ <br>    delete m_pAudioDecoder; <br>    m_pAudioDecoder = NULL; <br>} <br> <br> <br>/******************************Public*Routine******************************\ <br>* CreateInstance <br>* <br>* this goes in the factory template table to create new instances <br>* <br>* <br>\**************************************************************************/ <br>CUnknown * <br>CMpegAudioCodec::CreateInstance( <br>    LPUNKNOWN pUnk, <br>    HRESULT *phr <br>    ) <br>{ <br>    DbgLog((LOG_TRACE, 2, TEXT("CMpegAudioCodec::CreateInstance"))); <br>    return new CMpegAudioCodec(TEXT("MPEG Audio Codec Filter"), pUnk, phr); <br>} <br> <br> <br>/******************************Public*Routine******************************\ <br>* NonDelegatingQueryInterface <br>* <br>* Reveals ISpecifyPropertyPages <br>* <br>* <br>\**************************************************************************/ <br>STDMETHODIMP <br>CMpegAudioCodec::NonDelegatingQueryInterface( <br>    REFIID riid, <br>    void ** ppv <br>    ) <br>{ <br>    return CTransformFilter::NonDelegatingQueryInterface(riid, ppv); <br>} <br> <br> <br>/******************************Public*Routine******************************\ <br>* EndOfStream <br>* <br>* <br>\**************************************************************************/ <br>HRESULT <br>CMpegAudioCodec::EndOfStream() <br>{ <br>    DbgLog((LOG_TRACE, 2, TEXT("End of stream called"))); <br>    CAutoLock lck(&amp;m_csReceive); <br> <br>    // <br>    // Here we would normally decode the remainder of the buffer.  However, <br>    // the audio codec is designed such that its buffer never contains <br>    // any full frames of coded data, so all we have to do is reset the <br>    // audio codec. <br>    // <br> <br>    if (m_pAudioDecoder == NULL) { <br>        return VFW_E_WRONG_STATE; <br>    } <br> <br>    ResetAudioDecoder(); <br>    return CTransformFilter::EndOfStream(); <br>} <br> <br> <br>/******************************Public*Routine******************************\ <br>* EndFlush <br>* <br>* <br>\**************************************************************************/ <br>HRESULT <br>CMpegAudioCodec::EndFlush() <br>{ <br>    DbgLog((LOG_TRACE, 2, TEXT("End flush called"))); <br>    CAutoLock lck(&amp;m_csReceive); <br> <br>    ResetAudioDecoder(); <br>    return CTransformFilter::EndFlush(); <br>} <br> <br> <br>/*****************************Private*Routine******************************\ <br>* ProcessDiscontiuity <br>* <br>* <br>\**************************************************************************/ <br>void <br>CMpegAudioCodec::ProcessDiscontiuity( <br>    IMediaSample *pSample <br>    ) <br>{ <br>    ResetAudioDecoder(); <br> <br>    // <br>    //  Find out what the current stop time is <br>    // <br> <br>    // <br>    //  Get logical duration from upstream <br>    // <br>    REFTIME dStart, dStop; <br>    IMediaPosition *pPosition; <br> <br>    if (SUCCEEDED(m_pInput-&gt;GetConnected()-&gt;QueryInterface(IID_IMediaPosition, <br>                     (void **)&amp;pPosition)) <br>     &amp;&amp; SUCCEEDED(pPosition-&gt;get_CurrentPosition(&amp;dStart)) <br>     &amp;&amp; SUCCEEDED(pPosition-&gt;get_StopTime(&amp;dStop))) <br>    { <br>        m_tStop = (CRefTime)(COARefTime)dStop - (CRefTime)(COARefTime)dStart; <br>    } <br>    else { <br>        m_tStop = 0x7FFFFFFFFFFFFFFF; <br>    } <br> <br>    if (pPosition != NULL) { <br>        pPosition-&gt;Release(); <br>    } <br> <br>    DbgLog((LOG_TRACE, 2, <br>           TEXT("Receive() : Discontinuity - setting stop time to %s"), <br>           (LPCTSTR)CDisp(m_tStop))); <br>} <br> <br> <br>/*****************************Private*Routine******************************\ <br>* ProcessSyncPoint <br>* <br>* <br>\**************************************************************************/ <br>void <br>CMpegAudioCodec::ProcessSyncPoint( <br>    IMediaSample *pSample, <br>    BYTE *pSrc <br>    ) <br>{ <br>    CRefTime  tStart, tStop; <br> <br>    pSample-&gt;GetTime((REFERENCE_TIME*)&amp;tStart, <br>                     (REFERENCE_TIME*)&amp;tStop); <br> <br>    m_TimeAtLastSyncPoint = tStart; <br>    m_TimeSinceLastSyncPoint = 0; <br> <br>    // <br>    // If our buffer contains a partial audio frame adjust the <br>    // sync point time by one frame.  Note that LookForSyncWord advances <br>    // the m_lpCurr buffer pointer, if there is no sync word found <br>    // m_lpCurr should equal m_lpEnd, if the last byte in our audio buffer <br>    // is the first byte of the audio sync word m_lpCurr will equal <br>    // m_lpEnd - 1. <br>    // This can fail because sync words can be found other than at <br>    // frame start! <br>    // <br>    if (LookForSyncWord()) { <br>        m_TimeAtLastSyncPoint -= m_TimePerFrame; <br>    } <br>    else { <br> <br>        ASSERT(m_lpCurr &lt;= m_lpEnd); <br> <br>        // <br>        // Now check that there was not a pertial sync word left in our <br>        // buffer. <br>        // <br>        if (m_lpCurr &lt; m_lpEnd) { <br>            if ((*m_lpCurr == 0xFF) &amp;&amp; (pSrc[0] &amp; 0xF0) == 0xF0) { <br>                m_TimeAtLastSyncPoint -= m_TimePerFrame; <br>            } <br>        } <br>    } <br>} <br> <br> <br> <br>/*****************************Private*Routine******************************\ <br>* DeliverSample <br>* <br>* <br>\**************************************************************************/ <br>HRESULT <br>CMpegAudioCodec::DeliverSample( <br>    IMediaSample *pOutSample, <br>    CRefTime &amp;TimeDecoded, <br>    int nActBytesWritten <br>    ) <br>{ <br>    CRefTime tStart, tStop; <br> <br>    // <br>    // decompressed frames are always key <br>    // <br>    pOutSample-&gt;SetSyncPoint(TRUE); <br>    pOutSample-&gt;SetActualDataLength(nActBytesWritten); <br> <br>    // <br>    // Extrapolate the correct time stamp. <br>    // <br>    tStart = m_TimeAtLastSyncPoint + m_TimeSinceLastSyncPoint; <br>    if (tStart &lt; (LONG)0) { <br> <br>        /*  Only play from the start */ <br>    } <br> <br>    tStop = tStart + TimeDecoded; <br>    m_TimeSinceLastSyncPoint += TimeDecoded; <br>    pOutSample-&gt;SetTime((REFERENCE_TIME*)&amp;tStart, <br>                        (REFERENCE_TIME*)&amp;tStop); <br> <br>    DbgLog((LOG_TRACE, 3, TEXT("Writing %ld bytes with time stamp %s"), <br>            nActBytesWritten, (LPCTSTR)CDisp(tStart) )); <br> <br>    return m_pOutput-&gt;Deliver(pOutSample); <br>} <br> <br> <br>/******************************Public*Routine******************************\ <br>* Receive <br>* <br>* Copy the input sample into our buffer.  Loop while the buffer size is <br>* greater than or equal to the size required to decode a frame of audio data. <br>* Decode the audio frame and pass it along to the output pin for rendering. <br>* <br>* <br>\**************************************************************************/ <br>HRESULT <br>CMpegAudioCodec::Receive( <br>    IMediaSample *pSample <br>    ) <br>{ <br>    //  Make sure the pin doesn't go inactive on us <br>    CAutoLock lck(&amp;m_csReceive); <br>    if (m_pAudioDecoder == NULL) { <br>        return E_UNEXPECTED; <br>    } <br> <br>    IMediaSample    *pOutSample; <br>    BYTE            *pDst; <br>    BYTE            *pSrc; <br>    BYTE            *lpPacket; <br>    HRESULT         hr; <br>    long            LenLeftInBuffer = 0L; <br>    long            LenLeftInPacket; <br> <br>    DbgLog((LOG_TRACE, 2, TEXT("CMpegAudioCodec::Receive"))); <br> <br>    // <br>    // Check for a discontinuity, if one is found just reset the decoder <br>    // and then continue processing the current sample.  We do not have to <br>    // decode any frames left in the audio buffer because the audio codec <br>    // always consumes all the complete audio data frames copied to <br>    // the buffer. <br>    // <br>    if (pSample-&gt;IsDiscontinuity() == S_OK) { <br>        ProcessDiscontiuity(pSample); <br>    } <br> <br>    hr = pSample-&gt;GetPointer(&amp;pSrc); <br>    if (FAILED(hr)) { <br>        return hr; <br>    } <br> <br>    // <br>    // Get a pointer to the actual mpeg data and determine the <br>    // length of data supplied. <br>    // <br>    if (m_bPayloadOnly) { <br>        lpPacket = pSrc; <br>        LenLeftInPacket = pSample-&gt;GetActualDataLength(); <br>    } <br>    else { <br>        lpPacket = SkipToPacketData(pSrc, LenLeftInPacket); <br>        if (lpPacket == NULL) { <br>            NotifyEvent(EC_STREAM_ERROR_STILLPLAYING, E_INVALIDARG, 0); <br>            return S_OK; <br>        } <br>    } <br>    DbgLog((LOG_TRACE, 2, TEXT("Left in Packet %ld"), LenLeftInPacket )); <br> <br> <br>    // <br>    // If this sample is a sync point we need to update our clock and <br>    // reset the count of samples received since the last sync point. <br>    // If our buffer contains a partial audio frame we need to make a suitable <br>    // adjustment to the sync point time as the time refers to the first audio <br>    // frame in the current sample which would not necessarly be the first <br>    // sample decoded. <br>    // <br> <br>    if (pSample-&gt;IsSyncPoint() == S_OK) { <br>        ProcessSyncPoint(pSample, pSrc); <br>    } <br> <br> <br>    // <br>    // Now, decode the sample data passed to us. <br>    // <br> <br>    do { <br> <br>        LPBYTE      lpDstEnd; <br>        CRefTime    TimeDecoded; <br>        DWORD       rc; <br>        int         nActBytesWritten = 0; <br> <br>        GetNextPacketChunk(lpPacket, LenLeftInBuffer, LenLeftInPacket); <br> <br>        DbgLog((LOG_TRACE, 3, TEXT("Left in Buffer %ld"), LenLeftInBuffer )); <br>        DbgLog((LOG_TRACE, 3, TEXT("Left in Packet %ld"), LenLeftInPacket )); <br> <br>        if (LenLeftInBuffer &lt; m_FrameSize &amp;&amp; LenLeftInPacket == 0L) { <br>             break; <br>        } <br> <br>        // <br>        // this may block for an indeterminate amount of time <br>        // <br>        hr = m_pOutput-&gt;GetDeliveryBuffer(&amp;pOutSample,NULL,NULL,0); <br>        if (FAILED(hr)) { <br>            break; <br>        } <br>        ASSERT(pOutSample); <br> <br>        hr = pOutSample-&gt;GetPointer(&amp;pDst); <br>        if (FAILED(hr)) { <br>            break; <br>        } <br>        ASSERT(pDst); <br> <br> <br>        // <br>        // Initialize the audio control structure <br>        // <br>        m_AudioControl.dwNumFrames   = 1; <br>        m_AudioControl.dwOutBuffSize = m_pOutput-&gt;CurrentMediaType().GetSampleSize(); <br>        m_AudioControl.dwOutBuffUsed = 0; <br>        m_AudioControl.pCmprRead  = m_lpStart; <br>        m_AudioControl.pCmprWrite = m_lpEnd; <br> <br> <br>        // <br>        // Determine the end of the output buffer so that we don't try to <br>        // decode data beyond it.  m_BytesPerFrame is the number of bytes <br>        // one frame of Mpeg audio data will expand to after it has been <br>        // decoded. <br>        // <br>        lpDstEnd = pDst + m_AudioControl.dwOutBuffSize - m_FrameSizeOutput; <br>        TimeDecoded = 0; <br> <br> <br>        // <br>        // While there is an audio frame in the buffer and the frame is <br>        // complete and there is space in the output buffer to store the <br>        // decompressed frame, decompress it !! <br>        // <br> <br>        while (LookForSyncWord() <br>           &amp;&amp; (m_lpCurr + m_FrameSize + Padding() &lt; m_lpEnd) <br>           &amp;&amp; (pDst &lt;= lpDstEnd)) { <br> <br>            m_AudioControl.pOutBuffer  = pDst; <br>            m_AudioControl.pCmprRead   = m_lpCurr; <br>            m_AudioControl.dwMpegError = 0; <br> <br>            rc = m_pAudioDecoder-&gt;DecodeAudioFrame(&amp;m_AudioControl); <br>            switch (rc) { <br> <br>            case 0: <br>                // <br>                // We have successfully decoded an audio frame. <br>                // <br>                if (m_FrameSize == 0L) { <br>                    m_FrameSize = (LPBYTE)m_AudioControl.pCmprRead - <br>                                          m_lpCurr - Padding(); <br>                } <br>                m_lpCurr = (LPBYTE)m_AudioControl.pCmprRead; <br>                pDst += m_AudioControl.dwOutBuffUsed; <br>                nActBytesWritten += m_AudioControl.dwOutBuffUsed; <br>                m_AudioControl.dwOutBuffSize -= m_AudioControl.dwOutBuffUsed; <br>                TimeDecoded += m_TimePerFrame; <br>                break; <br> <br> <br>            case 2: <br>                // <br>                // We did not have enough data available to decode the <br>                // current audio frame.  This is buffer underflow. <br>                // <br>                DbgLog((LOG_ERROR, 1, TEXT("Buffer underflow !!"))); <br> <br>            default: <br>                // <br>                // Some sort of error occurred, throw the remainder of the <br>                // buffer away and skip this packet. <br>                // <br>                DbgLog((LOG_ERROR, 1, TEXT("Bad return code from audio codec!"))); <br>                m_lpCurr = m_lpEnd; <br>                NotifyEvent(EC_STREAM_ERROR_STILLPLAYING, E_INVALIDARG, 0); <br>                hr = S_OK; <br>                break; <br>            } <br>        } <br> <br> <br>        // <br>        // Have we decoded any data ?  If so we need to deliver the data to <br>        // to the filter that receives our output, usually the audio <br>        // rendering filter. <br>        // <br> <br>        if (TimeDecoded &gt; (LONG)0) { <br> <br>            hr = DeliverSample(pOutSample, TimeDecoded, nActBytesWritten); <br>            if (FAILED(hr)) { <br>                DbgLog((LOG_ERROR, 2, <br>                        TEXT("CMpegAudioCodec::Deliver failed 0x%8.8X"), hr)); <br>                pOutSample-&gt;Release(); <br>                break; <br>            } <br>        } <br> <br>        // <br>        // Release the output buffer. If the connected pin still needs it, <br>        // it will have addrefed it itself. <br>        // <br>        pOutSample-&gt;Release(); <br> <br> <br>        // <br>        // Stop decoding when we have consumed all the data in the input <br>        // media sample. <br>        // <br> <br>    } while (LenLeftInPacket != 0L); <br> <br>    // <br>    //  We notify the filter graph of problems but return S_FALSE <br>    //  back to the caller to notify end of stream <br>    // <br> <br>    // if (hr != S_OK) { <br>    //     NotifyEvent(hr == S_FALSE ? EC_COMPLETE : EC_ERRORABORT, 0, 0); <br>    // } <br>    return hr; <br>} <br> <br> <br> <br>/*****************************Private*Routine******************************\ <br>* ResetAudioDecoder <br>* <br>* <br>\**************************************************************************/ <br>void <br>CMpegAudioCodec::ResetAudioDecoder() <br>{ <br>    m_pAudioDecoder-&gt;ResetAudio(); <br>    m_lpStart = m_lpCurr = m_lpEnd = &amp;m_Buffer[0]; <br>    m_FrameSize = 0L; <br>} <br> <br> <br> <br>/******************************Public*Routine******************************\ <br>* GetNextPacketChunk <br>* <br>* <br>\**************************************************************************/ <br>void <br>CMpegAudioCodec::GetNextPacketChunk( <br>    LPBYTE  &amp;lpPacket, <br>    long    &amp;LenLeftInBuffer, <br>    long    &amp;LenLeftInPacket <br>    ) <br>{ <br>    long AmountToCopy; <br> <br>    LenLeftInBuffer = m_lpEnd - m_lpCurr; <br> <br>    // <br>    // Move what remains in the audio data buffer to the top of <br>    // the buffer and append the new audio data to it. <br>    // <br>    AmountToCopy = min( (AUDIO_BUFF_SIZE - LenLeftInBuffer), LenLeftInPacket); <br> <br>    MoveMemory(m_lpStart, m_lpCurr, LenLeftInBuffer); <br>    CopyMemory(m_lpStart + LenLeftInBuffer, lpPacket,  AmountToCopy); <br> <br>    LenLeftInPacket -= AmountToCopy; <br>    lpPacket += AmountToCopy; <br> <br> <br>    // <br>    // Adjust the buffer pointers so that m_lpCurr points to <br>    // the start of the buffer and m_lpEnd points to the last <br>    // valid audio byte in buffer. <br>    // <br>    m_lpCurr = m_lpStart; <br>    m_lpEnd = m_lpStart + LenLeftInBuffer + AmountToCopy; <br>    LenLeftInBuffer = m_lpEnd - m_lpCurr; <br>} <br> <br> <br>/******************************Public*Routine******************************\ <br>* LookForSyncWord <br>* <br>* <br>\**************************************************************************/ <br>BOOL <br>CMpegAudioCodec::LookForSyncWord() <br>{ <br>    /* now look for sync */ <br>    int sm = 0; <br> <br>    while (m_lpCurr &lt; m_lpEnd &amp;&amp; sm &lt; 2)  { <br> <br>        switch (sm) { <br>        case 0: <br>            sm = (*m_lpCurr == 0xff); <br>            break; <br> <br>        case 1: <br>            if ((*m_lpCurr &amp; 0xf0) == 0xf0) sm = 2; /* sync found */ <br>            else sm = (*m_lpCurr == 0xff); <br>            break; <br>        } <br>        m_lpCurr++; <br>    } <br> <br>    // <br>    // When we get here we have either run out of buffer or found the first <br>    // "sm" bytes of a valid sync word. <br>    // <br>    // Don't forget to put back the sync word bytes that we have just <br>    // read otherwise they would be lost forever. <br>    // <br>    m_lpCurr -= sm; <br> <br>    if (sm &lt; 2) { <br>        return FALSE;   // sync not found. <br>    } <br> <br>    return TRUE; <br>} <br> <br> <br>/******************************Public*Routine******************************\ <br>* Padding <br>* <br>* Returns 1 if the padding bit is set, zero otherwise <br>* <br>* <br>\**************************************************************************/ <br>int <br>CMpegAudioCodec::Padding() <br>{ <br>    DWORD dw1 = *(UNALIGNED DWORD *)m_lpCurr; <br> <br>    // <br>    // Determine the audio layer for the given frame <br>    // <br>    switch (dw1 &amp; 0x600) { <br> <br>    case 0x200:     // Layer 1 <br>        return (dw1 &amp; 0x20000) ? 4 : 0; <br> <br>    case 0x400: <br>    case 0x600:     // Layer 2 or Layer 3 <br>        return (dw1 &amp; 0x20000) ? 1 : 0; <br> <br>    default:        // Error !! <br>        return 0; <br>    } <br>} <br> <br> <br> <br> <br>/******************************Public*Routine******************************\ <br>* CheckInputType <br>* <br>* <br>* check if you can support mtIn <br>* <br>* <br>\**************************************************************************/ <br>HRESULT <br>CMpegAudioCodec::CheckInputType( <br>    const CMediaType* pmtIn <br>    ) <br>{ <br>    DbgLog((LOG_TRACE, 2, TEXT("CMpegAudioCodec::CheckInputType"))); <br> <br>    //  Check for native streams <br>    if (*pmtIn-&gt;Type() == MEDIATYPE_Stream &amp;&amp; <br>        *pmtIn-&gt;Subtype() == MEDIASUBTYPE_MPEG1Audio) { <br> <br>        /*  This will be checked a bit more in Connect() */ <br>        return S_OK; <br>    } <br> <br> <br>    // check this is an MPEG audio format type <br>    if (*pmtIn-&gt;FormatType() != FORMAT_WaveFormatEx) { <br>        DbgLog((LOG_ERROR, 2, TEXT("\tFormat not FORMAT_WaveFormatEx"))); <br>        return E_INVALIDARG; <br>    } <br> <br>    // we only support MEDIATYPE_Audio <br>    if (*pmtIn-&gt;Type() != MEDIATYPE_Audio) { <br>        DbgLog((LOG_ERROR, 2, TEXT("\tNot MEDIATYPE_Audio"))); <br>        return E_INVALIDARG; <br>    } <br> <br>    if (*pmtIn-&gt;Subtype() != MEDIASUBTYPE_MPEG1Packet &amp;&amp; <br>        *pmtIn-&gt;Subtype() != MEDIASUBTYPE_MPEG1Payload &amp;&amp; <br>        *pmtIn-&gt;Subtype() != MEDIASUBTYPE_MPEG1AudioPayload ) { <br>        DbgLog((LOG_ERROR, 2, TEXT("\tNot MEDIASUBTYPE_MPEG1Packet or Payload"))); <br>        return E_INVALIDARG; <br>    } <br> <br>    // <br>    // Make sure that we have not been given layer III data, we don't know <br>    // how to decode layer III. <br>    // <br>    if (((LPMPEG1WAVEFORMAT)pmtIn-&gt;pbFormat)-&gt;fwHeadLayer == ACM_MPEG_LAYER3) { <br>        DbgLog((LOG_ERROR, 2, TEXT("\tCan't decode layer III data"))); <br>        return E_INVALIDARG; <br>    } <br> <br>    CopyMemory(&amp;m_Format, pmtIn-&gt;pbFormat, sizeof(MPEG1WAVEFORMAT)); <br>    return S_OK; <br>} <br> <br> <br> <br>/******************************Public*Routine******************************\ <br>* CheckTransform <br>* <br>* check if you can support the transform from this input to this output <br>* <br>* <br>\**************************************************************************/ <br>HRESULT <br>CMpegAudioCodec::CheckTransform( <br>    const CMediaType* pmtIn, <br>    const CMediaType* pmtOut <br>    ) <br>{ <br>    DbgLog((LOG_TRACE, 2, TEXT("CMpegAudioCodec::CheckTransform"))); <br> <br>    // we only output audio <br>    if (*pmtOut-&gt;Type() != MEDIATYPE_Audio) { <br>        return S_FALSE; <br>    } <br> <br>    return S_OK; <br>} <br> <br> <br>/******************************Public*Routine******************************\ <br>* SetMediaType <br>* <br>* overriden to know when the media type is actually set <br>* <br>* <br>\**************************************************************************/ <br>HRESULT <br>CMpegAudioCodec::SetMediaType( <br>    PIN_DIRECTION direction, <br>    const CMediaType *pmt <br>    ) <br>{ <br>    if (direction == PINDIR_INPUT) { <br> <br>        // <br>        // Get the data type <br>        // <br>        if (*pmt-&gt;Subtype() == MEDIASUBTYPE_MPEG1Packet) { <br>            m_bPayloadOnly = FALSE; <br>        } <br>        else { <br>            ASSERT(*pmt-&gt;Subtype() == MEDIASUBTYPE_MPEG1Payload || <br>                   *pmt-&gt;Subtype() == MEDIASUBTYPE_MPEG1Audio || <br>                   *pmt-&gt;Subtype() == MEDIASUBTYPE_MPEG1AudioPayload); <br>            m_bPayloadOnly = TRUE; <br>        } <br>    } <br>    else { <br> <br>        LPWAVEFORMATEX lpWf = (LPWAVEFORMATEX)pmt-&gt;pbFormat; <br>        int SamplesPerFrame; <br> <br>        if (m_QuarterInt) { <br>            m_dwCtrl = DECODE_QUART_INT | DECODE_QUARTER; <br>        } <br>        else { <br>            switch (m_FreqDiv) { <br>            case 1: <br>                m_dwCtrl = DECODE_FULL; <br>                break; <br> <br>            case 2: <br>                m_dwCtrl = DECODE_HALF; <br>                break; <br> <br>            case 4: <br>                m_dwCtrl = DECODE_QUARTER; <br>                break; <br>            } <br>        } <br> <br>        switch (lpWf-&gt;wBitsPerSample) { <br>        case 16: <br>            m_dwCtrl |= DECODE_16BIT; <br>            break; <br> <br>        case 8: <br>            m_dwCtrl |= DECODE_8BIT; <br>            break; <br>        } <br> <br>        switch (m_Quality) { <br>        case DECODE_HALF_FULLQ: <br>            m_dwCtrl |= DECODE_HALF_FULLQ; <br>            break; <br> <br>        case DECODE_HALF_HIQ: <br>            m_dwCtrl |= DECODE_HALF_HIQ; <br>            break; <br>        } <br> <br>        switch (lpWf-&gt;nChannels) { <br>        case 2: <br>            m_dwCtrl |= DECODE_STEREO; <br>            break; <br> <br>        case 1: <br>            m_dwCtrl |= DECODE_MONO; <br>            break; <br>        } <br> <br>        if (m_Format.fwHeadLayer == ACM_MPEG_LAYER1) { <br>            SamplesPerFrame = 384; <br>        } <br>        else { <br>            SamplesPerFrame = 1152; <br>        } <br> <br>        m_TimePerFrame = MulDiv(SamplesPerFrame, 10000000, <br>                                m_Format.wfx.nSamplesPerSec); <br> <br>        m_FrameSizeOutput = MulDiv(MulDiv(SamplesPerFrame, <br>                                          lpWf-&gt;wBitsPerSample, 8), <br>                                   lpWf-&gt;nChannels, m_FreqDiv); <br>    } <br>    return S_OK; <br>} <br> <br> <br> <br> <br>/******************************Public*Routine******************************\ <br>* GetMediaType <br>* <br>* Return our preferred output media types (in order) <br>* <br>* <br>\**************************************************************************/ <br>HRESULT <br>CMpegAudioCodec::GetMediaType( <br>    int iPosition, <br>    CMediaType *pmt <br>    ) <br>{ <br>    LPWAVEFORMATEX      lpWf; <br>    LPWAVEFORMATEX      lpWfIn; <br>    LPMPEG1WAVEFORMAT   lpWfInMpeg; <br>    CMediaType          cmt; <br>    int                 SamplesPerFrame; <br>    WORD                nChannels; <br>    WORD                nBitsPerSample; <br> <br>    if (iPosition &lt; 0) { <br>        return E_INVALIDARG; <br>    } <br> <br>    // <br>    // If the requested output word size is 8 bits do not reveal the 16 bits <br>    // per sample option. <br>    // <br>    if (m_WordSize == 8) { <br>        if (iPosition &gt; 0) { <br>            return VFW_S_NO_MORE_ITEMS; <br>        } <br>        iPosition = 1; <br>    } <br> <br>    switch (iPosition) { <br>    case 0: <br>        nBitsPerSample = 16; <br>        break; <br> <br>    case 1: <br>        nBitsPerSample = 8; <br>        break; <br> <br>    default: <br>        return VFW_S_NO_MORE_ITEMS; <br>    } <br> <br>    lpWf = (LPWAVEFORMATEX)pmt-&gt;AllocFormatBuffer(sizeof(WAVEFORMATEX)); <br>    if (lpWf == NULL) { <br>        return E_OUTOFMEMORY; <br>    } <br>    if (*m_pInput-&gt;CurrentMediaType().Type() == MEDIATYPE_Stream) { <br>        lpWfIn = &amp;m_Format.wfx; <br>        lpWfInMpeg = &amp;m_Format; <br>    } else { <br>        lpWfIn = (LPWAVEFORMATEX)m_pInput-&gt;CurrentMediaType().pbFormat; <br>        lpWfInMpeg = (LPMPEG1WAVEFORMAT)m_pInput-&gt;CurrentMediaType().pbFormat; <br>    } <br>    ASSERT(lpWfIn != NULL); <br> <br> <br>    // <br>    // Dump the input format <br>    // <br>    DbgLog((LOG_TRACE, 2, TEXT("nSamplesPerSec = %ld"), lpWfIn-&gt;nSamplesPerSec)); <br>    DbgLog((LOG_TRACE, 2, TEXT("nChannels      = %hd"), lpWfIn-&gt;nChannels)); <br>    DbgLog((LOG_TRACE, 2, TEXT("Layer          = %hd"), lpWfInMpeg-&gt;fwHeadLayer)); <br> <br>    // <br>    // If the number of channels available matches the number preferred <br>    // we decode all the channels available.  Otherwise we decode the <br>    // minimum of the chanels available and the channels preferred. <br>    // <br>    if (lpWfIn-&gt;nChannels == m_PrefChan) { <br>        nChannels = m_PrefChan; <br>    } <br>    else { <br>        nChannels = min(m_PrefChan, lpWfIn-&gt;nChannels); <br>    } <br> <br>    lpWf-&gt;wFormatTag       = WAVE_FORMAT_PCM; <br>    lpWf-&gt;nChannels        = nChannels; <br>    lpWf-&gt;nSamplesPerSec   = lpWfIn-&gt;nSamplesPerSec / m_FreqDiv; <br>    lpWf-&gt;nBlockAlign      = (nBitsPerSample * nChannels) / 8; <br>    lpWf-&gt;nAvgBytesPerSec  = lpWf-&gt;nSamplesPerSec * lpWf-&gt;nBlockAlign; <br>    lpWf-&gt;wBitsPerSample   = nBitsPerSample; <br>    lpWf-&gt;cbSize           = 0; <br> <br>    // <br>    // Dump the ouput format <br>    // <br>    DbgLog((LOG_TRACE, 2, TEXT("!!nSamplesPerSec = %ld"), lpWf-&gt;nSamplesPerSec)); <br>    DbgLog((LOG_TRACE, 2, TEXT("!!nChannels      = %hd"), lpWf-&gt;nChannels)); <br>    DbgLog((LOG_TRACE, 2, TEXT("!!nBlockAlign    = %hd"), lpWf-&gt;nBlockAlign)); <br>    DbgLog((LOG_TRACE, 2, TEXT("!!wBitsPerSample = %hd"), lpWf-&gt;wBitsPerSample)); <br>    DbgLog((LOG_TRACE, 2, TEXT("!!nAvgBytesPerSec= %ld\n"), lpWf-&gt;nAvgBytesPerSec)); <br> <br>    // <br>    // we assume the output format is uncompressed <br>    // <br>    pmt-&gt;SetType(&amp;MEDIATYPE_Audio); <br>    pmt-&gt;SetSubtype(&amp;GUID_NULL); <br>    pmt-&gt;SetFormatType(&amp;FORMAT_WaveFormatEx); <br>    pmt-&gt;SetTemporalCompression(FALSE); <br> <br>    // <br>    // The time per frame and output sample size depend on the layer <br>    // of mpeg audio data being compressed. <br>    // <br>    if (lpWfInMpeg-&gt;fwHeadLayer == ACM_MPEG_LAYER1) { <br>        SamplesPerFrame = 384; <br>    } <br>    else { <br>        SamplesPerFrame = 1152; </code></pre>
<p>
</p>
<pre><code>} <br> <br>    m_TimePerFrame = MulDiv(SamplesPerFrame, 10000000, lpWfIn-&gt;nSamplesPerSec); <br>    m_FrameSizeOutput = MulDiv(MulDiv(SamplesPerFrame, nBitsPerSample, 8), <br>                               nChannels, m_FreqDiv); <br> <br>    pmt-&gt;SetSampleSize(m_FrameSizeOutput * MAX_FRAMES_PER_OUTPUT_SAMPLE); <br>    return S_OK; <br>} <br> <br> <br>/******************************Public*Routine******************************\ <br>* DecideBufferSize <br>* <br>* <br>* Called from CBaseOutputPin to prepare the allocator's count <br>* of buffers and sizes <br>* <br>* <br>\**************************************************************************/ <br>HRESULT <br>CMpegAudioCodec::DecideBufferSize( <br>    IMemAllocator *pAllocator, <br>    ALLOCATOR_PROPERTIES * pProperties <br>    ) <br>{ <br>    DbgLog((LOG_TRACE, 2, TEXT("CMpegAudioCodec::DecideBufferSize"))); <br> <br>    ASSERT(pAllocator); <br>    ASSERT(pProperties); <br>    HRESULT hr = NOERROR; <br> <br>    pProperties-&gt;cBuffers = 8; <br>    pProperties-&gt;cbBuffer = m_pOutput-&gt;CurrentMediaType().GetSampleSize(); <br> <br>    ASSERT(pProperties-&gt;cbBuffer); <br>    DbgLog((LOG_TRACE, 2, TEXT("Sample size = %ld\n"), pProperties-&gt;cbBuffer)); <br> <br>    // Ask the allocator to reserve us some sample memory, NOTE the function <br>    // can succeed (that is return NOERROR) but still not have allocated the <br>    // memory that we requested, so we must check we got whatever we wanted <br> <br>    ALLOCATOR_PROPERTIES Actual; <br>    hr = pAllocator-&gt;SetProperties(pProperties,&amp;Actual); <br>    if (FAILED(hr)) { <br>        return hr; <br>    } <br> <br>    ASSERT(Actual.cbAlign == 1); <br>    ASSERT(Actual.cbPrefix == 0); <br> <br>    if (Actual.cbBuffer &lt; pProperties-&gt;cbBuffer || <br>        Actual.cBuffers &lt; pProperties-&gt;cBuffers) { <br> <br>            // can't use this allocator <br>            return E_INVALIDARG; <br>    } <br>    return S_OK; <br>} <br> <br> <br>/******************************Public*Routine******************************\ <br>* StartStreaming <br>* <br>* <br>\**************************************************************************/ <br>HRESULT <br>CMpegAudioCodec::StartStreaming() <br>{ <br>    CAutoLock       lock(&amp;m_csFilter); <br> <br>    DbgLog((LOG_TRACE, 2, TEXT("CMpegAudioCodec::StartStreaming"))); <br> <br>    m_pAudioDecoder = new CAudioDecoder(this); <br>    if (m_pAudioDecoder == NULL) { <br>        return E_OUTOFMEMORY; <br>    } <br> <br>    ResetAudioDecoder(); <br>    return S_OK; <br>} <br> <br> <br>/******************************Public*Routine******************************\ <br>* StopStreaming <br>* <br>* <br>\**************************************************************************/ <br>HRESULT <br>CMpegAudioCodec::StopStreaming() <br>{ <br>    CAutoLock lock(&amp;m_csFilter); <br>    CAutoLock lck(&amp;m_csReceive); <br>    DbgLog((LOG_TRACE, 2, TEXT("CMpegAudioCodec::StopStreaming"))); <br> <br>    ASSERT(m_pAudioDecoder != NULL); <br> <br>    delete m_pAudioDecoder; <br>    m_pAudioDecoder = NULL; <br> <br>    return S_OK; <br>} <br> <br> <br>/******************************Public*Routine******************************\ <br>* GetDecoderInteger <br>* <br>* <br>\**************************************************************************/ <br>int <br>GetDecoderInteger( <br>    const TCHAR *pKey, <br>    int iDefault <br>    ) <br>{ <br>    HKEY hKey; <br>    LONG lRet; <br>    int  iRet = iDefault; <br> <br>    lRet = RegOpenKey(HKEY_CURRENT_USER, chRegistryKey, &amp;hKey); <br>    if (lRet == ERROR_SUCCESS) { <br> <br>        DWORD   dwType, dwLen; <br> <br>        dwLen = sizeof(iRet); <br>        if (ERROR_SUCCESS != RegQueryValueEx(hKey, pKey, 0L, &amp;dwType, <br>                                             (LPBYTE)&amp;iRet, &amp;dwLen)) { <br>            iRet = iDefault; <br>        } <br>        RegCloseKey(hKey); <br>    } <br>    return iRet; <br>} <br> <br>/******************************Public*Routine******************************\ <br>* SkipToPacketData <br>* <br>* <br>\**************************************************************************/ <br>LPBYTE <br>SkipToPacketData( <br>    LPBYTE pSrc, <br>    long &amp;LenLeftInPacket <br>    ) <br>{ <br>    LPBYTE  lpPacketStart; <br>    DWORD   bData; <br>    long    Length; <br> <br> <br>    // <br>    // Skip the stream ID and extract the packet length <br>    // <br>    pSrc += 4; <br>    bData = *pSrc++; <br>    Length = (long)((bData &lt;&lt; 8) + *pSrc++); <br>    DbgLog((LOG_TRACE, 3, TEXT("Packet length %ld"), Length )); <br> <br> <br>    // <br>    // Record position of first byte after packet length <br>    // <br>    lpPacketStart = pSrc; <br> <br> <br>    // <br>    // Remove stuffing bytes <br>    // <br>    for (; ; ) { <br>        bData = *pSrc++; <br>        if (!(bData &amp; 0x80)) { <br>            break; <br>        } <br>    } <br> <br>    if ((bData &amp; 0xC0) == 0x40) { <br>        pSrc++; <br>        bData = *pSrc++; <br>    } <br> <br>    switch (bData &amp; 0xF1) { <br> <br>    case 0x21: <br>        pSrc += 4; <br>        break; <br> <br>    case 0x31: <br>        pSrc += 9; <br>        break; <br> <br>    default: <br>        if (bData != 0x0F) { <br>            DbgLog((LOG_TRACE, 2, TEXT("Invalid packet - 0x%2.2X\n"), bData)); <br>            return NULL; <br>        } <br>    } <br> <br>    // <br>    // The length left in the packet is the original length of the packet <br>    // less those bytes that we have just skipped over. <br>    // <br>    LenLeftInPacket = Length - (pSrc - lpPacketStart); <br>    return pSrc; <br>} <br> <br> <br>/******************************Public*Routine******************************\ <br>* exported entry points for registration and <br>* unregistration (in this case they only call <br>* through to default implmentations). <br>* <br>* <br>* <br>* History: <br>* <br>\**************************************************************************/ <br>STDAPI <br>DllRegisterServer() <br>{ <br>  return AMovieDllRegisterServer2( TRUE ); <br>} <br> <br>STDAPI <br>DllUnregisterServer() <br>{ <br>  return AMovieDllRegisterServer2( FALSE ); <br>} <br> </code></pre>
<p>&nbsp;</p></body>
</HTML>
