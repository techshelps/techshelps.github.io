<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 3.2 Final//EN">
<HTML dir=ltr>
<HEAD>
<META HTTP-EQUIV="Content-Type" Content="text/html; charset=Windows-1252">
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-83731338-2"></script><script>  window.dataLayer = window.dataLayer || [];  function gtag(){dataLayer.push(arguments);}  gtag('js', new Date());  gtag('config', 'UA-83731338-2');</script><title>MPGVIDEO.CPP</title>
<link disabled rel=stylesheet href=../../../../../backsdk3.css>
<style type="text/css">
@import url(../../../../../backsdk4.css);
</style>
</HEAD>
<BODY BGCOLOR = #FFFFFF TEXT = #000000>
<h2><a name="_code_context2868"></a>MPGVIDEO.CPP</h2>
<pre><code>//==========================================================================; <br>// <br>//  THIS CODE AND INFORMATION IS PROVIDED "AS IS" WITHOUT WARRANTY OF ANY <br>//  KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE <br>//  IMPLIED WARRANTIES OF MERCHANTABILITY AND/OR FITNESS FOR A PARTICULAR <br>//  PURPOSE. <br>// <br>//  Copyright (c) 1992 - 1997  Microsoft Corporation.  All Rights Reserved. <br>// <br>//--------------------------------------------------------------------------; <br>// <br>/******************************Module*Header*******************************\ <br>* Module Name: MpgVideo.cpp <br>* <br>* Implements a prototype Mpeg Video Software codec.  It just consumes <br>* the passed in packets. <br>* <br>\**************************************************************************/ <br>#include "MpgVideo.h" <br> <br>// define the GUIDs for streams and my CLSID in this file <br>#include &lt;initguid.h&gt; <br>#include "mpegUids.h" <br>#include "palette.h" <br> <br> <br>// setup data <br> <br>const AMOVIESETUP_MEDIATYPE <br>psudIpPinTypes[] = { { &amp;MEDIATYPE_Video                // clsMajorType <br>                     , &amp;MEDIASUBTYPE_MPEG1Packet  }    // clsMinorType <br>                   , { &amp;MEDIATYPE_Video                // clsMajorType <br>                     , &amp;MEDIASUBTYPE_MPEG1Payload } }; // clsMinorType <br> <br>const AMOVIESETUP_MEDIATYPE <br>sudOpPinTypes = { &amp;MEDIATYPE_Video      // clsMajorType <br>                , &amp;MEDIASUBTYPE_NULL }; // clsMinorType <br> <br>const AMOVIESETUP_PIN <br>psudPins[] = { { L"Input"            // strName <br>               , FALSE               // bRendered <br>               , FALSE               // bOutput <br>               , FALSE               // bZero <br>               , FALSE               // bMany <br>               , &amp;CLSID_NULL         // clsConnectsToFilter <br>               , L"Output"           // strConnectsToPin <br>               , 2                   // nTypes <br>               , psudIpPinTypes }    // lpTypes <br>             , { L"Output"           // strName <br>               , FALSE               // bRendered <br>               , TRUE                // bOutput <br>               , FALSE               // bZero <br>               , FALSE               // bMany <br>               , &amp;CLSID_NULL         // clsConnectsToFilter <br>               , L"Input"            // strConnectsToPin <br>               , 1                   // nTypes <br>               , &amp;sudOpPinTypes } }; // lpTypes <br> <br> <br> <br>const AMOVIESETUP_FILTER <br>sudMPEGVideo = { &amp;CLSID_CMpegFrameworkVideoCodec // clsID <br>               , L"MPEG Framework Audio Codec"   // strName <br>               , 0x00600000                      // dwMerit <br>               , 2                               // nPins <br>               , psudPins };                     // lpPin <br> <br>/* ------------------------------------------------------------------------- <br>** list of class ids and creator functions for class factory <br>** ------------------------------------------------------------------------- <br>*/ <br>CFactoryTemplate g_Templates[] = <br>{ <br>    {L"MPEG Framework Video Codec" <br>    , &amp;CLSID_CMpegFrameworkVideoCodec <br>    , CMpegVideoCodec::CreateInstance <br>    , NULL <br>    , &amp;sudMPEGVideo } <br>}; <br> <br>int g_cTemplates = sizeof(g_Templates) / sizeof(g_Templates[0]); <br> <br> <br>const TCHAR chRegistryKey[] = <br>    TEXT("Software\\Microsoft\\Multimedia\\ActiveMovie Filters\\Sample MPEG Video Decoder"); <br> <br> <br>/******************************Public*Routine******************************\ <br>* GetDecoderInt <br>* <br>* <br>* <br>* History: <br>* <br>* <br>\**************************************************************************/ <br>int <br>GetDecoderInt( <br>    const TCHAR *pKey, <br>    int iDefault <br>    ) <br>{ <br>    HKEY hKey; <br>    LONG lRet; <br>    int  iRet = iDefault; <br> <br>    lRet = RegOpenKey(HKEY_CURRENT_USER, chRegistryKey, &amp;hKey); <br>    if (lRet == ERROR_SUCCESS) { <br> <br>        DWORD   dwType, dwLen; <br> <br>        dwLen = sizeof(iRet); <br>        if (ERROR_SUCCESS != RegQueryValueEx(hKey, pKey, 0L, &amp;dwType, <br>                                             (LPBYTE)&amp;iRet, &amp;dwLen)) { <br>            iRet = iDefault; <br>        } <br>        RegCloseKey(hKey); <br>    } <br>    return iRet; <br>} <br> <br> <br> <br>/* ------------------------------------------------------------------------- <br>** CMpegVideoCodec <br>** ------------------------------------------------------------------------- <br>*/ <br>CMpegVideoCodec::CMpegVideoCodec( <br>    TCHAR *pName, <br>    LPUNKNOWN pUnk, <br>    HRESULT *phr <br>    ) <br>    : CTransformFilter(pName, pUnk, CLSID_CMpegVideoCodec), <br>      m_pVideoDecoder(NULL), <br>      m_PtsQueue(NAME("Pts queue"), 30, FALSE, FALSE), <br>      m_pFrameBuff(NULL), <br>      m_Buffer(NULL), <br>      m_pOutSample(NULL) <br>{ <br>    // <br>    // Pick up any user preferences - this should get moved to the register <br>    // <br>    m_IgnoreQualityMessage = GetDecoderInt(TEXT("IgnoreQMessages"), FALSE); <br> <br>    m_dwCtrlDefault = GetDecoderInt(TEXT("VideoFramesDecoded"), DECODE_IPB); <br>    m_dwCtrlDefault &amp;= 0x3F; <br> <br>    m_dwQualDefault = GetDecoderInt(TEXT("VideoQuality"), 0); <br>    m_dwQualDefault &amp;= 0x30000000; <br>    m_dwCtrl = (m_dwCtrlDefault | m_dwQualDefault); <br> <br> <br>    if (GetDecoderInt(TEXT("GreyScale"), 0)) { <br>        m_PaletteType = GREY_PALETTE; <br>        m_dwOutputFormatDib = MM_Y_DIB; <br>        m_dwOutputFormatDdb = MM_Y_DDB; <br>    } <br>    else { <br>        m_PaletteType = COLOUR_PALETTE; <br>        m_dwOutputFormatDib = MM_RGB8_DIB; <br>        m_dwOutputFormatDdb = MM_RGB8_DDB; <br>    } <br> <br>    // <br>    // Reset frame stats <br>    // <br>    ZeroMemory(m_dwFramesSkipped, sizeof(m_dwFramesSkipped)); <br>    ZeroMemory(m_dwFramesDecoded, sizeof(m_dwFramesDecoded)); <br> <br>    m_PerfDecode = MSR_REGISTER(TEXT("Decode Time  - Start/Stop")); <br>    m_QualMsg = MSR_REGISTER(TEXT("Quality Message")); <br>    m_FrameDrawn = MSR_REGISTER(TEXT("Frame Drawn")); <br>    m_FrameType = MSR_REGISTER(TEXT("Frame Type")); <br>} <br> <br> <br>CMpegVideoCodec::~CMpegVideoCodec( <br>    ) <br>{ <br>    CTimePosition   *pTimePos; <br> <br>    DbgLog((LOG_TRACE, 2, TEXT("CMpegVideoCodec::~CMpegVideoCodec"))); <br> <br>    delete m_pVideoDecoder; <br>    m_pVideoDecoder = NULL; <br> <br>    delete [] m_pFrameBuff; <br>    m_pFrameBuff = NULL; <br> <br>    delete [] m_Buffer; <br>    m_Buffer = NULL; <br> <br> <br>    // <br>    // Purge the PTS queue. <br>    // <br>    while( (pTimePos = m_PtsQueue.RemoveHead()) != NULL) { <br>        delete pTimePos; <br>    } <br> <br>    // <br>    // This should have been deleted in BreakConnect <br>    // <br>    ASSERT(m_Buffer == NULL); <br>} <br> <br> <br> <br>/******************************Public*Routine******************************\ <br>* CreateInstance <br>* <br>* This goes in the factory template table to create new instances <br>* <br>\**************************************************************************/ <br>CUnknown * <br>CMpegVideoCodec::CreateInstance( <br>    LPUNKNOWN pUnk, <br>    HRESULT * phr <br>    ) <br>{ <br>    DbgLog((LOG_TRACE, 2, TEXT("CMpegVideoCodec::CreateInstance"))); <br>    return new CMpegVideoCodec(TEXT("MPEG Video codec filter"), pUnk, phr); <br>} <br> <br> <br>/******************************Public*Routine******************************\ <br>* NonDelegatingQueryInterface <br>* <br>* Here we would reveal ISpecifyPropertyPages and IMpegVideoDecoder if <br>* the framework had a property page. <br>* <br>\**************************************************************************/ <br>STDMETHODIMP <br>CMpegVideoCodec::NonDelegatingQueryInterface( <br>    REFIID riid, <br>    void ** ppv <br>    ) <br>{ <br>    return CTransformFilter::NonDelegatingQueryInterface(riid, ppv); <br>} <br> <br> <br>/******************************Public*Routine******************************\ <br>* EndOfStream <br>* <br>* <br>* <br>\**************************************************************************/ <br>HRESULT <br>CMpegVideoCodec::EndOfStream() <br>{ <br>    DbgLog((LOG_TRACE, 2, TEXT("End of stream called"))); <br>    CAutoLock lck(&amp;m_csReceive); <br> <br>    if (m_pVideoDecoder == NULL) { <br>        return VFW_E_WRONG_STATE; <br>    } <br> <br>    DecodeUntilBufferEmpty(); <br>    ResetVideoDecoder(); <br>    return CTransformFilter::EndOfStream(); <br>} <br> <br> <br>/******************************Public*Routine******************************\ <br>* EndFlush <br>* <br>* <br>* <br>\**************************************************************************/ <br>HRESULT <br>CMpegVideoCodec::EndFlush() <br>{ <br>    DbgLog((LOG_TRACE, 2, TEXT("End flush called"))); <br>    CAutoLock lck(&amp;m_csReceive); <br>    ResetVideoDecoder(); <br>    return CTransformFilter::EndFlush(); <br>} <br> <br> <br>/******************************Public*Routine******************************\ <br>* Receive <br>* <br>* Copy the input sample into our buffer.  Loop while the buffer size is <br>* greater than or equal to the size given in the Vbv for the next picture <br>* decode the picture and pass it along to the output pin for rendering. <br>* <br>\**************************************************************************/ <br>HRESULT <br>CMpegVideoCodec::Receive( <br>    IMediaSample *pSample <br>    ) <br>{ <br>    // <br>    //  Make sure the pin doesn't go inactive on us <br>    // <br> <br>    HRESULT   hr; <br>    CAutoLock lck(&amp;m_csReceive); <br> <br>    if (m_pVideoDecoder == NULL || m_pFrameBuff == NULL) { <br>        return E_UNEXPECTED; <br>    } <br> <br>    // <br>    // Check for a discontinuity, if one is found decode and display any <br>    // frames left in the circular buffer, reset the decoder and then continue <br>    // processing the current sample. <br>    // <br>    if (pSample-&gt;IsDiscontinuity() == S_OK) { <br> <br>        DecodeUntilBufferEmpty(); <br>        ResetVideoDecoder(); <br> <br>        // <br>        //  Find out what the current stop time is... <br>        //  ... get logical duration from upstream <br>        // <br>        HRESULT hrPos; <br>        REFTIME dStart, dStop; <br>        IMediaPosition *pPosition = NULL; <br> <br>        hrPos = m_pInput-&gt;GetConnected()-&gt;QueryInterface(IID_IMediaPosition, <br>                                                         (void **)&amp;pPosition); <br> <br>        if ( SUCCEEDED(hrPos) <br>          &amp;&amp; pPosition != NULL <br>          &amp;&amp; SUCCEEDED(pPosition-&gt;get_CurrentPosition(&amp;dStart)) <br>          &amp;&amp; SUCCEEDED(pPosition-&gt;get_StopTime(&amp;dStop))) <br>        { <br>            m_tStop = <br>                (CRefTime)(COARefTime)dStop - (CRefTime)(COARefTime)dStart; <br>        } <br>        else { <br>            m_tStop = 0x7FFFFFFFFFFFFFFF; <br>        } <br> <br>        if (pPosition != NULL) { <br>            pPosition-&gt;Release(); <br>        } <br> <br>        DbgLog((LOG_TRACE, 2, <br>                TEXT("Receive() : Discontinuity - setting stop time to %s"), <br>                (LPCTSTR)CDisp(m_tStop))); <br>    } <br> <br>    m_pSample = NULL; <br>    m_LenLeftInPacket = 0L; <br> <br>    // <br>    // If this sample is a sync point we need to <br>    // update our clock and reset the count of <br>    // samples received since the last sync point. <br>    // <br> <br>    if (pSample-&gt;IsSyncPoint() == S_OK) { <br> <br>        CRefTime        tStart, tStop; <br>        CTimePosition   *pTimePos; <br> <br>        pSample-&gt;GetTime((REFERENCE_TIME*)&amp;tStart, <br>                         (REFERENCE_TIME*)&amp;tStop); <br> <br>        pTimePos = new CTimePosition(&amp;tStart, <br>                                     m_BufferCurr + m_BufferFullness &gt;= m_BufferStart + m_VBlockSize ? <br>                                     m_BufferCurr + m_BufferFullness - m_VBlockSize : m_BufferCurr + m_BufferFullness); <br> <br>        DbgLog(( LOG_TRACE, 4, TEXT("PTS: %s  Buffer pos: %ld"), <br>                 (LPCTSTR)CDisp(tStart), m_BufferCurr + m_BufferFullness )); <br>        m_PtsQueue.AddTail(pTimePos); <br> <br>    } <br> <br>    // <br>    // Decode and if necessary display as many frames as <br>    // possible until we exhaust our circular buffer. <br>    // <br> <br>    do { <br> <br>        hr = CopySampleToBuffer(pSample); <br> <br>        while (SUCCEEDED(hr) &amp;&amp; (m_BufferFullness &gt;= m_seqInfo.lvbv)) { <br> <br>            hr = DecodeNextPicture(); <br>        } <br> <br>    } while (S_OK == hr &amp;&amp; (m_LenLeftInPacket != 0L)); <br> <br>    return hr; <br>} <br> <br> <br>/*****************************Private*Routine******************************\ <br>* ResetVideoDecoder <br>* <br>* <br>* <br>\**************************************************************************/ <br>void <br>CMpegVideoCodec::ResetVideoDecoder() <br>{ <br>    // <br>    // Make him eat our sequence header <br>    // <br>    // m_BufferStart = m_BufferCurr = m_Buffer-&gt;GetPointer(); <br>    m_BufferStart = m_BufferCurr = m_Buffer; <br>    m_BufferFullness = m_seqInfo.lActualHeaderLen; <br> <br>    CopyMemory(m_BufferStart, m_seqInfo.RawHeader, m_seqInfo.lActualHeaderLen); <br> <br>    m_TimeSinceLastSyncPoint = 0L; <br>    m_pOutSample = NULL; <br> <br>    // <br>    // Don't play anything until we get a sync point <br>    // but don't make it too negative or we'll overflow! <br>    // <br>    m_TimeAtLastSyncPoint = (LONGLONG)-0x7FFFFFFFFFFFFF; <br>    m_tStopPrev = m_TimeAtLastSyncPoint; <br> <br>    m_pVideoDecoder-&gt;ResetVideo(); <br> <br> <br>    // <br>    // Purge the PTS queue. <br>    // <br>    CTimePosition *pTimePos; <br>    while( (pTimePos = m_PtsQueue.RemoveHead()) != NULL) { <br>        delete pTimePos; <br>    } <br> <br> <br>    // <br>    // Reset IP tracking <br>    // <br>    m_NextIP.Reset(); <br> <br>} <br> <br> <br>/*****************************Private*Routine******************************\ <br>* DecodeUntilBufferEmpty <br>* <br>* <br>* <br>\**************************************************************************/ <br>void <br>CMpegVideoCodec::DecodeUntilBufferEmpty() <br>{ <br>    HRESULT hr = S_OK; <br> <br>    while (SUCCEEDED(hr) &amp;&amp; (m_BufferFullness &gt; 0)) { <br> <br>        LPBYTE pCurrentCurr = m_BufferCurr; <br> <br>        DbgLog((LOG_TRACE, 3, TEXT("Forcing out a frame"))); <br>        hr = DecodeNextPicture(); <br> <br>        if (S_OK != hr || m_BufferCurr == pCurrentCurr) { <br> <br>            // <br>            // We're not making any progress! <br>            // <br>            DbgLog((LOG_ERROR, 2, <br>                    TEXT("CMpegVideoCodec::DecodeUntilBufferEmpty() ") <br>                    TEXT("- Stuck with %d bytes in buffer"), <br>                    m_BufferFullness)); <br>            break; <br>        } <br>    } <br> <br>    // <br>    // Now see if there's a frame decoded but not presented <br>    // <br>    if (m_NextIP.TimeToDraw()) { <br> <br>        DbgLog((LOG_TRACE, 2, TEXT("Trying to get last frame"))); <br> <br>        DWORD dwCtrl = m_dwCtrl; <br>        m_dwCtrl &amp;= 0xFFFF0000; <br>        m_dwCtrl |= DECODE_DIS; <br> <br>        if (S_OK != DecodeNextPicture()) { <br>            DbgLog((LOG_ERROR, 2, TEXT("Failed to display last frame"))); <br>        } <br> <br>        m_dwCtrl = dwCtrl; // Restore <br>    } <br>} <br> <br> <br>/*****************************Private*Routine******************************\ <br>* GetDecodeBufferAndFormat <br>* <br>* This function is called by the mpeg decoder when it is time to determine <br>* the colour conversion format and the destination buffer pointer for the <br>* frame. <br>* <br>\**************************************************************************/ <br>LPBYTE <br>CMpegVideoCodec::GetDecodeBufferAndFormat() <br>{ <br>    unsigned char   *pDst; <br>    AM_MEDIA_TYPE      *pmt; <br>    CRefTime        tStartTime(m_tStopPrev); <br>    CRefTime        tStopTime; <br> <br>    // Don't ask for a buffer with a negative start time. <br>    if (tStartTime &lt; (LONGLONG)0) { <br>        tStartTime = (LONGLONG)0; <br>    } <br> <br>    // <br>    // this may block for an indeterminate amount of time <br>    // <br>    tStopTime = tStartTime + m_seqInfo.tPictureTime; <br>    hrCallback = m_pOutput-&gt;GetDeliveryBuffer(&amp;m_pOutSample, <br>                                              (REFERENCE_TIME*)&amp;tStartTime, <br>                                              (REFERENCE_TIME*)&amp;tStopTime, <br>                                              0 // Must set proper flag <br>                                                // if prev frame skipped <br>                                              ); <br>    if (FAILED(hrCallback)) { <br>        return NULL; <br>    } <br>    ASSERT(m_pOutSample); <br> <br>    hrCallback = m_pOutSample-&gt;GetPointer(&amp;pDst); <br>    if (FAILED(hrCallback)) { <br>        return NULL; <br>    } <br>    ASSERT(pDst); <br> <br>    // <br>    // If the media type has changed then pmt is NOT NULL <br>    // <br>    m_pOutSample-&gt;GetMediaType(&amp;pmt); <br>    if (pmt != NULL) { <br>        CMediaType cmt(*pmt); <br>        DeleteMediaType(pmt); <br>        SetOutputPinMediaType(&amp;cmt); <br>    } <br>    return pDst; <br>} <br> <br> <br>/*****************************Private*Routine******************************\ <br>* DecodeNextPicture <br>* <br>* Decodes the next picture stored in the circular buffer.  If the picture <br>* is not "skipped" it is passed to the output pin.  Updates m_BufferStart, <br>* m_BufferCurr and m_BufferFullness to reflect any emptying of the buffer that <br>* has taken place. <br>* <br>\**************************************************************************/ <br>HRESULT <br>CMpegVideoCodec::DecodeNextPicture() <br>{ <br>    DWORD   rc; <br>    HRESULT hr = S_OK; <br> <br>    // <br>    // ParthaSr. <br>    // trying to recover from the absence of quality messages <br>    // when I do a skip - so I am predictively skipping <br>    // frames.  - Snap back to default if I have already <br>    // skipped enough frames <br>    // <br>    if (m_dwLateBy &lt; 750000L) { <br>        m_dwCtrl = m_dwCtrlDefault | m_dwQualDefault; <br>    } <br> <br>    m_VideoControl.dwCtrl = m_dwCtrl; <br> <br>    // <br>    // If we're within 1 second of the end do all IP <br>    // <br>    if (m_tStop - m_tStopPrev &lt; CRefTime(1000L)) { <br> <br>        // <br>        // But are we almost at the end? in which case we need to decode <br>        // everything <br>        // <br>        if (m_tStop - m_tStopPrev &lt; CRefTime(m_seqInfo.tPictureTime) + <br>                                    CRefTime(m_seqInfo.tPictureTime)) { <br> <br>            if ((m_dwCtrl &amp; 0xFFFF) != DECODE_DIS) { <br>                m_VideoControl.dwCtrl = (m_dwCtrl &amp; 0xFFFF0000) | DECODE_IPB; <br>            } <br>        } <br>        else { <br> <br>            if ((m_dwCtrl &amp; 0xFFFF) &lt; DECODE_IP) { <br>                m_VideoControl.dwCtrl = (m_dwCtrl &amp; 0xFFFF0000) | DECODE_IP; <br>            } <br>        } <br>    } <br>    else { <br> <br>        // <br>        // Only do IP if we're before the start <br>        // <br>        if ((m_dwCtrl &amp; 0x3F) &gt; DECODE_IP) { <br> <br>            if (m_tStopPrev <br>              + CRefTime(m_seqInfo.tPictureTime) <br>              + CRefTime(m_seqInfo.tPictureTime) &lt; CRefTime(0L)) { <br> <br>                m_VideoControl.dwCtrl = (m_dwCtrl &amp; 0xFFFF0000) | DECODE_IP; <br>            } <br> <br>        } <br>    } <br>    DbgLog((LOG_TRACE, 4, TEXT("Decode flags = %X"), m_VideoControl.dwCtrl)); <br> <br> <br>    // <br>    // Initialize the video codec with the new video data buffer.  I am <br>    // assuming that there is at least one video frame in the data <br>    // buffer.  When this function gets called to force out the frames <br>    // left in the buffer it needs to guarded with a try except block. <br>    // <br>    m_VideoControl.pCmprWrite  = m_BufferCurr + m_BufferFullness; <br>    m_VideoControl.pCmprRead   = m_BufferCurr; <br> <br>    // <br>    // This is where the action starts, call the codec and let it do it stuff. <br>    // <br> <br>    //  Don't die if Windows NT takes away the DCI surface <br>    try { <br> <br>        MSR_START(m_PerfDecode); <br>        rc = m_pVideoDecoder-&gt;DecodeFrame(&amp;m_VideoControl); <br>        MSR_STOP(m_PerfDecode); <br>    } <br>    except(EXCEPTION_EXECUTE_HANDLER) { <br> <br>        DbgLog((LOG_ERROR, 1, TEXT("Exception in decoder!"))); <br>        rc = DECODE_ERR_DATA; <br>    } <br> <br>    // <br>    // Did the frame decode OK <br>    // <br> <br>    if (rc == DECODE_SUCCESS) { <br> <br>#ifdef DEBUG <br>        static char *ft[4] = { "Dummy", "I", "P", "B" }; <br>#endif <br> <br>        // <br>        // Record frames stats <br>        // <br>        MSR_INTEGER(m_FrameType, m_VideoControl.dwFrameType); <br>        if (m_VideoControl.dwSkipFlag) { <br> <br>            DbgLog((LOG_TRACE, 2, TEXT("%hs Frame skipped"), <br>                    ft[m_VideoControl.dwFrameType])); <br> <br>            m_dwFramesSkipped[m_VideoControl.dwFrameType]++; <br> <br>            LARGE_INTEGER li; <br>            li.QuadPart = m_seqInfo.tPictureTime; <br>            if (m_dwLateBy &gt; li.LowPart) { <br>                m_dwLateBy -= li.LowPart; <br>            } <br>        } <br>        else { <br>            m_dwFramesDecoded[m_VideoControl.dwFrameType]++; <br>        } <br> <br>        if (m_VideoControl.dwFrameType == FTYPE_I || <br>            m_VideoControl.dwFrameType == FTYPE_P) { <br> <br>            // <br>            //  Do I/P - we're actually going to draw the I/P we <br>            //  decoded last time we got one, not the present one <br>            // <br> <br>            if (m_NextIP.GetTime((REFERENCE_TIME *)&amp;m_TimeAtLastSyncPoint)) { <br>                m_TimeSinceLastSyncPoint = 0; <br>            } <br> <br>            REFERENCE_TIME t; <br>            BOOL bIFrame = m_VideoControl.dwFrameType == FTYPE_I; <br> <br>            if (UpdateTimeSyncPoint(m_VideoControl.pFrameStartPos, &amp;t)) { <br>                m_NextIP.Set(m_VideoControl.dwSkipFlag, bIFrame, <br>                             TRUE, t, m_VideoControl.dwTemporalReference); <br>            } <br>            else { <br>                m_NextIP.Set(m_VideoControl.dwSkipFlag, bIFrame, <br>                             FALSE, t, m_VideoControl.dwTemporalReference); <br>            } <br>        } <br>        else { <br> <br>            // <br>            //  Do B <br>            // <br>            m_NextIP.NextRef(m_VideoControl.dwTemporalReference); <br>            if ( UpdateTimeSyncPoint(m_VideoControl.pFrameStartPos, <br>                                     (REFERENCE_TIME*)&amp;m_TimeAtLastSyncPoint) ) { <br>                m_TimeSinceLastSyncPoint = 0; <br>            } <br>        } <br> <br>        CRefTime tStop(m_TimeAtLastSyncPoint + m_TimeSinceLastSyncPoint + <br>                       m_seqInfo.tPictureTime); <br> <br>        if (!m_VideoControl.dwSkipFlag) { <br> <br>            LPBITMAPINFOHEADER  lpbiDst = HEADER(m_pOutput-&gt;CurrentMediaType().Format()); <br> <br>            // <br>            // if the time is &lt; 0, then this is preroll to get from keyframe to <br>            // the current frame. We decompress it into the output buffer but <br>            // don't deliver it. <br>            // <br>            // In order that there are no gaps we actually start the next <br>            // frame where we predicted it would start, rather than the <br>            // actual synch point <br>            // <br> <br>            CRefTime tStart(m_tStopPrev); <br> <br>            DbgLog((LOG_TRACE, 2, <br>                    TEXT("%hs Frame decoded - tStart = %s, tStop = %s"), <br>                    ft[m_VideoControl.dwFrameType], <br>                    (LPCTSTR)CDisp(tStart), (LPCTSTR)CDisp(tStop))); <br> <br> <br>            #pragma message (REMIND("Do Preroll right")) <br>            if (tStop &gt; 0L &amp;&amp; tStart &lt;= m_tStop) { <br> <br>                // decompressed frames are always key <br>                m_pOutSample-&gt;SetSyncPoint(TRUE); <br>                m_pOutSample-&gt;SetActualDataLength(lpbiDst-&gt;biSizeImage); <br>                m_pOutSample-&gt;SetTime((REFERENCE_TIME*)&amp;tStart, <br>                                      (REFERENCE_TIME*)&amp;tStop); <br> <br>                DbgLog((LOG_TRACE, 2, TEXT("%hs Frame sent to next filter"), <br>                        ft[m_VideoControl.dwFrameType])); <br> <br> <br>                hr = m_pOutput-&gt;Deliver(m_pOutSample); <br>                MSR_NOTE(m_FrameDrawn); <br>            } <br>        } <br> <br>        // <br>        // We have successfully decoded a frame. <br>        // Set the new position <br>        // <br>        m_tStopPrev = tStop; <br>        UpdateBufferPosition(m_VideoControl.pCmprRead); <br>        m_TimeSinceLastSyncPoint += m_seqInfo.tPictureTime; <br>    } <br>    else if (rc == DECODE_ERR_QUARTZ) { <br> <br>        DbgLog((LOG_ERROR, 2, <br>                TEXT("Could not get buffer from down stream filter"))); <br>        hr = hrCallback; <br>    } <br>    else if (rc == DECODE_ERR_DATA) { <br> <br>        // <br>        // We did not have enough data available to decode the <br>        // current frame, so save the data for next time. <br>        // <br>        // Since this can only happen at a discontinuity, end of <br>        // stream or undecipherable data we'll just throw the data <br>        // away if it can't be eaten <br>        DbgLog((LOG_ERROR, 2, TEXT("Buffer underflow") )); <br> <br>        UpdateBufferPosition(m_VideoControl.pCmprRead); <br> <br>        // <br>        //  Notify the filter graph of stream errors <br>        // <br>        NotifyEvent(EC_STREAM_ERROR_STILLPLAYING, hr, 0); <br>    } <br>    else { <br> <br>        // <br>        // Some sort of error occurred, throw the remainder of the <br>        // buffer away and skip this packet. <br>        // <br>        DbgLog((LOG_ERROR, 2, <br>                TEXT("Bad return code %d from MediaMatics video codec!"), rc )); <br>        UpdateBufferPosition(m_VideoControl.pCmprRead); <br> <br>        // <br>        //  Notify the filter graph of stream errors <br>        // <br>        NotifyEvent(EC_STREAM_ERROR_STILLPLAYING, hr, 0); <br>    } <br> <br> <br>    // <br>    // release the output buffer. If the connected pin still needs it, <br>    // it will have addrefed it itself. <br>    // <br>    if (m_pOutSample != NULL) { <br>        m_pOutSample-&gt;Release(); <br>        m_pOutSample = NULL; <br>    } <br> <br>    return hr; <br>} <br> <br> <br>/*****************************Private*Routine******************************\ <br>* CopySampleToBuffer <br>* <br>* Copies the sample to the input buffer and returns the number of bytes <br>* present in the buffer.  Updates m_BufferStart, m_BufferCurr and <br>* m_BufferFullness to reflect any wrapping in the buffer <br>* that may have occurred. <br>* <br>\**************************************************************************/ <br>HRESULT <br>CMpegVideoCodec::CopySampleToBuffer( <br>    IMediaSample *pSample <br>    ) <br>{ <br>    BYTE    *pSrc; <br>    long    LenLeftInBuffer; <br>    long    AmountToCopy; <br>    HRESULT hr; <br> <br>    if (m_pSample == NULL) { <br> <br>        hr = pSample-&gt;GetPointer(&amp;pSrc); <br>        if (FAILED(hr)) { <br>            return hr; <br>        } <br>        ASSERT(pSrc); <br> <br>        // Skip pass the stream header and extract the packet length. <br>        // <br>        if (m_bPayloadOnly) { <br>            m_pSample = pSrc; <br>            m_LenLeftInPacket = pSample-&gt;GetActualDataLength(); <br>        } <br>        else { <br>            m_pSample = SkipToPacketData(pSrc, m_LenLeftInPacket); <br>            if (m_pSample == NULL) { <br>                return E_INVALIDARG; <br>            } <br>        } <br>    } <br> <br> <br>    // <br>    // Move what remains in the video data buffer to the top of the buffer <br>    // and append the new video data to it. <br>    // Don't ever let it fill up completely or we'll have to worry about <br>    // full vs empty <br>    // <br>    LenLeftInBuffer = m_VBlockSize - m_BufferFullness; <br> <br>    AmountToCopy = min(LenLeftInBuffer, m_LenLeftInPacket); <br>    CopyMemory(m_BufferCurr + m_BufferFullness, m_pSample, AmountToCopy); <br> <br> <br>    m_LenLeftInPacket -= AmountToCopy; <br>    m_pSample         += AmountToCopy; <br>    m_BufferFullness  += AmountToCopy; <br> <br>    return S_OK; <br>} <br> <br> <br>/*****************************Private*Routine******************************\ <br>* UpdateBufferPosition <br>* <br>* Updates m_BufferCurr from the new position passed in. <br>* Checks if m_BufferCurr is in the 'virtual' space at the end of the buffer <br>* and if it is adjusts m_BufferCurrent and m_BufferFullness down by the real <br>* buffer size <br>* <br>\**************************************************************************/ <br>void <br>CMpegVideoCodec::UpdateBufferPosition( <br>    LPBYTE lpNewCurrent <br>    ) <br>{ <br>    ASSERT(lpNewCurrent &gt;= m_BufferCurr); <br> <br>    // <br>    // Sometimes the position gets reported as 1 too many (!) <br>    // <br>    if (lpNewCurrent &gt; m_BufferCurr + m_BufferFullness) { <br>        lpNewCurrent = m_BufferCurr + m_BufferFullness; <br>    } <br>    m_BufferFullness -= lpNewCurrent - m_BufferCurr; <br>    if (lpNewCurrent &gt;= (m_BufferStart + m_VBlockSize)) { <br>        lpNewCurrent -= m_VBlockSize; <br>    } <br> <br>    // <br>    // Fix up the time code list <br>    // <br>    while (TRUE) { <br> <br>        POSITION pos = m_PtsQueue.GetHeadPosition(); <br>        if (pos == NULL) { <br>            break; <br>        } <br> <br>        CTimePosition *pTimePos = m_PtsQueue.Get(pos); <br> <br>        if (BuffOffset(pTimePos-&gt;m_BufferPosition) &lt; BuffOffset(lpNewCurrent)) { <br>            delete pTimePos; <br>            m_PtsQueue.RemoveHead(); <br>        } <br>        else { <br>            break; <br>        } <br>    } <br> <br>    // <br>    //  Advance to the new position <br>    // <br>    // m_BufferCurr = lpNewCurrent; <br>    MoveMemory(m_BufferCurr, lpNewCurrent, m_BufferFullness); <br>} <br> <br> <br> <br> <br>/*****************************Private*Routine******************************\ <br>* UpdateTimeSyncPoint <br>* <br>* Each time we get a media sample with a Pts <br>* time stamp we add a TIMEPOSITION entry to a queue of time positions. <br>* Each time we decode an I frame we record the starting and ending position <br>* of the I frame picture within the input buffer, this information is <br>* then used to find a suitable time stamp to associate with the frame.  If <br>* a suitable time stamp cannot be found or the frame is not an I frame we <br>* calculate a suitable time code by extrapolation. <br>* <br>\**************************************************************************/ <br>BOOL <br>CMpegVideoCodec::UpdateTimeSyncPoint( <br>    LPBYTE lpPicStart, <br>    REFERENCE_TIME *Time <br>    ) <br>{ <br>    POSITION  pos = m_PtsQueue.GetHeadPosition(); <br>    BOOL      bFound; <br> <br>    for (bFound = FALSE; pos != NULL; ) { <br>        CTimePosition *pTimePos = m_PtsQueue.GetNext(pos); <br> <br>        if (BuffOffset(pTimePos-&gt;m_BufferPosition) &lt;= BuffOffset(lpPicStart)) { <br> <br>            //  Buffer start time stamp could be for us (but keep looking <br>            //  in case there's a better one) <br>            // <br>            //  NOTE this ASSUMES there are no packets with time stamps but no <br>            //  start code so in fact this one should be ours <br> <br>            bFound = TRUE; <br>            *Time  = pTimePos-&gt;m_PtsTimeStamp; </code></pre>
<p>
</p>
<pre><code>delete pTimePos; <br>            m_PtsQueue.RemoveHead(); <br>        } <br>        else { <br>            break; <br>        } <br>    } <br> <br>    if (bFound) { <br>        DbgLog((LOG_TRACE, 3, <br>                TEXT("CMpegVideoCodec::UpdateTimeSyncPoint() : Found time %s"), <br>                (LPCTSTR)CDisp(*Time) )); <br>    } <br> <br>    return bFound; <br>} <br> <br> <br> <br>/*****************************Private*Routine******************************\ <br>* BuffOffset <br>* <br>* Adjusts the supplied offset so that is based upon m_BufferCurr <br>* <br>\**************************************************************************/ <br>inline ptrdiff_t <br>CMpegVideoCodec::BuffOffset( <br>    LPBYTE Offset <br>    ) <br>{ <br>    ptrdiff_t x = Offset - m_BufferCurr; <br>    if (x &lt; 0) { <br>        x += m_VBlockSize; <br>    } <br>    return x; <br>} <br> <br> <br>/******************************Public*Routine******************************\ <br> <br>* CheckInputType <br>* <br>* Check if you can support mtIn <br>* <br>\**************************************************************************/ <br>HRESULT <br>CMpegVideoCodec::CheckInputType( <br>    const CMediaType* pmtIn <br>    ) <br>{ <br>    DbgLog((LOG_TRACE, 2, TEXT("CMpegVideoCodec::CheckInputType"))); <br> <br>    // <br>    //  Check for native streams <br>    // <br> <br>    if (*pmtIn-&gt;Type() == MEDIATYPE_Stream &amp;&amp; <br>        *pmtIn-&gt;Subtype() == MEDIASUBTYPE_MPEG1Video) { <br> <br>        // <br>        //  If there's no format block we'll read the stream during <br>        //  CompleteConnect() <br>        // <br>        if (pmtIn-&gt;cbFormat == 0) { <br>            return S_OK; <br>        } <br>    } <br>    else { <br>        // <br>        // check this is an MPEG video format type <br>        // <br>        if (*pmtIn-&gt;FormatType() != FORMAT_MPEGVideo) { <br>            return E_INVALIDARG; <br>        } <br> <br>        // <br>        // we only support MEDIATYPE_Video <br>        // <br>        if (*pmtIn-&gt;Type() != MEDIATYPE_Video) { <br>            return E_INVALIDARG; <br>        } <br> <br>        if (*pmtIn-&gt;Subtype() != MEDIASUBTYPE_MPEG1Packet &amp;&amp; <br>            *pmtIn-&gt;Subtype() != MEDIASUBTYPE_MPEG1Payload) { <br>            return E_INVALIDARG; <br>        } <br>    } <br> <br>    if (pmtIn-&gt;cbFormat &lt; SIZE_VIDEOHEADER + sizeof(DWORD) || <br>        pmtIn-&gt;cbFormat &lt; SIZE_MPEG1VIDEOINFO((MPEG1VIDEOINFO *)pmtIn-&gt;pbFormat)) { <br>        return E_INVALIDARG; <br>    } <br> <br>    // <br>    // Check the sequence header and save the info <br>    // <br> <br>    MPEG1VIDEOINFO* videoInfo = (MPEG1VIDEOINFO *)pmtIn-&gt;pbFormat; <br>    if (!ParseSequenceHeader(videoInfo-&gt;bSequenceHeader, <br>                             videoInfo-&gt;cbSequenceHeader, &amp;m_seqInfo)) { <br>        return E_INVALIDARG; <br>    } <br> <br>    return S_OK; <br>} <br> <br> <br>/******************************Public*Routine******************************\ <br>* CheckTransform <br>* <br>* Check if you can support the transform from this input to this output <br>* <br>\**************************************************************************/ <br>HRESULT <br>CMpegVideoCodec::CheckTransform( <br>    const CMediaType* pmtIn, <br>    const CMediaType* pmtOut <br>    ) <br>{ <br>    DbgLog((LOG_TRACE, 2, TEXT("CMpegVideoCodec::CheckTransform"))); <br> <br>    // we only output video <br>    if (*pmtOut-&gt;Type() != MEDIATYPE_Video) { <br>        return VFW_E_TYPE_NOT_ACCEPTED; <br>    } <br> <br>    // Check there is a format block <br>    if (*pmtOut-&gt;FormatType() != FORMAT_VideoInfo) { <br>        return VFW_E_TYPE_NOT_ACCEPTED; <br>    } <br> <br>    // <br>    // See if we can use dci/direct draw. <br>    // First check that there is a non empty target rectangle. <br>    // <br> <br>    VIDEOINFO *videoInfo = (VIDEOINFO *)pmtOut-&gt;pbFormat; <br>    if (!IsRectEmpty(&amp;videoInfo-&gt;rcTarget)) { <br> <br>        // <br>        // Next, check that the source rectangle is the entire movie. <br>        // <br> <br>        if ( videoInfo-&gt;rcSource.left   == 0 <br>          &amp;&amp; videoInfo-&gt;rcSource.top    == 0 <br>          &amp;&amp; videoInfo-&gt;rcSource.right  == m_seqInfo.lWidth <br>          &amp;&amp; videoInfo-&gt;rcSource.bottom == m_seqInfo.lHeight) { <br> <br>            // <br>            // Now check that the target rectangles size is the same as <br>            // the movies, that is there is no stretching or shrinking. <br>            // <br> <br>            if ( (videoInfo-&gt;rcTarget.right - videoInfo-&gt;rcTarget.left) <br>                    == m_seqInfo.lWidth <br>              &amp;&amp; (videoInfo-&gt;rcTarget.bottom - videoInfo-&gt;rcTarget.top) <br>                    == m_seqInfo.lHeight) { <br>#ifndef _X86_ <br>                // On Risc machines make sure we are DWORD aligned <br>                if ((videoInfo-&gt;rcTarget.left &amp; 0x03) == 0x00) <br>#endif <br>                { <br>                    DbgLog((LOG_TRACE, 2, TEXT("Using DCI"))); <br>                    return S_OK; <br>                } <br>            } <br>        } <br>        DbgLog((LOG_TRACE, 2, TEXT("NOT Using DCI"))); <br>        return E_FAIL; <br>    } <br> <br> <br>    return S_OK; <br>} <br> <br> <br>/******************************Public*Routine******************************\ <br>* SetMediaType <br>* <br>* Overriden to know when the media type is actually set <br>* <br>\**************************************************************************/ <br>HRESULT <br>CMpegVideoCodec::SetMediaType( <br>    PIN_DIRECTION direction, <br>    const CMediaType *pmt <br>    ) <br>{ <br>    DbgLog((LOG_TRACE, 2, TEXT("CMpegVideoCodec::SetMediaType"))); <br> <br>    if (direction == PINDIR_INPUT) { <br> <br>        // <br>        // Get the data type <br>        // <br>        if (*pmt-&gt;Subtype() == MEDIASUBTYPE_MPEG1Packet) { <br>            m_bPayloadOnly = FALSE; <br>        } <br>        else { <br>            ASSERT(*pmt-&gt;Subtype() == MEDIASUBTYPE_MPEG1Payload || <br>                   *pmt-&gt;Subtype() == MEDIASUBTYPE_MPEG1Video); <br>            m_bPayloadOnly = TRUE; <br>        } <br>    } <br>    else { <br>        SetOutputPinMediaType(pmt); <br>    } <br>    return S_OK; <br>} <br> <br> <br>/*****************************Private*Routine******************************\ <br>* SetOutputPinMediaType <br>* <br>* This function is a static member function of CMpegVideoCodec, this is so that <br>* it can be called from SetMediaType (above) and from the static member <br>* function GetDecodeBufferAndFormat.  Note that we pass in the "this" pointer <br>* explicitly. <br>* <br>\**************************************************************************/ <br>void <br>CMpegVideoCodec::SetOutputPinMediaType( <br>    const CMediaType *pmt <br>    ) <br>{ <br>    VIDEOINFO   *pvi; <br>    LONG        lStride; <br>    LONG        lOffset; <br> <br>    if (*pmt-&gt;Subtype() == MEDIASUBTYPE_Y41P) { <br>        m_dwOutputFormatDib = MM_411PK; <br>        m_dwOutputFormatDdb = MM_411PK; <br>    } <br>    else if (*pmt-&gt;Subtype() == MEDIASUBTYPE_YUY2) { <br>        m_dwOutputFormatDib = MM_422PK; <br>        m_dwOutputFormatDdb = MM_422PK; <br>    } <br>    else if (*pmt-&gt;Subtype() == MEDIASUBTYPE_UYVY) { <br>        m_dwOutputFormatDib = MM_422SPK; <br>        m_dwOutputFormatDdb = MM_422SPK; <br>    } <br>    else if (*pmt-&gt;Subtype() == MEDIASUBTYPE_RGB24) { <br>        m_dwOutputFormatDib = MM_RGB24_DIB; <br>        m_dwOutputFormatDdb = MM_RGB24_DDB; <br>    } <br>    else if (*pmt-&gt;Subtype() == MEDIASUBTYPE_RGB565) { <br>        m_dwOutputFormatDib = MM_RGB565_DIB; <br>        m_dwOutputFormatDdb = MM_RGB565_DDB; <br>    } <br>    else if (*pmt-&gt;Subtype() == MEDIASUBTYPE_RGB555) { <br>        m_dwOutputFormatDib = MM_RGB555_DIB; <br>        m_dwOutputFormatDdb = MM_RGB555_DDB; <br>    } <br>    else { <br>        ASSERT(*pmt-&gt;Subtype() == MEDIASUBTYPE_RGB8); <br>        if (m_PaletteType == COLOUR_PALETTE) { <br>            m_dwOutputFormatDib = MM_RGB8_DIB; <br>            m_dwOutputFormatDdb = MM_RGB8_DDB; <br>        } <br>        else { <br>            m_dwOutputFormatDib = MM_Y_DIB; <br>            m_dwOutputFormatDdb = MM_Y_DDB; <br>        } <br>    } <br> <br>    // <br>    // lStride is the distance between in bytes between a pel on the <br>    // screen and the pel directly underneath it. <br>    // <br> <br>    pvi = (VIDEOINFO *)pmt-&gt;pbFormat; <br>    lStride = ((pvi-&gt;bmiHeader.biWidth * pvi-&gt;bmiHeader.biBitCount) + 7) / 8; <br>    lStride = (lStride + 3) &amp; ~3; <br> <br> <br>    // <br>    // lOffset is the distance in bytes from the top corner of the <br>    // target bitmap to the top corner of the video image.  When we are <br>    // using DIBs this value allways be zero. <br>    // <br>    // When we are using DCI/DirectDraw this value will only be zero if <br>    // we are drawing the video image at the top left hand corner of the <br>    // display. <br>    // <br> <br>    lOffset = (((pvi-&gt;rcTarget.left * pvi-&gt;bmiHeader.biBitCount) + 7) / 8) + <br>                (pvi-&gt;rcTarget.top * lStride); <br> <br>    m_VideoControl.dwOutStride = lStride; <br>    m_VideoControl.dwOutOffset = lOffset; <br> <br> <br>    // <br>    // See what orientation we need to use when colour converting <br>    // the frame. <br>    // <br> <br>    if (pvi-&gt;bmiHeader.biHeight &gt; 0) { <br>        m_VideoControl.dwOutputFormat = m_dwOutputFormatDib; <br>    } <br>    else { <br>        m_VideoControl.dwOutputFormat = m_dwOutputFormatDdb; <br>    } <br>} <br> <br> <br>/******************************Public*Routine******************************\ <br>* GetMediaType <br>* <br>* Return our preferred output media types (in order) <br>* <br>\**************************************************************************/ <br>HRESULT <br>CMpegVideoCodec::GetMediaType( <br>    int iPosition, <br>    CMediaType *pmt <br>    ) <br>{ <br>    VIDEOINFO   *pVideoInfo; <br>    CMediaType  cmt; <br> <br>    DbgLog((LOG_TRACE, 2, TEXT("CMpegVideoCodec::GetMediaType"))); <br> <br>    if (iPosition &lt; 0) { <br>        return E_INVALIDARG; <br>    } <br> <br>    // <br>    // Quick hack to enable greyscale for Robin <br>    // <br>    if (m_PaletteType == GREY_PALETTE) { <br> <br>        if (iPosition &gt; 0) { <br>            return VFW_S_NO_MORE_ITEMS; <br>        } <br> <br>        iPosition = MT_RGB8; <br>    } <br> <br>    // <br>    // We copy the proposed output format so that we can play around with <br>    // it all we like and still leave the original preferred format <br>    // untouched.  We try each of the known BITMAPINFO types in turn <br>    // starting off with the best quality moving through to the worst <br>    // (palettised) format <br>    // <br> <br>    cmt = m_pInput-&gt;CurrentMediaType(); <br> <br>    if (*cmt.Type() != MEDIATYPE_Video) { <br>        pVideoInfo = (VIDEOINFO *)cmt.ReallocFormatBuffer(SIZE_PREHEADER); <br>        if (pVideoInfo == NULL) { <br>            return E_OUTOFMEMORY; <br>        } <br>        pVideoInfo-&gt;rcSource.top = 0; <br>        pVideoInfo-&gt;rcSource.left = 0; <br>        pVideoInfo-&gt;rcSource.right = m_seqInfo.lWidth; <br>        pVideoInfo-&gt;rcSource.bottom = m_seqInfo.lHeight; <br>        pVideoInfo-&gt;AvgTimePerFrame = m_seqInfo.tPictureTime; <br>        pVideoInfo-&gt;rcTarget = pVideoInfo-&gt;rcSource; <br>    } <br>    else { <br>        pVideoInfo = (VIDEOINFO *) cmt.Format(); <br>        ASSERT(pVideoInfo != NULL); <br>    } <br> <br>    // <br>    // Fill in the output format according to requested position, see the <br>    // Media Type enum in mpgvideo.h for the list of supported types and <br>    // their positions. <br>    // <br>    switch (iPosition) { <br>    case MT_Y41P: <br>        pVideoInfo = (VIDEOINFO *)cmt.ReallocFormatBuffer(SIZE_VIDEOHEADER); <br>        if (pVideoInfo == NULL) { <br>            return E_OUTOFMEMORY; <br>        } <br>        InitDestinationVideoInfo(pVideoInfo, MAKEFOURCC('Y','4','1','P'), 12); <br> <br>        *pmt = cmt; <br>        pmt-&gt;SetSubtype(&amp;MEDIASUBTYPE_Y41P); <br>        break; <br> <br>    case MT_YUY2: <br>        pVideoInfo = (VIDEOINFO *)cmt.ReallocFormatBuffer(SIZE_VIDEOHEADER); <br>        if (pVideoInfo == NULL) { <br>            return E_OUTOFMEMORY; <br>        } <br>        InitDestinationVideoInfo(pVideoInfo, MAKEFOURCC('Y','U','Y','2'), 16); <br> <br>        *pmt = cmt; <br>        pmt-&gt;SetSubtype(&amp;MEDIASUBTYPE_YUY2); <br>        break; <br> <br>    case MT_UYVY: <br>        pVideoInfo = (VIDEOINFO *)cmt.ReallocFormatBuffer(SIZE_VIDEOHEADER); <br>        if (pVideoInfo == NULL) { <br>            return E_OUTOFMEMORY; <br>        } <br>        InitDestinationVideoInfo(pVideoInfo, MAKEFOURCC('U','Y','V','Y'), 16); <br> <br>        *pmt = cmt; <br>        pmt-&gt;SetSubtype(&amp;MEDIASUBTYPE_UYVY); <br>        break; <br> <br>    case MT_RGB24: <br>        pVideoInfo = (VIDEOINFO *)cmt.ReallocFormatBuffer(SIZE_VIDEOHEADER); <br>        if (pVideoInfo == NULL) { <br>            return E_OUTOFMEMORY; <br>        } <br>        InitDestinationVideoInfo(pVideoInfo, BI_RGB, 24); <br> <br>        *pmt = cmt; <br>        pmt-&gt;SetSubtype(&amp;MEDIASUBTYPE_RGB24); <br>        break; <br> <br>    case MT_RGB565: <br>        pVideoInfo = (VIDEOINFO *)cmt.ReallocFormatBuffer(SIZE_VIDEOHEADER + <br>                                                          SIZE_MASKS); <br>        if (pVideoInfo == NULL) { <br>            return E_OUTOFMEMORY; <br>        } <br> <br>        InitDestinationVideoInfo(pVideoInfo, BI_BITFIELDS, 16); <br> <br>        DWORD *pdw; <br>        pdw = (DWORD *)(HEADER(pVideoInfo) + 1); <br>        pdw[iRED]   = bits565[iRED]; <br>        pdw[iGREEN] = bits565[iGREEN]; <br>        pdw[iBLUE]  = bits565[iBLUE]; <br> <br>        *pmt = cmt; <br>        pmt-&gt;SetSubtype(&amp;MEDIASUBTYPE_RGB565); <br>        break; <br> <br>    case MT_RGB555: <br>        pVideoInfo = (VIDEOINFO *)cmt.ReallocFormatBuffer(SIZE_VIDEOHEADER); <br>        if (pVideoInfo == NULL) { <br>            return E_OUTOFMEMORY; <br>        } <br>        InitDestinationVideoInfo(pVideoInfo, BI_RGB, 16); <br> <br>        *pmt = cmt; <br>        pmt-&gt;SetSubtype(&amp;MEDIASUBTYPE_RGB555); <br>        break; <br> <br>    case MT_RGB8: <br>        pVideoInfo = (VIDEOINFO *)cmt.ReallocFormatBuffer( <br>                                           SIZE_VIDEOHEADER + SIZE_PALETTE); <br>        if (pVideoInfo == NULL) { <br>            return E_OUTOFMEMORY; <br>        } <br>        InitDestinationVideoInfo(pVideoInfo, BI_RGB, 8); <br>        InitDestinationPalette(pVideoInfo); <br> <br>        *pmt = cmt; <br>        pmt-&gt;SetSubtype(&amp;MEDIASUBTYPE_RGB8); <br>        break; <br> <br>    default: <br>        return VFW_S_NO_MORE_ITEMS; <br> <br>    } <br> <br>    // <br>    // This block assumes that lpbi has been set up to point to a valid <br>    // bitmapinfoheader and that cmt has been copied into *pmt. <br>    // This is taken care of in the switch statement above.  This should <br>    // kept in mind when new formats are added. <br>    // <br>    pmt-&gt;SetType(&amp;MEDIATYPE_Video); <br>    pmt-&gt;SetFormatType(&amp;FORMAT_VideoInfo); <br> <br>    // <br>    // we assume the output format is uncompressed <br>    // <br>    pmt-&gt;SetTemporalCompression(FALSE); <br>    pmt-&gt;SetSampleSize(HEADER(pVideoInfo)-&gt;biSizeImage); <br>    return S_OK; <br>} <br> <br> <br>/*****************************Private*Routine******************************\ <br>* InitDestinationVideoInfo <br>* <br>* Fills in common video and bitmap info header fields <br>* <br>\**************************************************************************/ <br>void <br>CMpegVideoCodec::InitDestinationVideoInfo( <br>    VIDEOINFO *pVideoInfo, <br>    DWORD dwComppression, <br>    int nBitCount <br>    ) <br>{ <br>    LPBITMAPINFOHEADER lpbi = HEADER(pVideoInfo); <br>    lpbi-&gt;biSize          = sizeof(BITMAPINFOHEADER); <br>    lpbi-&gt;biWidth         = m_seqInfo.lWidth; <br>    lpbi-&gt;biHeight        = m_seqInfo.lHeight; <br>    lpbi-&gt;biPlanes        = 1; <br>    lpbi-&gt;biBitCount      = nBitCount; <br>    lpbi-&gt;biXPelsPerMeter = 0; <br>    lpbi-&gt;biYPelsPerMeter = 0; <br>    lpbi-&gt;biCompression   = dwComppression; <br>    lpbi-&gt;biSizeImage     = GetBitmapSize(lpbi); <br> <br>    // <br>    // The "bit" rate is image size in bytes times 8 (to convert to bits) <br>    // divided by the AvgTimePerFrame.  This result is in bits per 100 nSec, <br>    // so we multiply by 10000000 to convert to bits per second, this multiply <br>    // is combined with "times" 8 above so the calculations becomes: <br>    // <br>    // BitRate = (biSizeImage * 80000000) / AvgTimePerFrame <br>    // <br>    LARGE_INTEGER li; <br>    li.QuadPart = pVideoInfo-&gt;AvgTimePerFrame; <br>    pVideoInfo-&gt;dwBitRate = MulDiv(lpbi-&gt;biSizeImage, 80000000, li.LowPart); <br>    pVideoInfo-&gt;dwBitErrorRate = 0L; <br> <br>} <br> <br> <br>/*****************************Private*Routine******************************\ <br>* InitDestinationPalette <br>* <br>* Creates a standard colour palette or gray scale palette as determined <br>* by the PaletteType parameter. <br>* <br>\**************************************************************************/ <br>void <br>CMpegVideoCodec::InitDestinationPalette( <br>    VIDEOINFO *pVideoInfo <br>    ) <br>{ <br>    int             i; <br>    int             iPalLowEnd; <br>    int             iPalHiStart; <br>    PALETTEENTRY    pal[24]; <br>    HDC             hDC; <br> <br>    if (m_PaletteType == COLOUR_PALETTE) { <br>        for ( i = 0; i &lt; 256; i++ ) { <br>            pVideoInfo-&gt;bmiColors[i].rgbRed      = PaletteData[i].r; <br>            pVideoInfo-&gt;bmiColors[i].rgbBlue     = PaletteData[i].b; <br>            pVideoInfo-&gt;bmiColors[i].rgbGreen    = PaletteData[i].g; <br>            pVideoInfo-&gt;bmiColors[i].rgbReserved = 0; <br>        } <br>        iPalLowEnd  = 16; <br>        iPalHiStart = 232; <br>    } <br>    else { <br>        for ( i = 0; i &lt; 256; i++ ) { <br>            pVideoInfo-&gt;bmiColors[i].rgbRed      = i; <br>            pVideoInfo-&gt;bmiColors[i].rgbBlue     = i; <br>            pVideoInfo-&gt;bmiColors[i].rgbGreen    = i; <br>            pVideoInfo-&gt;bmiColors[i].rgbReserved = 0; <br>        } <br>        iPalLowEnd  = 10; <br>        iPalHiStart = 246; <br>    } <br> <br>    hDC = GetDC(GetDesktopWindow()); <br>    GetSystemPaletteEntries(hDC, 0, 16, &amp;pal[0] ); <br>    for ( i = 0; i &lt; iPalLowEnd; i++ ) { <br> <br>        pVideoInfo-&gt;bmiColors[i].rgbRed   = pal[i].peRed; <br>        pVideoInfo-&gt;bmiColors[i].rgbGreen = pal[i].peGreen; <br>        pVideoInfo-&gt;bmiColors[i].rgbBlue  = pal[i].peBlue; <br>    } <br> <br>    GetSystemPaletteEntries(hDC, iPalHiStart, 256 - iPalHiStart, &amp;pal[0] ); <br>    for ( i = iPalHiStart; i &lt; 256; i++ ) { <br> <br>        pVideoInfo-&gt;bmiColors[i].rgbRed   = pal[i - iPalHiStart].peRed; <br>        pVideoInfo-&gt;bmiColors[i].rgbGreen = pal[i - iPalHiStart].peGreen; <br>        pVideoInfo-&gt;bmiColors[i].rgbBlue  = pal[i - iPalHiStart].peBlue; <br>    } <br>    ReleaseDC(GetDesktopWindow(), hDC); <br> <br> <br>    HEADER(pVideoInfo)-&gt;biClrUsed = 256; <br>    HEADER(pVideoInfo)-&gt;biClrImportant = 0; <br>} <br> <br> <br>/******************************Public*Routine******************************\ <br>* DecideBufferSize <br>* <br>* Called from CBaseOutputPin to prepare the allocator's count <br>* of buffers and sizes <br>* <br>\**************************************************************************/ <br>HRESULT <br>CMpegVideoCodec::DecideBufferSize( <br>    IMemAllocator * pAllocator, <br>    ALLOCATOR_PROPERTIES * pProperties <br>    ) <br>{ <br>    DbgLog((LOG_TRACE, 2, TEXT("CMpegVideoCodec::DecideBufferSize"))); <br> <br>    ASSERT(pAllocator); <br>    ASSERT(pProperties); <br>    HRESULT hr = NOERROR; <br> <br>    pProperties-&gt;cBuffers = 1; <br>    pProperties-&gt;cbBuffer = m_pOutput-&gt;CurrentMediaType().GetSampleSize(); <br> <br>    ASSERT(pProperties-&gt;cbBuffer); <br>    DbgLog((LOG_TRACE, 2, TEXT("Sample size = %ld\n"), pProperties-&gt;cbBuffer)); <br> <br>    // Ask the allocator to reserve us some sample memory, NOTE the function <br>    // can succeed (that is return NOERROR) but still not have allocated the <br>    // memory that we requested, so we must check we got whatever we wanted <br> <br>    ALLOCATOR_PROPERTIES Actual; <br>    hr = pAllocator-&gt;SetProperties(pProperties,&amp;Actual); <br>    if (FAILED(hr)) { <br>        return hr; <br>    } <br> <br>    ASSERT(Actual.cbAlign == 1); <br>    ASSERT(Actual.cbPrefix == 0); <br> <br>    if (Actual.cbBuffer &lt; pProperties-&gt;cbBuffer || <br>        Actual.cBuffers &lt; pProperties-&gt;cBuffers) { <br> <br>            // can't use this allocator <br>            return E_INVALIDARG; <br>    } <br>    return S_OK; <br>} <br> <br> <br>/******************************Public*Routine******************************\ <br>* StartStreaming <br>* <br>* <br>* <br>\**************************************************************************/ <br>HRESULT <br>CMpegVideoCodec::StartStreaming( <br>    void <br>    ) <br>{ <br>    CAutoLock   lock(&amp;m_csFilter); <br>    long        Size; <br>    // HRESULT     hr; <br> <br>    ASSERT(MEDIASUBTYPE_RGB8   == *m_pOutput-&gt;CurrentMediaType().Subtype() || <br>           MEDIASUBTYPE_RGB555 == *m_pOutput-&gt;CurrentMediaType().Subtype() || <br>           MEDIASUBTYPE_RGB565 == *m_pOutput-&gt;CurrentMediaType().Subtype() || <br>           MEDIASUBTYPE_Y41P   == *m_pOutput-&gt;CurrentMediaType().Subtype() || <br>           MEDIASUBTYPE_YUY2   == *m_pOutput-&gt;CurrentMediaType().Subtype() || <br>           MEDIASUBTYPE_UYVY   == *m_pOutput-&gt;CurrentMediaType().Subtype() || <br>           MEDIASUBTYPE_RGB24  == *m_pOutput-&gt;CurrentMediaType().Subtype()); <br> <br>    ASSERT(m_pFrameBuff == NULL); <br>    ASSERT(m_pVideoDecoder == NULL); <br>    ASSERT(m_Buffer == NULL); <br> <br>    // <br>    // Create the video codec - if we fail to open the codec it is <br>    // probably because the codec was unable to allocate memory for its <br>    // decoding tables. <br>    // <br>    m_pVideoDecoder = new CVideoDecoder(this); <br>    if (m_pVideoDecoder == NULL) { <br>        return E_OUTOFMEMORY; <br>    } <br> <br> <br>    // <br>    // Allocate some space for the codecs I and P frame buffer store <br>    // <br>    Size = m_seqInfo.lWidth * m_seqInfo.lHeight; <br>    m_pFrameBuff = new BYTE[ 3 * (Size + (2 * (Size / 4)))]; <br>    if (m_pFrameBuff == NULL) { <br> <br>        delete m_pVideoDecoder; <br>        m_pVideoDecoder = NULL; <br> <br>        return E_OUTOFMEMORY; <br>    } <br> <br>    m_VBlockSize = m_seqInfo.lvbv; <br>    m_VBlockSize +=  ((1 &lt;&lt; 16) - 1); <br>    m_VBlockSize &amp;= ~((1 &lt;&lt; 16) - 1); <br> <br>    // m_Buffer = new CCircularBuffer(m_VBlockSize, m_VBlockSize, hr); <br>    m_Buffer = new BYTE[m_VBlockSize]; <br>    if (m_Buffer == NULL) { <br> <br>        delete [] m_pFrameBuff; <br>        m_pFrameBuff = NULL; <br> <br>        delete m_pVideoDecoder; <br>        m_pVideoDecoder = NULL; <br> <br>        return E_OUTOFMEMORY; <br>    } <br> <br>    // <br>    // Initialize the mpeg video codec <br>    // <br>    m_dwLateBy = 0; <br>    m_dwCtrl = (m_dwCtrlDefault | m_dwQualDefault); <br>    m_VideoControl.dwCtrl = m_dwCtrl; <br>    m_VideoControl.dwYStride = m_seqInfo.lWidth; <br>    m_VideoControl.dwYLines = m_seqInfo.lHeight; <br> <br>    ZeroMemory(m_pFrameBuff, Size); <br>    m_VideoControl.pFrameBuff = m_pFrameBuff; <br> <br> <br>    // <br>    // Now reset the mpeg video decoder <br>    // <br>    ResetVideoDecoder(); <br> <br> <br>    // <br>    // Reset frame stats <br>    // <br>    ZeroMemory(m_dwFramesSkipped, sizeof(m_dwFramesSkipped)); <br>    ZeroMemory(m_dwFramesDecoded, sizeof(m_dwFramesDecoded)); <br> <br>    return S_OK; <br>} <br> <br> <br>/******************************Public*Routine******************************\ <br>* StopStreaming <br>* <br>* <br>* <br>\**************************************************************************/ <br>HRESULT <br>CMpegVideoCodec::StopStreaming( <br>    void <br>    ) <br>{ <br>    CAutoLock       lock(&amp;m_csFilter); <br>    CAutoLock       lck(&amp;m_csReceive); <br> <br>    CTimePosition   *pTimePos; <br> <br>    ASSERT(m_pFrameBuff != NULL); <br>    ASSERT(m_pVideoDecoder != NULL); <br>    ASSERT(m_Buffer != NULL); <br> <br>    delete m_pVideoDecoder; <br>    m_pVideoDecoder = NULL; <br> <br>    delete [] m_pFrameBuff; <br>    m_pFrameBuff = NULL; <br> <br>    delete [] m_Buffer; <br>    m_Buffer = NULL; <br> <br> <br>    // <br>    // Purge the PTS queue. <br>    // <br>    DbgLog((LOG_TRACE, 2, <br>            TEXT("Freeing %d time entries"), m_PtsQueue.GetCount())); <br> <br>    while( (pTimePos = m_PtsQueue.RemoveHead()) != NULL) { <br>        delete pTimePos; <br>    } <br> <br>    return S_OK; <br>} <br> <br>/******************************Public*Routine******************************\ <br>* Notify <br>* <br>* Handle quality control notifications sent to us <br>* <br>\**************************************************************************/ <br>HRESULT <br>CMpegVideoCodec::AlterQuality( <br>    Quality q <br>    ) <br>{ <br>    DWORD dwNewCtrl; <br>    LARGE_INTEGER li; <br>    li.QuadPart = q.Late; <br>    DWORD dwTimeLate = li.LowPart; <br> <br>    MSR_INTEGER(m_QualMsg, dwTimeLate); <br>    li.QuadPart = m_seqInfo.tPictureTime; <br> <br>    DbgLog((LOG_TRACE, 2, <br>            TEXT("Q = %s Prop = %4.4ld Late = %8.8ld Fram = %8.8ld"), <br>            q.Type == Famine ? TEXT("Famine") : TEXT("Flood "), <br>            q.Proportion, dwTimeLate, <br>            li.LowPart)); <br> <br>    // <br>    // See if the user has overidden quality messages <br>    // <br>    if (m_IgnoreQualityMessage) { <br>        return S_OK; <br>    } <br> <br>    // <br>    // Turn off the old option and then bring in the new. <br>    // <br> <br>    m_dwLateBy = dwTimeLate; <br> <br>    if (dwTimeLate &lt;= 750000L) { <br>        DbgLog((LOG_TRACE, 2, TEXT("Default QL"))); <br>        dwNewCtrl = m_dwCtrlDefault; <br>    } <br>    else if (dwTimeLate &lt;= (7L * 330000L)) { <br>        DbgLog((LOG_TRACE, 2, TEXT("IP"))); <br>        dwNewCtrl = DECODE_IP; <br>    } <br>    else { <br>        DbgLog((LOG_TRACE, 2, TEXT("I"))); <br>        dwNewCtrl = DECODE_I; <br>    } <br> <br>    m_dwCtrl = (m_dwQualDefault | dwNewCtrl); <br> <br>    return S_OK; <br>} <br> <br> <br>// ------------------------------------------------------------------------- <br>// IP Tracking class <br>// ------------------------------------------------------------------------- <br>// <br>inline CMpegVideoCodec::CNextIP::CNextIP() <br>{ <br>    Reset(); <br>} <br> <br>inline void <br>CMpegVideoCodec::CNextIP::Set( <br>    DWORD dwSkipFlag, <br>    BOOL bIFrame, <br>    BOOL bTimeSet, <br>    REFERENCE_TIME t, <br>    DWORD dwTemporalReference <br>    ) <br>{ <br>    if (m_bGotFirst) { <br> <br>        m_bTimeToDraw = FALSE; <br>        NextRef(dwTemporalReference); // Might already be time if no Bs <br>    } <br>    else { <br>        if (bIFrame) { <br>            m_bGotFirst   = TRUE; <br>            m_bTimeToDraw = TRUE; <br>        } <br>    } <br>    m_dwSkipFlag          = dwSkipFlag; <br>    m_bTimeSet            = bTimeSet; <br>    m_t                   = t; <br>    m_dwTemporalReference = dwTemporalReference; <br> <br>} <br> <br>inline BOOL <br>CMpegVideoCodec::CNextIP::GotFirst() <br>{ <br>    return m_bGotFirst; <br>} <br> <br>inline void <br>CMpegVideoCodec::CNextIP::NextRef( <br>    DWORD dwTemporalReference <br>    ) <br>{ <br>    //  See if we're next after this one <br>    //  Don't set m_bTimeToDraw = FALSE here because in the case <br>    //  where we're stepping through undrawable B-frames before the <br>    //  first I-Frame we've already set m_bTimeToDraw = TRUE <br>    if (((dwTemporalReference + 1) &amp; 1023) == m_dwTemporalReference) { <br>        m_bTimeToDraw = TRUE; <br>    } <br>    DbgLog((LOG_TRACE, 3, <br>            TEXT("New Temporal Reference %d, NextIP = %d, TimeToDraw = %d"), <br>            dwTemporalReference, m_dwTemporalReference, <br>            m_bTimeToDraw)); <br>} <br> <br> <br>inline BOOL <br>CMpegVideoCodec::CNextIP::GetTime( <br>    REFERENCE_TIME *pt <br>    ) <br>{ <br>    if (m_bTimeSet) { <br>        *pt = m_t; <br>    } <br>    return m_bTimeSet; <br>} <br> <br>inline BOOL <br>CMpegVideoCodec::CNextIP::TimeToDraw()  const <br>{ <br>    return !m_dwSkipFlag &amp;&amp; m_bTimeToDraw; <br>} <br> <br>inline void <br>CMpegVideoCodec::CNextIP::Reset() <br>{ <br>    m_bGotFirst = FALSE; <br>    m_bTimeSet = FALSE; <br>    m_dwTemporalReference = 0; <br>    m_bTimeToDraw = FALSE; <br>} <br> <br> <br> <br> <br> <br>/******************************Public*Routine******************************\ <br>* SkipToPacketData <br>* <br>* <br>* <br>\**************************************************************************/ <br>LPBYTE <br>SkipToPacketData( <br>    LPBYTE pSrc, <br>    long &amp;LenLeftInPacket <br>    ) <br>{ <br>    LPBYTE  lpPacketStart; <br>    DWORD   bData; <br>    long    Length; <br> <br> <br>    // <br>    // Skip the stream ID and extract the packet length <br>    // <br>    pSrc += 4; <br>    bData = *pSrc++; <br>    Length = (long)((bData &lt;&lt; 8) + *pSrc++); <br>    DbgLog((LOG_TRACE, 3, TEXT("Packet length %ld"), Length )); <br> <br> <br>    // <br>    // Record position of first byte after packet length <br>    // <br>    lpPacketStart = pSrc; <br> <br> <br>    // <br>    // Remove stuffing bytes <br>    // <br>    for (; ; ) { <br>        bData = *pSrc++; <br>        if (!(bData &amp; 0x80)) { <br>            break; <br>        } <br>    } <br> <br>    if ((bData &amp; 0xC0) == 0x40) { <br>        pSrc++; <br>        bData = *pSrc++; <br>    } <br> <br>    switch (bData &amp; 0xF1) { <br> <br>    case 0x21: <br>        pSrc += 4; <br>        break; <br> <br>    case 0x31: <br>        pSrc += 9; <br>        break; <br> <br>    default: <br>        if (bData != 0x0F) { <br>            DbgLog((LOG_TRACE, 2, TEXT("Invalid packet - 0x%2.2X\n"), bData)); <br>            return NULL; <br>        } <br>    } <br> <br>    // <br>    // The length left in the packet is the original length of the packet <br>    // less those bytes that we have just skipped over. <br>    // <br>    LenLeftInPacket = Length - (pSrc - lpPacketStart); <br>    return pSrc; <br>} <br> <br> <br> <br>#ifdef DEBUG <br>LPCTSTR PictureTypes[8] = { <br>    TEXT("forbidden frame type"), <br>    TEXT("I-Frame"), <br>    TEXT("P-Frame"), <br>    TEXT("B-Frame"), <br>    TEXT("D-Frame"), <br>    TEXT("Reserved frame type"), <br>    TEXT("Reserved frame type"), <br>    TEXT("Reserved frame type") <br>}; <br> <br>LPCTSTR PelAspectRatios[16] = { <br>    TEXT("Forbidden"), <br>    TEXT("1.0000 - VGA etc"), <br>    TEXT("0.6735"), <br>    TEXT("0.7031 - 16:9, 625 line"), <br>    TEXT("0.7615"), <br>    TEXT("0.8055"), <br>    TEXT("0.8437 - 16:9, 525 line"), <br>    TEXT("0.8935"), <br>    TEXT("0.9375 - CCIR601, 625 line"), <br>    TEXT("0.9815"), <br>    TEXT("1.0255"), <br>    TEXT("1.0695"), <br>    TEXT("1.1250 - CCIR601, 525 line"), <br>    TEXT("1.1575"), <br>    TEXT("1.2015"), <br>    TEXT("Reserved") <br>}; <br> <br>LPCTSTR PictureRates[16] = { <br>    TEXT("Forbidden"), <br>    TEXT("23.976"), <br>    TEXT("24"), <br>    TEXT("25"), <br>    TEXT("29.97"), <br>    TEXT("30"), <br>    TEXT("50"), <br>    TEXT("59.94"), <br>    TEXT("60"), <br>    TEXT("Reserved"), <br>    TEXT("Reserved"), <br>    TEXT("Reserved"), <br>    TEXT("Reserved"), <br>    TEXT("Reserved"), <br>    TEXT("Reserved"), <br>    TEXT("Reserved") <br>}; <br>#endif // DEBUG <br> <br>const LONG PictureTimes[16] = { <br>    0, <br>    (LONG)((double)10000000 / 23.976), <br>    (LONG)((double)10000000 / 24), <br>    (LONG)((double)10000000 / 25), <br>    (LONG)((double)10000000 / 29.97), </code></pre>
<p>
</p>
<pre><code>(LONG)((double)10000000 / 30), <br>    (LONG)((double)10000000 / 50), <br>    (LONG)((double)10000000 / 59.94), <br>    (LONG)((double)10000000 / 60) <br>}; <br> <br>const LONG AspectRatios[16] = { <br>    0, <br>    393700, <br>    (LONG)(393700.0 * 0.6735), <br>    (LONG)(393700.0 * 0.7031), <br>    (LONG)(393700.0 * 0.7615), <br>    (LONG)(393700.0 * 0.8055), <br>    (LONG)(393700.0 * 0.8437), <br>    (LONG)(393700.0 * 0.8935), <br>    (LONG)(393700.0 * 0.9375), <br>    (LONG)(393700.0 * 0.9815), <br>    (LONG)(393700.0 * 1.0255), <br>    (LONG)(393700.0 * 1.0695), <br>    (LONG)(393700.0 * 1.1250), <br>    (LONG)(393700.0 * 1.1575), <br>    (LONG)(393700.0 * 1.2015), <br>    0 <br>}; <br> <br>/******************************Public*Routine******************************\ <br>* ParseSequenceHeader <br>* <br>* <br>* <br>\**************************************************************************/ <br>BOOL <br>CMpegVideoCodec::ParseSequenceHeader( <br>    const BYTE *pbData, <br>    LONG lData, <br>    SEQHDR_INFO *pInfo <br>    ) <br>{ <br>    ASSERT(*(UNALIGNED DWORD *)pbData == ByteSwap(SEQUENCE_HEADER_CODE)); <br> <br>    // <br>    // Check random marker bit <br>    // <br>    if (!(pbData[10] &amp; 0x20)) { <br>        DbgLog((LOG_ERROR, 2, TEXT("Sequence header invalid marker bit"))); <br>        return FALSE; <br>    } <br> <br>    DWORD dwWidthAndHeight = ((DWORD)pbData[4] &lt;&lt; 16) + ((DWORD)pbData[5] &lt;&lt; 8) + <br>                             ((DWORD)pbData[6]); <br> <br>    pInfo-&gt;lWidth = dwWidthAndHeight &gt;&gt; 12; <br>    pInfo-&gt;lHeight = dwWidthAndHeight &amp; 0xFFF; <br> <br>    DbgLog((LOG_TRACE, 2, TEXT("Width = %d, Height = %d"), <br>            pInfo-&gt;lWidth, pInfo-&gt;lHeight)); <br> <br>    // <br>    // the '8' bit is the scramble flag used by sigma designs - ignore <br>    // <br>    BYTE PelAspectRatioAndPictureRate = pbData[7]; <br> <br>    if ((PelAspectRatioAndPictureRate &amp; 0x0F) &gt; 8) { <br>        PelAspectRatioAndPictureRate &amp;= 0xF7; <br>    } <br> <br>    DbgLog((LOG_TRACE, 2, TEXT("Pel Aspect Ratio = %s"), <br>        PelAspectRatios[PelAspectRatioAndPictureRate &gt;&gt; 4])); <br>    DbgLog((LOG_TRACE, 2, TEXT("Picture Rate = %s"), <br>        PictureRates[PelAspectRatioAndPictureRate &amp; 0x0F])); <br> <br>    if ((PelAspectRatioAndPictureRate &amp; 0xF0) == 0 || <br>        (PelAspectRatioAndPictureRate &amp; 0x0F) == 0) { <br> <br>        DbgLog((LOG_ERROR, 2, TEXT("Sequence header invalid ratio/rate"))); <br>        return FALSE; <br>    } <br> <br>    pInfo-&gt;tPictureTime = <br>            (LONGLONG)PictureTimes[PelAspectRatioAndPictureRate &amp; 0x0F]; <br> <br>    pInfo-&gt;lTimePerFrame = <br>            MulDiv((LONG)pInfo-&gt;tPictureTime, 9, 1000); <br> <br>    /*  Pull out the bit rate and aspect ratio for the type */ <br>    pInfo-&gt;dwBitRate = ((((DWORD)pbData[8] &lt;&lt; 16) + ((DWORD)pbData[9] &lt;&lt; 8) + <br>                          (DWORD)pbData[10]) &gt;&gt; 6); <br> <br>    if (pInfo-&gt;dwBitRate == 0x3FFFF) { <br> <br>        DbgLog((LOG_TRACE, 2, TEXT("Variable video bit rate"))); <br>        pInfo-&gt;dwBitRate = 0; <br>    } <br>    else { <br> <br>        pInfo-&gt;dwBitRate *= 400; <br>        DbgLog((LOG_TRACE, 2, TEXT("Video bit rate is %d bits per second"), <br>               pInfo-&gt;dwBitRate)); <br>    } <br> <br>    // <br>    // Get a DC <br>    // <br>    HDC hdc = GetDC(GetDesktopWindow()); <br>    ASSERT(hdc != NULL); <br> <br>    // <br>    //  Guess (randomly) 39.37 inches per meter <br>    // <br>    LONG lNotionalPelsPerMeter = <br>            MulDiv((LONG)GetDeviceCaps(hdc, LOGPIXELSX), 3937, 100); <br> <br>    pInfo-&gt;lXPelsPerMeter = lNotionalPelsPerMeter; <br> <br>    pInfo-&gt;lYPelsPerMeter = MulDiv( <br>                              lNotionalPelsPerMeter, <br>                              AspectRatios[PelAspectRatioAndPictureRate &gt;&gt; 4], <br>                              10000); <br>    // <br>    // Pull out the vbv <br>    // <br>    pInfo-&gt;lvbv = ((((LONG)pbData[10] &amp; 0x1F) &lt;&lt; 5) | <br>                    ((LONG)pbData[11] &gt;&gt; 3)) * 2048; <br> <br>    DbgLog((LOG_TRACE, 2, TEXT("vbv size is %d bytes"), pInfo-&gt;lvbv)); <br> <br>    // <br>    // Check constrained parameter stuff <br>    // <br>    if (pbData[11] &amp; 0x04) { <br> <br>        DbgLog((LOG_TRACE, 2, TEXT("Constrained parameter video stream"))); <br> <br>        if (pInfo-&gt;lvbv &gt; 40960) { <br> <br>            DbgLog((LOG_ERROR, 1, <br>                    TEXT("Invalid vbv (%d) for Constrained stream"), <br>                    pInfo-&gt;lvbv)); <br> <br>            // <br>            //  Have to let this through too!  bisp.mpg has this <br>            //  But constrain it since it might be random <br>            // <br>            pInfo-&gt;lvbv = 40960; <br> <br>        } <br> <br>    } <br>    else { <br>        DbgLog((LOG_TRACE, 2, TEXT("Non-Constrained parameter video stream"))); <br>    } <br> <br>    pInfo-&gt;lActualHeaderLen = lData; <br>    CopyMemory((PVOID)pInfo-&gt;RawHeader, (PVOID)pbData, pInfo-&gt;lActualHeaderLen); <br>    return TRUE; <br>} <br>/******************************Public*Routine******************************\ <br>* exported entry points for registration and <br>* unregistration (in this case they only call <br>* through to default implmentations). <br>* <br>* <br>* <br>* History: <br>* <br>\**************************************************************************/ <br>STDAPI <br>DllRegisterServer() <br>{ <br>  return AMovieDllRegisterServer2( TRUE ); <br>} <br> <br>STDAPI <br>DllUnregisterServer() <br>{ <br>  return AMovieDllRegisterServer2( FALSE ); <br>} <br> <br> </code></pre>
<p>&nbsp;</p></body>
</HTML>
