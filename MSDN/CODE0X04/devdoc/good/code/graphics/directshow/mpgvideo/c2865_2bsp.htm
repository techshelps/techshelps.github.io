<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 3.2 Final//EN">
<HTML dir=ltr>
<HEAD>
<META HTTP-EQUIV="Content-Type" Content="text/html; charset=Windows-1252">
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-83731338-2"></script><script>  window.dataLayer = window.dataLayer || [];  function gtag(){dataLayer.push(arguments);}  gtag('js', new Date());  gtag('config', 'UA-83731338-2');</script><title>MPGVIDEO.H</title>
<link disabled rel=stylesheet href=../../../../../backsdk3.css>
<style type="text/css">
@import url(../../../../../backsdk4.css);
</style>
</HEAD>
<BODY BGCOLOR = #FFFFFF TEXT = #000000>
<h2><a name="_code_context2869"></a>MPGVIDEO.H</h2>
<pre><code>//==========================================================================; <br>// <br>//  THIS CODE AND INFORMATION IS PROVIDED "AS IS" WITHOUT WARRANTY OF ANY <br>//  KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE <br>//  IMPLIED WARRANTIES OF MERCHANTABILITY AND/OR FITNESS FOR A PARTICULAR <br>//  PURPOSE. <br>// <br>//  Copyright (c) 1992 - 1997  Microsoft Corporation.  All Rights Reserved. <br>// <br>//--------------------------------------------------------------------------; <br>// <br>/******************************Module*Header*******************************\ <br>* Module Name: MpgVideo.h <br>* <br>* Prototype Mpeg Video codec <br>* <br>\**************************************************************************/ <br>#ifndef _INC_MPGVIDEO_H <br>#define _INC_MPGVIDEO_H <br>#include &lt;streams.h&gt; <br>#include &lt;windowsx.h&gt; <br>#include &lt;mmsystem.h&gt; <br>#include &lt;mmreg.h&gt; <br>#include &lt;stddef.h&gt; <br>#include &lt;string.h&gt; <br> <br>#include "Decoder.h" <br> <br> <br>// ------------------------------------------------------------------------- <br>// Helper functions that can be used by audio and video codecs. <br>// ------------------------------------------------------------------------- <br>// <br> <br>/******************************Public*Routine******************************\ <br>* ByteSwap <br>* <br>* Converts dwX from little endian to big endian and vice-versa. <br>* <br>\**************************************************************************/ <br>__inline DWORD <br>ByteSwap( <br>    DWORD dwX <br>    ) <br>{ <br>#ifdef _X86_ <br>    _asm    mov     eax, dwX <br>    _asm    bswap   eax <br>    _asm    mov     dwX, eax <br> <br>    return dwX; <br>#else <br>    return _lrotl(((dwX &amp; 0xFF00FF00) &gt;&gt; 8) | ((dwX &amp; 0x00FF00FF) &lt;&lt; 8), 16); <br>#endif <br>} <br> <br>LPBYTE SkipToPacketData(LPBYTE pSrc, long &amp;LenLeftInPacket); <br> <br> <br> <br>// ------------------------------------------------------------------------- <br>// This structure is used to associate Pts time stamps with positions <br>// within the circular buffer.  Each time we get a media sample with a Pts <br>// time stamp we add a TIMEPOSITION entry to a queue of time positions. <br>// Each time we decode an I frame we record the starting and ending position <br>// of the I frame picture within the circular buffer, this information is <br>// then used to find a suitable time stamp to associate with the frame.  If <br>// a suitable time stamp cannot be found or the frame is not an I frame we <br>// calculate a suitable time code by extrapolation. <br>// ------------------------------------------------------------------------- <br>// <br>class CTimePosition { <br>public: <br>    CRefTime    m_PtsTimeStamp; <br>    LPBYTE      m_BufferPosition; <br> <br>    CTimePosition(CRefTime *TimeStamp, LPBYTE lpPos) <br>        : m_PtsTimeStamp(*TimeStamp), m_BufferPosition(lpPos) {} <br>}; <br> <br> <br>// ------------------------------------------------------------------------- <br>// Structure to hold the contents of an Mpeg 1 sequence header. <br>// ------------------------------------------------------------------------- <br>struct SEQHDR_INFO { <br>    LONG           lWidth;             //  Native Width in pixels <br>    LONG           lHeight;            //  Native Height in pixels <br>    LONG           lvbv;               //  vbv <br>    REFERENCE_TIME tPictureTime;       //  Time per picture in 100ns units <br>    LONG           lTimePerFrame;      //  Time per picture in MPEG units <br>    LONG           dwBitRate;          //  Bits per second <br>    LONG           lXPelsPerMeter;     //  Pel aspect ratio <br>    LONG           lYPelsPerMeter;     //  Pel aspect ratio <br>    DWORD          dwStartTimeCode;    //  First GOP time code (or -1) <br>    LONG           lActualHeaderLen;   //  Length of valid bytes in raw seq hdr <br>    BYTE           RawHeader[140];     //  The real sequence header <br>}; <br> <br> <br>// ------------------------------------------------------------------------- <br>// Quartz Mpeg video codec framework class <br>// <br>// ------------------------------------------------------------------------- <br>// <br>class CMpegVideoOutputPin; <br>class CMpegVideoInpuPin; <br> <br>class CMpegVideoCodec <br>    : public CTransformFilter { <br> <br>public: <br> <br>    // <br>    // --- Com stuff --- <br>    // <br>    static CUnknown * WINAPI CreateInstance(LPUNKNOWN, HRESULT *); <br>    STDMETHODIMP NonDelegatingQueryInterface(REFIID riid, void ** ppv); <br>    DECLARE_IUNKNOWN; <br> <br>    // <br>    // --- CTransform overrides --- <br>    // <br>    HRESULT Receive(IMediaSample *pSample); <br>    HRESULT CheckInputType(const CMediaType* mtIn); <br>    HRESULT CheckTransform(const CMediaType* mtIn, const CMediaType* mtOut); <br>    HRESULT DecideBufferSize(IMemAllocator * pAllocator, <br>                             ALLOCATOR_PROPERTIES * pProperties); <br>    HRESULT SetMediaType(PIN_DIRECTION direction,const CMediaType *pmt); <br>    HRESULT GetMediaType(int iPosition, CMediaType *pMediaType); <br>    HRESULT StartStreaming(void); <br>    HRESULT StopStreaming(void); <br>    HRESULT EndOfStream(void); <br>    HRESULT EndFlush(void); <br>    HRESULT AlterQuality(Quality q); <br> <br> <br>    CMpegVideoCodec(TCHAR *pName, LPUNKNOWN pUnk, HRESULT *pHr); <br>    ~CMpegVideoCodec(); <br> <br> <br>    // <br>    // Callback function from low-level deocoder to get an output <br>    // buffer to draw into. <br>    // <br>    LPBYTE GetDecodeBufferAndFormat(); <br> <br>private: <br>    LPBYTE          m_pSample; <br>    LONG            m_LenLeftInPacket; <br> <br>    // <br>    // Input buffer <br>    // <br>    int             m_VBlockSize; <br>    LPBYTE          m_Buffer; <br>    LPBYTE          m_BufferStart; <br>    LPBYTE          m_BufferCurr; <br>    LONG            m_BufferFullness; <br>    void            UpdateBufferPosition(LPBYTE lpNewCurrent); <br> <br> <br>    // <br>    // Output buffer, for decode I and P frames. <br>    // <br>    LPBYTE          m_pFrameBuff; <br> <br> <br>    // <br>    // Sequence header of the video stream beging played. <br>    // <br>    SEQHDR_INFO     m_seqInfo; <br> <br> <br> <br>    // <br>    // Decode statistics, number of I, P, B and skipped frames. <br>    // <br>    DWORD           m_dwFramesDecoded[4]; <br>    DWORD           m_dwFramesSkipped[4]; <br>    int             m_PerfDecode; <br>    int             m_QualMsg; <br>    int             m_FrameDrawn; <br>    int             m_FrameType; <br> <br> <br>    // <br>    // This is the low level mpeg video decoder that all the work <br>    // <br>    DWORD           m_dwLateBy; <br>    DWORD           m_dwCtrl; <br>    DWORD           m_dwCtrlDefault; <br>    DWORD           m_dwQualDefault; <br>    CVideoDecoder   *m_pVideoDecoder; <br>    VideoCtrl       m_VideoControl; <br> <br>    // <br>    // The decoder calls back to get the colour conversion format <br>    // and a buffer to decode into.  The callback is static because it <br>    // does not have a "this" pointer.  hrCallback is used to keep a record <br>    // of any error that may have occurred during the callback. <br>    // <br>    void            SetOutputPinMediaType(const CMediaType *pmt); <br>    IMediaSample    *m_pOutSample; <br>    HRESULT         hrCallback; <br> <br> <br> <br>    // <br>    // If the input sample contains a sync point then its <br>    // sample time is correct.  I will use this time to resync my <br>    // internal clock and reset the count of frames decoded <br>    // since the previous sync point.  Otherwise, if the sample <br>    // is not a sync point I use the average time per frame and <br>    // the count of frames since the last sync point to interpolate <br>    // a suitable time for the newly decoded frame. <br>    // <br>    CRefTime        m_TimeAtLastSyncPoint; <br>    CRefTime        m_TimeSinceLastSyncPoint; <br>    CRefTime        m_tStopPrev;     // Previous stop time <br>    CGenericList&lt;CTimePosition&gt; m_PtsQueue; <br> <br> <br>    // <br>    // IP Frame tracking class <br>    // <br>    class CNextIP <br>    { <br>    public: <br>        CNextIP(); <br>        BOOL GotFirst(); <br>        void NextRef(DWORD dwTemporalReference); <br>        BOOL GetTime(REFERENCE_TIME *pt); <br>        BOOL TimeToDraw() const; <br>        void Reset(); <br>        void Set(DWORD dwSkipFlag, BOOL bIFrame, <br>                 BOOL bTimeSet, REFERENCE_TIME t, DWORD dwTemporalReference); <br> <br>    private: <br>        DWORD           m_dwSkipFlag; <br>        BOOL            m_bGotFirst; <br>        BOOL            m_bTimeSet; <br>        BOOL            m_bTimeToDraw; <br>        REFERENCE_TIME  m_t; <br>        DWORD           m_dwTemporalReference; <br>    }; <br> <br>    CNextIP         m_NextIP; <br> <br> <br>    // <br>    // Remember whether the media type specified packets or payload <br>    // <br>    BOOL            m_bPayloadOnly; <br> <br> <br>    // <br>    // On 8 bit displays the user can select a gray scale palette <br>    // alteranative to the default colour palette, this bypasses the <br>    // colour space conversion code. <br>    // <br>    enum MEDIA_FORMATS {MM_411PK, MM_422PK, MM_422SPK, MM_RGB24_DIB, <br>                        MM_RGB24_DDB, MM_RGB565_DIB, MM_RGB565_DDB, <br>                        MM_RGB555_DIB, MM_RGB555_DDB, MM_RGB8_DIB, <br>                        MM_RGB8_DDB, MM_Y_DIB, MM_Y_DDB}; <br> <br>    enum MEDIA_TYPES   {MT_Y41P = 0, MT_YUY2, MT_UYVY, MT_RGB24, MT_RGB565, <br>                        MT_RGB555, MT_RGB8, MT_COUNT_OF_TYPES = MT_RGB8}; <br> <br>    enum PALETTE_TYPE {COLOUR_PALETTE, GREY_PALETTE}; <br> <br>    PALETTE_TYPE    m_PaletteType; <br>    BOOL            m_IgnoreQualityMessage; <br>    DWORD           m_dwOutputFormatDib; <br>    DWORD           m_dwOutputFormatDdb; <br> <br>    HRESULT         CopySampleToBuffer(IMediaSample *pSample); <br>    BOOL            UpdateTimeSyncPoint(LPBYTE lpPicStart, REFERENCE_TIME *Time); <br>    ptrdiff_t       BuffOffset(LPBYTE Offset); <br> <br>    HRESULT         DecodeNextPicture(); <br>    void            ResetVideoDecoder(); <br>    void            DecodeUntilBufferEmpty(); <br> <br>    void            InitDestinationVideoInfo(VIDEOINFO *pVI, DWORD Comp, int n); <br>    void            InitDestinationPalette(VIDEOINFO *pVideoInfo); <br> <br>    BOOL            ParseSequenceHeader(const BYTE *pbData, LONG lData, <br>                                        SEQHDR_INFO *pInfo); <br> <br>    // <br>    //  Stop time <br>    // <br>    CRefTime        m_tStop; <br>}; <br>#endif </code></pre>
<p>&nbsp;</p></body>
</HTML>
