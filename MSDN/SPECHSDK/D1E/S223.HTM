<HTML><HEAD><script async src="https://www.googletagmanager.com/gtag/js?id=UA-83731338-2"></script><script>  window.dataLayer = window.dataLayer || [];  function gtag(){dataLayer.push(arguments);}  gtag('js', new Date());  gtag('config', 'UA-83731338-2');</script><title>Audio-Destination Object</TITLE><META HTTP-EQUIV="CONTENT-TYPE" CONTENT="text/html; charset= iso-8859-1"><style>@import url(/msdn_ie4.css);</style>
<link disabled rel="stylesheet" href="/msdn_ie3.css"></HEAD><BODY BGCOLOR="#FFFFFF">
<FONT FACE="verdana,atial,helvetica" SIZE="2"><FORM NAME="x"><OBJECT CLASSID="clsid:9c2ac687-ceef-11cf-96d9-00a0c903b016" NAME="iv"></OBJECT></FORM>
<h2>Audio-Destination Object</H2><P>Before an application can use text-to-speech, it must determine where the speech audio should be played. Typical audio destinations include the user's computer, a telephone line, or a file. </P>
<P>To play audio on a wave-out device, the application can create an instance of the multimedia audio-destination object, which is an OLE Component Object Model (COM) object that supports audio communication interfaces in common with the engine. To send audio to a different destination, such as a file, or to manipulate the audio before it reaches the destination device, an application can use a custom audio-destination object that the application developer provides or use one provided by a third-party vendor. </P></FONT></BODY></HTML>
