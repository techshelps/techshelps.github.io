<HTML><HEAD><script async src="https://www.googletagmanager.com/gtag/js?id=UA-83731338-2"></script><script>  window.dataLayer = window.dataLayer || [];  function gtag(){dataLayer.push(arguments);}  gtag('js', new Date());  gtag('config', 'UA-83731338-2');</script><title>ITTSCentral::TextData</TITLE><META HTTP-EQUIV="CONTENT-TYPE" CONTENT="text/html; charset= iso-8859-1"><style>@import url(/msdn_ie4.css);</style>
<link disabled rel="stylesheet" href="/msdn_ie3.css"></HEAD><BODY BGCOLOR="#FFFFFF">
<FONT FACE="verdana,atial,helvetica" SIZE="2"><FORM NAME="x"><OBJECT CLASSID="clsid:9c2ac687-ceef-11cf-96d9-00a0c903b016" NAME="iv"></OBJECT></FORM>
<h2>ITTSCentral::TextData</H2><P></P>
<P>HRESULT TextData(VOICECHARSET eCharacterSet, DWORD dwFlags, SDATA dText, <BR>    PVOID pNotifyInterface, IID IIDNotifyInterface);</P>
<P></P>
<P>Starts the process of converting text into audio data to be spoken.</P>
<P> <FONT FACE="Symbol">·</FONT>    Returns NOERROR if successful, or one of these error values:</P>
<P>&lt;E_FAIL&gt;<BR>&lt;E_INVALIDARG&gt;<BR>&lt;E_OUTOFMEMORY&gt;<BR>&lt;TTSERR_INVALIDCHAR&gt;<BR>&lt;TTSERR_QUEUEFULL&gt;<BR>&lt;TTSERR_WAVEDEVICEBUSY&gt;</P>
<P></P>
<P><I>eCharacterSet</I></P>
<P>[in] Character set to be used to convert the text. This parameter can be one of these values:</P>

<TABLE COLS="2" BORDER="0" CELLPADDING="7"><COLGROUP><COL WIDTH="161pt" VALIGN="TOP"><COL WIDTH="173pt" VALIGN="TOP"></COLGROUP><TBODY><TR><TD VALIGN="TOP"><P>Value</P></TD><TD VALIGN="TOP"><P>Meaning</P></TD></TR><TR><TD COLSPAN="2" VALIGN="TOP"><P></P></TD></TR><TR><TD VALIGN="TOP"><P>CHARSET_ENGINEPHONETIC</P></TD><TD VALIGN="TOP"><P>An engine-specific phonetic character set</P></TD></TR><TR><TD VALIGN="TOP"><P>CHARSET_IPAPHONETIC</P></TD><TD VALIGN="TOP"><P>The IPA character set</P></TD></TR><TR><TD VALIGN="TOP"><P>CHARSET_TEXT</P></TD><TD VALIGN="TOP"><P>The text character set</P></TD></TR></TBODY></TABLE>
<P><BR></P><P></P>
<P>If the engine cannot handle the character set, it returns an error.</P>
<P></P>
<P><I>dwFlags</I></P>
<P>[in] TTSDATAFLAG_TAGGED if the text contains text-to-speech control tags that alter inflection, speed, and so on, or zero if the text does not contain tags. Note that an engine-specific phonetic character set may use a different tagging protocol than that used by the IPA character set. This is left for future expansion.</P>
<P><I>dText</I></P>
<P>[in] <B>SDATA</B> structure. The <B>pData</B> member contains the null-terminated string for the text to be spoken, and the <B>dwSize</B> member specifies the length of the string, including the terminating NULL. Because <B>TextData</B> copies this text into one or more text-to-speech buffers, the application can free the source buffer as soon as the function returns. When the engine finishes processing the last text-to-speech buffer, the engine notifies the application by calling the <B>ITTSBufNotifySink::TextDataDone</B> member function. The engine does not wait for the audio object to finish speaking the audio before calling <B>TextDataDone</B>. The size of a text-to-speech buffer is determined by the engine. If the engine cannot allocate enough memory to store the text-to-speech buffers, it should return E_OUTOFMEMORY. </P>
<P>If <I>dText</I> contains an empty (NULL) string, the engine returns NOERROR and sends both the <B>ITTSBufNotifySink::TextDataStarted</B> and <B>ITTSBufNotifySink::TextDataDone</B> notifications.</P>
<P></P>
<P><I>pNotifyInterface</I></P>
<P>[in] Address of the notification interface through which the engine notifies the application about the status of the text-to-speech buffer. The interface identifier is specified by <I>IIDNotifyInterface. </I>If the application does not require notifications, this parameter can be NULL. </P>
<P>Because passing the address does not transfer ownership of the notification interface, the engine must call the <B>AddRef </B>member function of the notification interface before returning from the call to <B>TextData</B>. The engine must also call the <B>Release</B> member function of the notification interface when it closes. The calling application must release any reference counts it holds on the notification interface after calling <B>TextData</B>, unless it needs the notification object to be valid when the engine releases it. </P>
<P></P>
<P><I>IIDNotifyInterface</I></P>
<P>[in] Interface identifier of the interface used for notification. In the current implementation, the identifier must be IID_ITTSBufNotifySinkA (for ANSI) or IID_ITTSBufNotifySinkW (for Unicode). An engine can define additional values to support custom interfaces.</P>
<P></P>
<P><B>TextData</B> is asynchronous — that is, the member function returns before all of the text is played.</P>
<P><B>TextData</B> passes the text to the engine, which performs the actual conversion of text to audio; however, this function may initiate the conversion in a different thread. The engine can use a background thread to convert the text.</P>
<P>Text is loaded into a series of buffers. As each buffer is loaded, the engine converts the text to audio. If the engine receives the next buffer while it is still processing the previous one, the next buffer is appended to the previous buffer's text. If the engine cannot allocate enough memory to store the text-to-speech buffers, it should return E_OUTOFMEMORY.</P>
<P>Each text-to-speech buffer is assumed to be a continuation of the previous buffer and is not autonomous. To make the buffer autonomous, send an <B>Rst</B> (reset) tag. If an engine reaches the end of a buffer and finds no more buffers in the text-to-speech buffer queue, the engine can assume that the end of the buffer completes a statement. For best results, the <B>SDATA</B> structure specified by <I>dText</I> should contain the address of a complete sentence or paragraph. If the structure contains the address of a complete sentence or paragraph, the text-to-speech buffer that <B>TextData</B> passes to the engine for conversation to audio data will be aligned on a sentence or paragraph boundary.</P>
<P>If <B>TextData</B> is called while the engine is processing the previous buffer, the engine concatenates the new buffer with the previous one. For example, if the previous buffer contains "&lt;a bunch of words&gt; wal" and <B>TextData</B> adds another buffer containing "ked &lt;a bunch more words&gt;", the engine should speak, "&lt;a bunch of words&gt; walked &lt;a bunch more words&gt;." However, if the engine has already finished processing the previous buffer (because it processes a sentence or paragraph ahead), it speaks, "&lt;a bunch of words&gt; wal. ked &lt;a bunch more words&gt;."</P>
<P>Initially, an engine object plays any text that is sent to it as soon as possible. To change this state, you should call the <B>ITTSCentral::AudioPause</B> member function. Once <B>AudioPause</B> is called, no audio is output until the <B>ITTSCentral::AudioResume</B> member function is called.</P></FONT></BODY></HTML>
