<HTML><HEAD><script async src="https://www.googletagmanager.com/gtag/js?id=UA-83731338-2"></script><script>  window.dataLayer = window.dataLayer || [];  function gtag(){dataLayer.push(arguments);}  gtag('js', new Date());  gtag('config', 'UA-83731338-2');</script><title>About Voice Commands</TITLE><META HTTP-EQUIV="CONTENT-TYPE" CONTENT="text/html; charset= iso-8859-1"><style>@import url(/msdn_ie4.css);</style>
<link disabled rel="stylesheet" href="/msdn_ie3.css"></HEAD><BODY BGCOLOR="#FFFFFF">
<FONT FACE="verdana,atial,helvetica" SIZE="2"><FORM NAME="x"><OBJECT CLASSID="clsid:9c2ac687-ceef-11cf-96d9-00a0c903b016" NAME="iv"></OBJECT></FORM>
<H1>About Voice Commands</H1><P><I>Voice commands</I> allow the user to control an application by speaking commands through an audio input device rather than by using the mouse or keyboard, giving the user hands-free control of the application. Voice commands involve the use of an audio input device, such as a microphone or a telephone, a speech-recognition engine, and a voice menu. When the user speaks a command into the audio input device, the speech-recognition engine attempts to transcribe the spoken input into text. If the engine succeeds, it compares the command text to that of the commands in the active voice menus. (A voice menu contains a list of commands to which an application can respond.) If the engine finds a matching command in a voice menu, it notifies the application of the match, and the application carries out the command. </P>
<P>Implementing voice commands in an application involves the use of three different objects: the voice-command object, the voice-menu object, and the voice-menu enumerator. This section describes these objects and explains how to use them to implement voice commands in an application. </P>
<P>Some users do not wish to have the computer speak or to talk to the computer. For these users, Microsoft provides a Speech control panel application that sets a registry entry indicating the user's preferences. An application can check this entry before trying to load its voice-command code and can save memory by not loading the code if it is not needed. For more information about the registry entry, see the section, "Common Elements of the Speech Application Programming Interface.".</P>
<P>The voice-command and voice-menu objects are exposed as OLE automation objects, allowing them to be accessed and controlled through Visual Basic, Visual Basic for Applications (VBA), and other automation-aware application macro languages. You can take advantage of the OLE automation capabilities of these objects to add voice commands and voice-text capabilities to your Visual Basic applications. For more information, see Appendix E, "Voice Commands, Text-to-Speech, and OLE Automation." </P></FONT></BODY></HTML>
