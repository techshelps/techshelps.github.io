<HTML><HEAD><script async src="https://www.googletagmanager.com/gtag/js?id=UA-83731338-2"></script><script>  window.dataLayer = window.dataLayer || [];  function gtag(){dataLayer.push(arguments);}  gtag('js', new Date());  gtag('config', 'UA-83731338-2');</script><title>Dictation Grammars</TITLE><META HTTP-EQUIV="CONTENT-TYPE" CONTENT="text/html; charset= iso-8859-1"><style>@import url(/msdn_ie4.css);</style>
<link disabled rel="stylesheet" href="/msdn_ie3.css"></HEAD><BODY BGCOLOR="#FFFFFF">
<FONT FACE="verdana,atial,helvetica" SIZE="2"><FORM NAME="x"><OBJECT CLASSID="clsid:9c2ac687-ceef-11cf-96d9-00a0c903b016" NAME="iv"></OBJECT></FORM>
<H3>Dictation Grammars</H3><P>Context-free grammars are sufficient for command and control or data entry, but speech recognition requires another grammar format, the dictation grammar. The dictation grammar format is much simpler than the context-free grammar format, so the application almost always generates the binary form of the dictation grammar. This format consists of the following elements:</P>
<P> <FONT FACE="Symbol">·</FONT>    A broad category name such as "Medical," "Legal," or "Scientific." Some engines may have predefined language models for these and can take advantage of them.</P>
<P> <FONT FACE="Symbol">·</FONT>    Several pages of sample writing from the user. This allows an engine to determine the user's writing style and vocabulary. The sample should correspond to the expected use of the grammar — for example, if the grammar is to be used for electronic mail, the sample writing should consist of e-mail messages. Or, if the session is for dictating a business letter, the samples should be business letters.</P>
<P> <FONT FACE="Symbol">·</FONT>    Words to expect. If the application has information about what the user will be speaking about, it can include a set of likely words.</P>
<P> <FONT FACE="Symbol">·</FONT>    Related words. An application can include sets of related words that are likely to occur in the dictation, such as city names or company names.</P>
<P></P>
<P>The application interacts with the grammar's data format and grammar objects in exactly the same way as it does with a context-free grammar, except that instead of using the <B>ISRGramCFG</B> interface, it uses <B>ISRGramDictation</B>.</P>
<P>The <B>ISRGramDictation</B> interface contains various functions that allow the application to tell the dictation engine what it expects the user to say next. These functions allow well-written applications to get an extra boost in accuracy.</P>
<P>The <B>ISRGramDictation::Context</B> member function provides the speech-recognition engine with the words that were spoken before and after the current utterance. An application calls the <B>Context</B> member function whenever the cursor position changes in a text document. </P>
<P>The <B>Hint</B> member function gives the speech-recognition engine information about the kind of text that the speaker is dictating. If an application has information that the user is about to speak an address, number, name, or some other specific data type, it should call the <B>Hint</B> member function to inform the engine. </P>
<P>An application can use the <B>Words</B> member function to give the engine a list of words that the user is likely to speak. </P>
<P>Archiving is more important for dictation grammars than context-free grammars because dictation grammars take longer to compile into native format and more information about the session is stored by the engine.</P>
<P>For more information about dictation grammars, see "Supporting Dictation in an Application" later in this section.</P></FONT></BODY></HTML>
