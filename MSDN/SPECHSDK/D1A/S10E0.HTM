<HTML><HEAD><script async src="https://www.googletagmanager.com/gtag/js?id=UA-83731338-2"></script><script>  window.dataLayer = window.dataLayer || [];  function gtag(){dataLayer.push(arguments);}  gtag('js', new Date());  gtag('config', 'UA-83731338-2');</script><title>S</TITLE><META HTTP-EQUIV="CONTENT-TYPE" CONTENT="text/html; charset= iso-8859-1"><style>@import url(/msdn_ie4.css);</style>
<link disabled rel="stylesheet" href="/msdn_ie3.css"></HEAD><BODY BGCOLOR="#FFFFFF">
<FONT FACE="verdana,atial,helvetica" SIZE="2"><FORM NAME="x"><OBJECT CLASSID="clsid:9c2ac687-ceef-11cf-96d9-00a0c903b016" NAME="iv"></OBJECT></FORM>
<h2>S</H2><P><B>SNR (signal-to-noise ratio)</B></P>
<P>The amount of power, measured in decibels (dB), by which a signal exceeds the amount of channel noise at the same point of transmission. It provides an indication of the clarity or accuracy with which communication can take place.</P>
<P></P>
<P><B>speaker</B></P>
<P>The end-user who utters the speech to be recognized by an application. Training performed by a speaker may be stored in a speaker profile.</P>
<P></P>
<P><B>speaker-adaptive</B></P>
<P>The engine trains itself to recognize the user's voice while the user performs ordinary tasks.</P>
<P></P>
<P><B>speaker-dependent</B></P>
<P>The engine requires the user to train it to recognize his or her voice.</P>
<P></P>
<P><B>speaker-independent</B></P>
<P>The engine does not require training. Speaker-independent engines typically start with an accuracy above 95 percent for most users (those who speak without accents).</P>
<P></P>
<P><B>speaker profile</B></P>
<P>All of the information the engine has about the speaker, such as a data header, languages for which training has been done, known patterns of speech and the language model, how specific words are pronounced, phonetic training, speaker ID, and speaker preferences.</P>
<P></P>
<P><B>speech recognition</B></P>
<P>The ability of a computer to understand the spoken word for the purpose of receiving command and data input from the speaker.</P>
<P></P>
<P><B>speech-recognition engine</B></P>
<P>An OLE Component Object Model dynamic-link library (DLL) or executable file (.exe) that performs recognition from a digital-audio stream. Speech-recognition engines are supplied by vendors who specialize in the software.</P>
<P></P>
<P><B>speech-recognition enumerator</B></P>
<P>Enumerates the engines that are available to an application.</P>
<P></P>
<P><B>speech-recognition mode</B></P>
<P>An engine typically provides an assortment of modes that can be used to recognize speech in different languages, dialects, and audio-sampling rates.</P>
<P></P>
<P><B>speech-recognition results object</B></P>
<P>Provides detailed information about a speech-recognition event.</P>
<P></P>
<P><B>speech-recognition sharing object</B></P>
<P>Enumerates shared engine-audio source pairs, or creates new ones.</P>
<P></P>
<P><B>subword matching</B></P>
<P>The engine looks for subwords—usually phonemes—and then performs further pattern recognition on those.</P>
<P></P>
<P><B>synthesis</B></P>
<P>The text-to-speech engine synthesizes the glottal pulse from human vocal cords and applies various filters to simulate throat length, mouth cavity, lip shape, and tongue position.</P></FONT></BODY></HTML>
