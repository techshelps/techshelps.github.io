<HTML><HEAD><script async src="https://www.googletagmanager.com/gtag/js?id=UA-83731338-2"></script><script>  window.dataLayer = window.dataLayer || [];  function gtag(){dataLayer.push(arguments);}  gtag('js', new Date());  gtag('config', 'UA-83731338-2');</script><title>Porting an Existing Speech-Recognition Engine</TITLE><META HTTP-EQUIV="CONTENT-TYPE" CONTENT="text/html; charset= iso-8859-1"><style>@import url(/msdn_ie4.css);</style>
<link disabled rel="stylesheet" href="/msdn_ie3.css"></HEAD><BODY BGCOLOR="#FFFFFF">
<FONT FACE="verdana,atial,helvetica" SIZE="2"><FORM NAME="x"><OBJECT CLASSID="clsid:9c2ac687-ceef-11cf-96d9-00a0c903b016" NAME="iv"></OBJECT></FORM>
<H3>Porting an Existing Speech-Recognition Engine</H3><P>Typically, an engine developer ports the code for an existing speech-recognition engine from 16-bit Windows, UNIX&reg;, Macintosh&reg;, or OS/2&reg;, rather than developing a completely new engine. Porting a speech-recognition engine to the speech API usually involves the following steps:</P>
<P>    1.    Port the engine code to Win32 by using the API that is already in the code. This should be straightforward, but be aware that this may uncover old bugs because Win32 is more stringent about memory usage.</P>
<P>    2.    Move the engine code into a dynamic-link library (DLL).</P>
<P>    3.    Implement the major interfaces for speech recognition first to get the engine running with the speech API as quickly as possible.</P>
<P>    4.    Redesign the engine's audio input and output architecture to use streams. Using streams makes the engine consistent with the multimedia audio source and multimedia audio-destination objects, which also use streams. These objects are similar to multimedia wave-in and wave-out drivers. </P>
<P>    5.    Design the engine's interface architecture to support the interfaces defined for the speech-recognition engine object.</P>
<P>    6.    Implement the speech-recognition interfaces and functions for the engine.</P>
<P>    7.    Write additional code to enable the engine to support multiple instances. The time required to do this varies depending on the engine's internal architecture.</P>
<P></P>
<P>The engine must provide the engine enumerator, engine object, and grammar object, and may optionally provide a speech-recognition results object. The following table lists the required and optional interfaces for each object.</P>
<P>The engine should support both ANSI and Unicode implementations of each interface.</P>

<TABLE COLS="2" BORDER="0" CELLPADDING="7"><COLGROUP><COL WIDTH="168pt" VALIGN="TOP"><COL WIDTH="180pt" VALIGN="TOP"></COLGROUP><TBODY><TR><TD VALIGN="TOP"><P>Object</P></TD><TD VALIGN="TOP"><P>Interface</P></TD></TR><TR><TD COLSPAN="2" VALIGN="TOP"><P></P></TD></TR><TR><TD VALIGN="TOP"><P>Engine enumerator</P></TD><TD VALIGN="TOP"><P>ISREnum<BR>ISRFind (optional)</P></TD></TR><TR><TD VALIGN="TOP"><P>Engine</P></TD><TD VALIGN="TOP"><P>ILexPronounce (optional)<BR>ISRAttributes<BR>ISRCentral<BR>ISRDialogs<BR>ISRSpeaker (optional)</P></TD></TR><TR><TD VALIGN="TOP"><P>Grammar</P></TD><TD VALIGN="TOP"><P>ISRGramCFG (context-free grammar)<BR>ISRGramCommon<BR>ISRGramDictation (dictation grammar)</P></TD></TR><TR><TD VALIGN="TOP"><P>Speech recognition results (optional)</P></TD><TD VALIGN="TOP"><P>ISRResAudio (optional)<BR>ISRResBasic (optional)<BR>ISRResCorrection (optional)<BR>ISRResEval (optional)<BR>ISRResGraph (optional)<BR>ISRResMemory (optional)<BR>ISRResMerge (optional)<BR>ISRResSpeaker (optional)</P></TD></TR></TBODY></TABLE>
<P><BR></P><P></P>
<P>The engine should also support the following notification sinks to pass information back to the application.</P>
<P> <FONT FACE="Symbol">·</FONT>    <B>ISRNotifySink</B>.  Used by an engine object to notify the application of interference, noise, and other factors that affect speech recognition.</P>
<P> <FONT FACE="Symbol">·</FONT>    <B>ISRGramNotifySink</B>.  Used by a grammar object to notify the application about a particular recognition.</P></FONT></BODY></HTML>
