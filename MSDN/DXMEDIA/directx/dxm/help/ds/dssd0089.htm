<!DOCTYPE HTML PUBLIC "-//IETF//DTD HTML//EN">
<HTML>
<HEAD><script async src="https://www.googletagmanager.com/gtag/js?id=UA-83731338-2"></script><script>  window.dataLayer = window.dataLayer || [];  function gtag(){dataLayer.push(arguments);}  gtag('js', new Date());  gtag('config', 'UA-83731338-2');</script><title>Exposing Capture and Compression Formats</TITLE>
<STYLE>
<!--
.tctop {color: blue}
.cpslug {color: blue; text-decoration: none}
-->
</STYLE>
<META NAME="MS-HKWD" CONTENT="Exposing Capture and Compression Formats">
<META HTTP-EQUIV="Content-Type" CONTENT="text/html; CHARSET=iso8859-1">
<META NAME="MS.LOCALE" CONTENT="EN-US">
<META NAME="ROBOTS" CONTENT="all">
<OBJECT ID="DAControl" 
  STYLE="position:absolute; left:0; top:11;width:702;height:90"
  CLASSID="CLSID:B6FFC24C-7E13-11D0-9B47-00C04FC2F51D">
</OBJECT>
<!--STYLE="width:702;height:110"-->
<SCRIPT LANGUAGE="JScript">
<!--
  // The DirectAnimation library
  m = DAControl.PixelLibrary;

  /* -- Insert your code here --*/ 

  mediaBase = "art\\";
  glowBase = m.importImage(mediaBase + "glow.gif");
  xImage = m.importImage(mediaBase + "newtransx.gif");
  xImage = xImage.Transform(m.Translate2(-303,0));
  //header1 = m.importImage(mediaBase + "header1.gif");
  //header1 = header1.Transform(m.Translate2(-301,0));

  //header2 = m.importImage(mediaBase + "hdrd3drm.gif");
  //header2 = header2.Transform(m.Translate2(-143,0));

  //header3 = m.importImage(mediaBase + "header3.gif");
  //header3 = header3.Transform(m.Translate2(157,-18));

  //background = m.Overlay(header1, m.Overlay( header2, header3));

  glowPath1 = m.Polyline( new Array( 295,26, 305,26, 305,50, 310,57, 519,57, 
    536,40, 536,17, 675,17, 675,23 ) );

  glowPath2 = m.PolyLine( new Array( 44,41, 44,25, 52,16, 84,16, 106,16 ) );

  glowPath3 = m.PolyLine( new Array( 57,55, 69,55, 78,65, 92,65, 99,58,
    99,82, 95,85, 95,93, 132,93, 132,78,
    303,78, 315,66, 549,66, 549,17, 675,17,
    675,23 ) );

  glowPath4 = m.PolyLine( new Array( 29,55, 19,55, 19,31, 38,30, 38,21,
    46,16, 106,16 ) );

  glowPath5 = m.PolyLine( new Array( 45,62, 45,81, 37,81, 41,85, 46,85,   
  51,91, 68,91, 66,81, 90,81, 90,65, 94,65, 105,47 ) );

  glow1 = glowBase.Transform( moveGlow( glowPath1, 5 ) );
  glow2 = glowBase.Transform( moveGlow( glowPath2, 2 ) );
  glow3 = glowBase.Transform( moveGlow( glowPath3, 8 ) );
  glow4 = glowBase.Transform( moveGlow( glowPath4, 2.5 ) );
  glow5 = glowBase.Transform( moveGlow( glowPath5, 2 ) );

  finalImg = m.Overlay(xImage, m.Overlay( glow5, m.Overlay( glow4, 
    m.Overlay( glow3, m.Overlay( glow2, glow1)))));


  // set the model, an image, as the model to be displayed
  DAControl.Image = finalImg;//m.Overlay(finalImg, background);
  // set the background in case of a non-windowless browser (like IE3)
  DAControl.BackgroundImage = m.SolidColorImage(m.Blue);     
     
  // start the animation       
  DAControl.Start()


  function moveGlow(path, speed)  {
    imDimX = 702;
    imDimY = 120;

    coordsXf = m.Translate2(-imDimX/2, -imDimY/2);
    path = path.Transform(coordsXf);
    return xf = m.FollowPath(path, speed).Repeat(1);
  }

//-->
</SCRIPT>
</HEAD>
<BODY TOPMARGIN=0 LEFTMARGIN=0 BGPROPERTIES="FIXED" BGCOLOR="#FFFFFF" LINK="#000000" VLINK="#808080" ALINK="#000000">
<A NAME="pagetop"></A><A NAME="Stream_Capabilities"></A>

<TABLE BORDER=0 CELLSPACING="0" CELLPADDING="0" WIDTH="*">
<TR>
<TD ROWSPAN="3" VALIGN="TOP" WIDTH="*">
<IMG SRC="/directx/dxm/help/ds/art/header1.gif" WIDTH="107" HEIGHT="110" BORDER=0 ALT="DirectShow Animated Header -- Exposing Capture and Compression Formats"></TD>
<TD ROWSPAN="2" VALIGN="TOP" WIDTH="217"><IMG SRC="/directx/dxm/help/ds/art/hdrdshow.gif" WIDTH="210" HEIGHT="110" BORDER=0 ALT="DirectShow Animated Header -- Exposing Capture and Compression Formats"></TD><TD VALIGN="TOP" WIDTH="383"><IMG SRC="/directx/dxm/help/ds/art/header3.gif" WIDTH="383" HEIGHT="95" BORDER=0 ALT="*">
</TD>
<TD VALIGN="TOP" WIDTH="100%">
<IMG SRC="/directx/dxm/help/d3drm/art/spacer1.gif" WIDTH="100%" HEIGHT="94" BORDER=0 ALT="Microsoft DirectShow SDK">
</TD>
</TR><TR><TD VALIGN="TOP"><PRE><FONT FACE="VERDANA,ARIAL,HELVETICA" SIZE="1"><IMG SRC="/directx/dxm/help/ds/art/yelbtn.gif" WIDTH="11" HEIGHT="11" ALIGN="MIDDLE" BORDER=0 ALT="*"><A STYLE="color:black;font-weight:bold" HREF="/directx/dxm/help/ds/index.htm">Index</A>  <IMG SRC="/directx/dxm/help/ds/art/yelbtn.gif" WIDTH="11" HEIGHT="11" ALIGN="MIDDLE" BORDER=0 ALT="*"><A STYLE="color:black;font-weight:bold" HREF="/directx/dxm/help/ds/dssd0066.htm">Topic Contents</A>
</FONT></PRE></TD></TR>
<TR><TD COLSPAN="2" VALIGN="TOP"><PRE><FONT FACE="Verdana,Arial,Helvetica" SIZE="1"><IMG SRC="/directx/dxm/help/ds/art/yelbtn.gif" WIDTH="11" HEIGHT="11" ALIGN="MIDDLE" BORDER=0 ALT="*"><B>Previous Topic:</B> <A  STYLE="color:black" HREF="/directx/dxm/help/ds/rectangles.htm">Source and Target Rectangles in Video Renderers</A>
<IMG SRC="/directx/dxm/help/ds/art/yelbtn.gif" WIDTH="11" HEIGHT="11" ALIGN="MIDDLE" BORDER=0 ALT="*"><B>Next Topic:</B> <A  STYLE="color:black" HREF="/directx/dxm/help/ds/dssd0090.htm">C/C++ Reference</A>
</FONT></PRE></TD></TR></TABLE><BR CLEAR=ALL>
<FONT FACE="VERDANA,ARIAL,HELVETICA" SIZE="2"><BLOCKQUOTE STYLE="margin:15pt">
<H2>Exposing Capture and Compression Formats</H2>
<BR CLEAR=ALL>
<P>This article describes how to return capture and compression formats by using the <A HREF="/directx/dxm/help/ds/dssd0108.htm#GetStreamCaps">IAMStreamConfig::GetStreamCaps</A> method. This method can get more information about accepted media types than the traditional way of enumerating a pin's media types, so it should typically be used instead. See <A CLASS=TCTOP HREF="/directx/dxm/help/ds/dssd0083.htm#transon_3">Establishing Media Type Connections</A> for information about traditional media type enumeration. <B>IAMStreamConfig::GetStreamCaps</B> can return information about the kinds of formats allowed for audio or video. Additionally, this article provides some sample code that demonstrates how to reconnect the input pin of a transform filter to ensure your filter can produce a particular output.

<P>The <A HREF="/directx/dxm/help/ds/dssd0108.htm#GetStreamCaps">IAMStreamConfig::GetStreamCaps</A> method returns an array of pairs of media type and capabilities structures. The media type is an <A HREF="/directx/dxm/help/ds/dssd0298.htm#AM_MEDIA_TYPE">AM_MEDIA_TYPE</A> structure and the capabilities are represented either by an <A HREF="/directx/dxm/help/ds/dssd0298.htm#AUDIO_STREAM_CONFIG_CAPS">AUDIO_STREAM_CONFIG_CAPS</A> structure or a <A HREF="/directx/dxm/help/ds/dssd0298.htm#VIDEO_STREAM_CONFIG_CAPS">VIDEO_STREAM_CONFIG_CAPS</A> structure. The first section in this article presents a video example and the second presents an audio example.

<P><B>Contents of this article:</B>
<UL><LI><A CLASS=TCTOP HREF="/directx/dxm/help/ds/dssd0089.htm#Video_Capabilities">Video Capabilities</A>
<LI><A CLASS=TCTOP HREF="/directx/dxm/help/ds/dssd0089.htm#Audio_Capabilities">Audio Capabilities</A>
<LI><A CLASS=TCTOP HREF="/directx/dxm/help/ds/dssd0089.htm#Reconnecting_your_Input">Reconnecting Your Input to Ensure Specific Output Types</A>
</UL>
<A NAME="Video_Capabilities"></A><P><B>Video Capabilities</B>
<P>The <A HREF="/directx/dxm/help/ds/dssd0108.htm#GetStreamCaps">IAMStreamConfig::GetStreamCaps</A> method presents video capabilities in an array of pairs of <A HREF="/directx/dxm/help/ds/dssd0298.htm#AM_MEDIA_TYPE">AM_MEDIA_TYPE</A> and <A HREF="/directx/dxm/help/ds/dssd0298.htm#VIDEO_STREAM_CONFIG_CAPS">VIDEO_STREAM_CONFIG_CAPS</A> structures. You can use this to expose all the formats and resolutions supported on a pin as discussed below.

<P>See <A CLASS=TCTOP HREF="/directx/dxm/help/ds/dssd0089.htm#Audio_Capabilities">Audio Capabilities</A> for audio-related examples of <A HREF="/directx/dxm/help/ds/dssd0108.htm#GetStreamCaps">IAMStreamConfig::GetStreamCaps</A>.

<P>Suppose your capture card supports JPEG format at all resolutions between 160 &#215; 120 pixels and 320 &#215; 240 pixels, inclusive. The difference between supported resolutions is one in this case because you add or subtract one pixel from each supported resolution to get the next supported resolution. This difference in supported resolutions is called granularity. 

<P>Suppose you card also supports the size 640 &#215; 480. The following illustrates this single resolution and the above range of resolutions (all sizes between 160 &#215; 120 pixels and 320 &#215; 240 pixels). 

<P><IMG SRC="/directx/dxm/help/ds/art/strmcap1.gif" WIDTH="386" HEIGHT="243" ALT="Illustration of JPEG support at all sizes between 160 &#215; 120 pixels and 320 &#215; 240 pixels, and 640 &#215; 480">

<P>Also, suppose it supports 24-bit color RGB format at resolutions between 160 &#215; 120 and 320 &#215; 240, but with a granularity of 8. The following illustration shows some of the valid sizes in this case. 

<P><IMG SRC="/directx/dxm/help/ds/art/strmcap3.gif" WIDTH="409" HEIGHT="271" ALT="Illustration of RGB support at sizes between 160 &#215; 120 and 320 &#215; 240 with a granularity of 8">

<P>To put it another way, and listing more resolutions, the following are all among the list of valid resolutions.

<UL><LI>160 &#215; 120
<LI>168 &#215; 120
<LI>168 &#215; 128
<LI>176 &#215; 128
<LI>176 &#215; 136
<LI>... additional resolutions ...
<LI>312 &#215; 232
<LI>320 &#215; 240
</UL>
<P>Use <A HREF="/directx/dxm/help/ds/dssd0108.htm#IAMStreamConfig">GetStreamCaps</A> to expose these color format and dimension capabilities by offering a media type of 320 &#215; 240 JPEG (if that is your default or preferred size) coupled with minimum capabilities of 160 &#215; 120, maximum capabilities of 320 &#215; 240, and a granularity of 1. The next pair you expose by using <B>GetStreamCaps</B> is a media type of 640 &#215; 480 JPEG coupled with a minimum of 640 &#215; 480 and a maximum of 640 &#215; 480 and a granularity of 0. The third pair includes a media type of 320 &#215; 240, 24-bit RGB with minimum capabilities of 160 &#215; 120, maximum capabilities of 320 &#215; 240, and a granularity of 8. In this way you can publish almost every format and capability your card might support. An application that must know what compression formats you provide can get all the pairs and make a list of all the unique subtypes of the media types.

<P>A filter obtains its media type source and target rectangles from the <A HREF="/directx/dxm/help/ds/dssd0298.htm#VIDEOINFOHEADER">VIDEOINFOHEADER</A> structure's 
<A HREF="/directx/dxm/help/ds/dssd0298.htm#VIDEOINFOHEADER_rcSource">rcSource</A> and <A HREF="/directx/dxm/help/ds/dssd0298.htm#VIDEOINFOHEADER_rcTarget">rcTarget</A> members, respectively. Filters do not have to support source and target rectangles.

<P>The cropping rectangle described throughout the <A HREF="/directx/dxm/help/ds/dssd0108.htm#IAMStreamConfig">IAMStreamConfig</A> documentation is the same as the <A HREF="/directx/dxm/help/ds/dssd0298.htm#VIDEOINFOHEADER">VIDEOINFOHEADER</A> structure's <A HREF="/directx/dxm/help/ds/dssd0298.htm#VIDEOINFOHEADER_rcSource">rcSource</A> rectangle for the output pin.

<P>The output rectangle described throughout the <A HREF="/directx/dxm/help/ds/dssd0108.htm#IAMStreamConfig">IAMStreamConfig</A> documentation is the same as the <B>biWidth</B> and <B>biHeight</B> members of the output pin's <A HREF="/directx/dxm/help/ds/dssd0078.htm#BITMAPINFOHEADER_AVI">BITMAPINFOHEADER</A> structure.

<P>If a filter's output pin is connected to a media type with nonempty source and target rectangles, then your filter is required to stretch the input format's source subrectangle into the output format's target subrectangle. The source subrectangle is stored in the <A HREF="/directx/dxm/help/ds/dssd0298.htm#VIDEO_STREAM_CONFIG_CAPS">VIDEO_STREAM_CONFIG_CAPS</A> structure's <A HREF="/directx/dxm/help/ds/dssd0298.htm#InputSize">InputSize</A> member.

<P>For example, consider the following video compressor scenario: The input image is in RGB format and has a size of 160 &#215; 120 pixels. The source rectangle's upper-left corner is at coordinate (20,20), and its lower-right corner is at (30,30). The output image is in MPEG format with a size of 320 &#215; 240. The target rectangle's upper-left corner is at (0,0) and its lower-right corner is at (100,100). In this case, the filter should take a 10 &#215; 10 piece of the 160 &#215; 120 RGB source bitmap, and make it fill the top 100 &#215; 100 area of a 320 &#215; 240 bitmap, leaving the rest of the 320 &#215; 240 bitmap untouched. The following illustration shows this scenario.

<P><IMG SRC="/directx/dxm/help/ds/art/strmcap4.gif" WIDTH="457" HEIGHT="290" ALT="Illustration of video compressor stretching subrectangle of image between source and target rectangles">

<P>A filter might not support this and can fail to connect with a media type where <A HREF="/directx/dxm/help/ds/dssd0298.htm#VIDEOINFOHEADER_rcSource">rcSource</A> and <A HREF="/directx/dxm/help/ds/dssd0298.htm#VIDEOINFOHEADER_rcTarget">rcTarget</A> are not empty.

<P>The <A HREF="/directx/dxm/help/ds/dssd0298.htm#VIDEOINFOHEADER">VIDEOINFOHEADER</A> structure exposes information about a filter's data rate capabilities. For example, suppose you connected your output pin to the next filter with a certain media type (either directly or by using the media type passed by the <A HREF="/directx/dxm/help/ds/dssd0238.htm#SetFormat">CMediaType::SetFormat</A> function). Look at the 
<A HREF="/directx/dxm/help/ds/dssd0298.htm#VIDEOINFOHEADER_dwBitRate">dwBitRate</A> member of that media type's <B>VIDEOINFOHEADER</B> format structure to see what data rate you should compress the video to. If you multiply the number of units of time per frame in the <B>VIDEOINFOHEADER</B> structure's 
<A HREF="/directx/dxm/help/ds/dssd0298.htm#VIDEOINFOHEADER_AvgTimePerFrame">AvgTimePerFrame</A> member by the data rate in the 
<B>dwBitRate</B> member and divide by 10,000,000 (the number of units per second), you can figure out how many bytes each frame should be. You can produce a smaller sized frame, but never a larger one. To determine the frame rate for a video compressor or for a capture filter, use <B>AvgTimePerFrame</B> from your output pin's media type. 


<A NAME="Audio_Capabilities"></A><P><B>Audio Capabilities</B>
<P>For audio capabilities, <A HREF="/directx/dxm/help/ds/dssd0108.htm#GetStreamCaps">IAMStreamConfig::GetStreamCaps</A> returns an array of pairs of <A HREF="/directx/dxm/help/ds/dssd0298.htm#AM_MEDIA_TYPE">AM_MEDIA_TYPE</A> and <A HREF="/directx/dxm/help/ds/dssd0298.htm#AUDIO_STREAM_CONFIG_CAPS">AUDIO_STREAM_CONFIG_CAPS</A> structures. As with video, you can use this to expose all kinds of audio capabilities on the pin, such as data rate and whether it supports mono or stereo.

<P>See <A CLASS=TCTOP HREF="/directx/dxm/help/ds/dssd0089.htm#Video_Capabilities">Video Capabilities</A> for video-related examples relating to <A HREF="/directx/dxm/help/ds/dssd0108.htm#GetStreamCaps">IAMStreamConfig::GetStreamCaps</A>.

<P>Suppose you support pulse code modulation (PCM) wave format (as represented by the Microsoft&#174; Win32&#174; <A HREF="/directx/dxm/help/ds/dssd0404.htm#PCMWAVEFORMAT">PCMWAVEFORMAT</A> structure) at sampling rates of 11,025, 22,050, and 44,100 samples per second, all at 8- or 16-bit mono or stereo. In this case, you would offer two pairs of structures. The first pair would have an <A HREF="/directx/dxm/help/ds/dssd0298.htm#AUDIO_STREAM_CONFIG_CAPS">AUDIO_STREAM_CONFIG_CAPS</A> capability structure saying you support a minimum of 11,025 to a maximum of 22,050 samples per second with a granularity of 11,025 samples per second (granularity is the difference between supported values); an 8-bit minimum to a 16-bit maximum bits per sample with a granularity of 8 bits per sample; and one-channel minimum and two-channel maximum. The first pair's media type would be your default PCM format in that range, perhaps 22 kilohertz (kHz), 16-bit stereo. Your second pair would be a capability showing 44,100 for both minimum and maximum samples per second; 8-bit (minimum) and 16-bit (maximum) bits per sample, with a granularity of 8 bits per sample; and one-channel minimum and two-channel maximum. The media type would be your default 44 kHz format, perhaps 44 kHz 16-bit stereo.

<P>If you support non-PCM wave formats, the media type returned by this method can show which non-PCM formats you support (with a default sample rate, bit rate, and channels) and the capabilities structure accompanying that media type can describe which other sample rates, bit rates, and channels you support.


<A NAME="Reconnecting_your_Input"></A><P><B>Reconnecting Your Input to Ensure Specific Output Types</B>
<P>Filters implement the <A HREF="/directx/dxm/help/ds/dssd0108.htm#SetFormat">IAMStreamConfig::SetFormat</A> method to set the audio or video stream's format before pins are connected. Additionally, if your output pin is already connected and you can provide a new type, then reconnect your pin. If the other pin your filter is connected to can't accept the media type, fail this call and leave your connection alone. 

<P>Transform filters that do not know what output types their pins can provide should refuse any calls to <A HREF="/directx/dxm/help/ds/dssd0108.htm#SetFormat">IAMStreamConfig::SetFormat</A> and <A HREF="/directx/dxm/help/ds/dssd0108.htm#GetStreamCaps">IAMStreamConfig::GetStreamCaps</A> with the error code <A HREF="/directx/dxm/help/ds/dssd0308.htm#VFW_E_NOT_CONNECTED">VFW_E_NOT_CONNECTED</A> until their input pin is connected.

<P>If your pin knows what types it can provide even when your input is not connected, it is okay to offer and accept them as usual. See <A CLASS=TCTOP HREF="/directx/dxm/help/ds/dssd0083.htm">Connecting Transform Filters</A> for more information.

<P>In certain cases it is useful to reconnect pins when you are offering a format on an established connection. For example, if you can compress video into format X but only if you get 24-bit RGB input, and you can turn 8-bit RGB input into compressed format Y, you can either:
<OL><LI>Offer and accept both X and Y in <A HREF="/directx/dxm/help/ds/dssd0108.htm#GetStreamCaps">IAMStreamConfig::GetStreamCaps</A> and <A HREF="/directx/dxm/help/ds/dssd0108.htm#SetFormat">IAMStreamConfig::SetFormat</A> all the time, or, 
<LI>Only offer format X if your input is connected as 24, and only offer Y if your input is connected as 8. Fail both <A HREF="/directx/dxm/help/ds/dssd0108.htm#GetStreamCaps">IAMStreamConfig::GetStreamCaps</A> and <A HREF="/directx/dxm/help/ds/dssd0108.htm#SetFormat">IAMStreamConfig::SetFormat</A> if your input is not connected.
</OL>
<P>No matter which one you choose, you will need some reconnecting code that looks like this:
<PRE><FONT FACE="Courier" SIZE="2">
// Overridden to do fancy reconnecting footwork.
//
HRESULT MyOutputPin::CheckMediaType(const CMediaType *pmtOut)
{
    HRESULT hr;
    CMediaType *pmtEnum;
    BOOL fFound = FALSE;
    IEnumMediaTypes *pEnum;

    if (!m_pFilter-&gt;m_pInput-&gt;IsConnected()) {
       &#009;return VFW_E_NOT_CONNECTED;
    }

    // Quickly verify that the media type is not bogus here
    //
   
    // If somebody has previously called SetFormat, fail this call if the media type 
    // isn't an exact match.
   
       // Accept this output type like normal; nothing fancy required.
    hr = m_pFilter-&gt;CheckTransform(&amp;m_pFilter-&gt;m_pInput-&gt;CurrentMediaType(),
&#009;&#009;&#009;&#009;    pmtOut);
    if (hr == NOERROR)
&#009;return hr;

    DbgLog((LOG_TRACE,3,TEXT("Can't accept this output media type")));
    DbgLog((LOG_TRACE,3,TEXT(" But how about reconnecting our input...")));
    
    // Attempt to find an acceptable type by reconnecting our input pin.
    // The pin our input pin connects to might be able to provide a type
    // that our pin can convert into the necessary type.
    hr = m_pFilter-&gt;m_pInput-&gt;GetConnected()-&gt;EnumMediaTypes(&amp;pEnum);
    if (hr != NOERROR)
&#009;return E_FAIL;
    while (1) {
&#009;hr = pEnum-&gt;Next(1, (AM_MEDIA_TYPE **)&amp;pmtEnum, &amp;j);

&#009;// All out of enumerated types.
&#009;if (hr == S_FALSE || j == 0) {
&#009;    break;
&#009;}

&#009;// Can our pin convert between these?
&#009;hr = m_pFilter-&gt;CheckTransform(pmtEnum, pmtOut);

&#009;if (hr != NOERROR) {
&#009;    DeleteMediaType(pmtEnum);
&#009;    continue;
&#009;}

&#009;// OK, it offers an acceptable type, but will it accept it now?
&#009;hr = m_pFilter-&gt;m_pInput-&gt;GetConnected()-&gt;QueryAccept(pmtEnum);
&#009;// Nope.
&#009;if (hr != NOERROR) {
&#009;    DeleteMediaType(pmtEnum);
&#009;    continue;
&#009;}
&#009;// OK, I'm satisfied.
&#009;fFound = TRUE;
&#009;DbgLog((LOG_TRACE,2,TEXT("This output type is only acceptable after reconnecting our input.")));

&#009;// All done with this.
&#009;DeleteMediaType(pmtEnum);
&#009;break;
    }
    pEnum-&gt;Release();

    if (!fFound)
        DbgLog((LOG_TRACE,3,TEXT("*NO! Reconnecting our input won't help")));
&#009;
    return fFound ? NOERROR : VFW_E_INVALIDMEDIATYPE;
}



HRESULT MyOutputPin::SetFormat(AM_MEDIA_TYPE *pmt)
{
    HRESULT hr;
    LPWAVEFORMATEX lpwfx;
    DWORD dwSize;

    if (pmt == NULL)
&#009;return E_POINTER;


    // To make sure streaming isn't in the middle of starting/stopping:
    CAutoLock cObjectLock(&amp;m_pFilter-&gt;m_csFilter);

    if (m_pFilter-&gt;m_State != State_Stopped)
&#009;return VFW_E_NOT_STOPPED;

    // Possible output formats depend on the input format.
    if (!m_pFilter-&gt;m_pInput-&gt;IsConnected())
&#009;return VFW_E_NOT_CONNECTED;

    // Already using this format.
    if (IsConnected() &amp;&amp; CurrentMediaType() == *pmt)
&#009;return NOERROR;

    // See if this type is acceptable.
    if ((hr = CheckMediaType((CMediaType *)pmt)) != NOERROR) {
&#009;DbgLog((LOG_TRACE,2,TEXT("IAMStreamConfig::SetFormat rejected")));
&#009;return hr;
    }

    // If connecting to another filter, make sure they like it.
    if (IsConnected()) {
&#009;hr = GetConnected()-&gt;QueryAccept(pmt);
&#009;if (hr != NOERROR)
&#009;    return VFW_E_INVALIDMEDIATYPE;
    }

    // Now make a note that from now on, this is the only format allowed,
    // and refuse anything but this in the CheckMediaType code above.

    // Changing the format means reconnecting if necessary.
    if (IsConnected())
        m_pFilter-&gt;m_pGraph-&gt;Reconnect(this);

    return NOERROR;
}


// Overridden to complete our fancy reconnection footwork:
//
HRESULT MyWrapper::SetMediaType(PIN_DIRECTION direction,const CMediaType *pmt)
{
    HRESULT hr;

    // Set the OUTPUT type.
    if (direction == PINDIR_OUTPUT) {

&#009;// Uh oh.  As part of our fancy reconnection, our input pin might be asked to
&#009;// provide a media type it cannot provide without reconnection
&#009;// to a different type.
&#009;if (m_pInput &amp;&amp; m_pInput-&gt;IsConnected()) {

&#009;    // If our pin can actually provide this type now, don't worry.
    &#009;    hr = CheckTransform(&amp;m_pInput-&gt;CurrentMediaType(),
&#009;&#009;&#009;&#009;    &amp;m_pOutput-&gt;CurrentMediaType());
&#009;    if (hr == NOERROR)
&#009;&#009;return hr;
&#009;
            &#009;DbgLog((LOG_TRACE,2,TEXT("*Set OUTPUT requires RECONNECT of INPUT!")));

&#009;    // Reconnect our input pin. 
&#009;    return m_pGraph-&gt;Reconnect(m_pInput);

&#009;}

&#009;return NOERROR;
    }

    return NOERROR;
}
</FONT></PRE>
<P><P><FONT FACE="MS SANS SERIF" SIZE="1" COLOR="BLACK">
<A CLASS=cpslug HREF="../cpyright.htm" TARGET="_top">&#169; 1998 Microsoft Corporation. All rights reserved. Terms of Use.</A>
</FONT>
<BR CLEAR=ALL><P>
<FONT FACE="Verdana,Arial,Helvetica" SIZE="1"><A HREF="#pagetop"><IMG SRC="/directx/dxm/help/ds/art/yelbtn.gif" WIDTH="11" HEIGHT="11" ALIGN="MIDDLE" BORDER=0 ALT="*">Top of Page</A></FONT>
</BLOCKQUOTE><P>
</FONT><P>
</BODY></HTML>
