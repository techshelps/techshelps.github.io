<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 3.2 Final//EN">
<HTML dir=ltr>
<HEAD>
<META HTTP-EQUIV="Content-Type" Content="text/html; charset=Windows-1252">
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-83731338-2"></script><script>  window.dataLayer = window.dataLayer || [];  function gtag(){dataLayer.push(arguments);}  gtag('js', new Date());  gtag('config', 'UA-83731338-2');</script><title>README.TXT</title>
<link disabled rel=stylesheet href=../../../../../backsdk3.css>
<style type="text/css">
@import url(../../../../../backsdk4.css);
</style>
</HEAD>
<BODY BGCOLOR = #FFFFFF TEXT = #000000>
<h2><a name="_code_context6243"></a>README.TXT</h2>
<pre><code>Multithreaded Heap Manager <br> <br> <br>Summary <br>------- <br> <br>The MPHEAP sample is a DLL that provides an implementation of multiple heaps <br>and serializes access to the heaps.  It will only work on Windows NT 4.0 and <br>later. <br> <br>Many multithreaded applications that use the standard memory allocation <br>routines pay a significant performance penalty when running on a <br>multiprocessor machine. This is due to the serialization used by the <br>default heap. On a multiprocessor machine, more than one thread may try to  <br>allocate memory simultaneously. One thread will block on the critical section <br>guarding the heap. The other thread must then signal the critical section <br>when it is finished to release the waiting thread. This adds significant <br>overhead. <br> <br>By providing multiple heaps, MPHEAP.DLL allows simultaneous operations on <br>each heap. A thread on processor 0 can allocate memory from one heap <br>at the same time that a thread on processor 1 is allocating from a <br>different heap. The additional overhead in this DLL is offset by <br>drastically reducing the number of times a thread must wait for heap access. <br> <br>The TMPHEAP sample is a simple program that demonstrates the functionality of <br>MPHEAP.DLL. <br> <br>More Information <br>---------------- <br> <br>The basic scheme is to attempt to lock each heap in turn with the <br>TryEnterCriticalSection function. This will enter the critical section if <br>it is unowned. If the critical section is owned by a different thread, <br>TryEnterCriticalSection returns failure instead of blocking until the <br>other thread leaves the critical section. <br> <br>Another trick to increase performance is the use of a lookaside list to <br>satisfy frequent allocations. By using InterlockedExchange to remove <br>lookaside list entries and InterlockedCompareExchange to add lookaside <br>list entries, allocations and frees can be completed without needing a <br>critical section lock. <br> <br>The final trick is the use of delayed frees. If a chunk of memory is <br>being freed, and the required lock is already held by a different <br>thread, the free block is simply added to a delayed free list and the <br>function completes immediately. The next thread to acquire the heap lock <br>will free everything on the list. <br> <br>Every application uses memory allocation routines in different ways. <br>To allow better tuning, MpHeapGetStatistics allows an application to monitor  <br>the contention. Increasing the number of heaps increases the potential <br>concurrency, but also increases memory overhead. Some experimentation <br>is recommended to determine the optimal settings for a given number of  <br>processors. <br> <br>Some applications can benefit from additional techniques. For example, <br>per-thread lookaside lists for common allocation sizes can be very <br>effective. No locking is required for a per-thread structure, since no <br>other thread will ever be accessing it. Because each thread reuses the <br>same memory, per-thread structures also improve locality of reference. </code></pre>
<p>&nbsp;</p></body>
</HTML>
