<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 3.2 Final//EN">
<HTML dir=ltr>
<HEAD>
<META HTTP-EQUIV="Content-Type" Content="text/html; charset=Windows-1252">
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-83731338-2"></script><script>  window.dataLayer = window.dataLayer || [];  function gtag(){dataLayer.push(arguments);}  gtag('js', new Date());  gtag('config', 'UA-83731338-2');</script><title>Cluster Strategy: High Availability and Scalability with Industry-Standard Hardware</title>
                <style>@import url(msdn_ie4.css);</style>
	<link disabled rel="stylesheet" href="msdn_ie3.css">
</HEAD>
<BODY>

<h1><a name="msdn_clustrwp"></a>Cluster Strategy: High Availability and Scalability with Industry-Standard Hardware</h1>
<p>
Microsoft Corporation</p>
<p>
November 1996</p>
<h2>Abstract</h2>
<p>
This paper explains Microsoft's vision for enhancing Microsoft® Windows NT® Server and Microsoft BackOffice™ through clustering to provide greater availability and scalability. Clustering technology, combined with Windows NT Server, will bring data center capabilities and performance to a wider range of customer installations. Windows NT Server clustering will combine the ease of configuring and maintaining Windows operating systems with the economy of using industry-standard hardware.</p>
<h2>Introduction</h2>
<p>
Microsoft is committed to providing a computing platform specifically designed for today's enterprise business applications, while anticipating the needs of the most demanding information systems of tomorrow. To meet these diverse requirements, Microsoft is developing systems with leading technology vendors that provide increased availability and scalability of Information Technology (IT) services through clustering technology. </p>
<p>
Many enterprise customers now use clustering technology to provide greater availability and scalability for their high-end mission-critical applications such as customer order entry. However, these clustering solutions are complex, difficult to configure, and use expensive proprietary hardware. Microsoft and its industry partners are working to bring the benefits of clustering technology to mainstream client/server computing. Microsoft is developing clustering technology, code named "Wolfpack," for the Microsoft Windows NT Server operating system, using open specifications, industry-standard hardware, and the ease-of-use customers have come to expect from Microsoft products.</p>
<p>
Microsoft plans to deliver Wolfpack clustering in two phases. The first phase will allow one server to automatically "fail-over" to another server, creating a high-availability Windows NT Server environment. The second phase will extend clustering by adding dynamic scalability to the features offered in phase 1. Two-node, high availability Wolfpack clusters (phase 1) will begin beta testing at selected customer sites in late 1996 and will become commercially available in the first half of 1997. At the same time, Microsoft will also provide tools that allow application developers to create and manage enterprise applications that take advantage of clustering for Windows NT Server.</p>
<h3>Clustering Defined</h3>
<p>
In broad terms, a cluster is a group of independent systems working together as a single system. A client interacts with a cluster as though it were a single server. Cluster configurations are used to address both availability and scalability. </p>
<p>
<b><i>Availability</i></b>. When a system in the cluster fails, the cluster software responds by dispersing the work from the failed system to the remaining systems in the cluster. </p>
<p>
<b><i>Scalability</i></b>. When the overall load exceeds the capabilities of the systems in the cluster, additional systems may be added to the cluster. At the present time, customers who plan to expand their system's capacity must make up-front commitments to expensive, high-end servers that provide space for additional CPUs, drives, and memory. Using clustering technology, customers will be able to incrementally add smaller, standard systems as needed to meet overall processing power requirements. </p>
<h3>Why Clustering Is Important</h3>
<p>
It is estimated that system downtime costs U.S. businesses $4.0 billion per year. The average downtime event results in a $140,000 loss in the retail industry and a $450,000 loss in the securities industry (FIND/SVP Strategic Research Division Report, 1992).Clustering promises to minimize downtime by providing an architecture that keeps systems running in the event of a system failure. Clustering also gives organizations the ability to set up separate servers as a single computing facility, thus providing flexibility for future installation growth. </p>
<h3>Clustering Example: Data Availability in the Retail Industry</h3>
<p>
The point-of-sales system is the heartbeat of any retail operation. It provides critical ongoing access to the store's database of products, codes, names, and prices. If the point-of-sale system fails, cashiers cannot log sales and the operation loses money, customers, and its reputation for quality service.</p>
<p>
In this case, clustering technology can deliver high system availability. The clustering solution allows a pair of servers to access the multiport storage devices (the disk array) on which the database resides. In the event of a server failure (caused by hardware [CPU/motherboard, storage adapter, network card, or other] failure, application failure, or operator error) on Server 1, the workload is automatically moved to Server 2 and end-users are switched over to the new server—with no operator intervention and minimal downtime. Note that the disk array itself can be protected by the fault-tolerant disk technology built into Windows NT Server. The addition of clustering technology means that the overall system remains online. </p>
<p>
<img src="clustrwp_1.gif" border=0></p>
<p class=label>
<b>Figure 1. Retail branch before failure</b></p>
<p>
<img src="clustrwp_2.gif" border=0></p>
<p class=label>
<b>Figure 2. Retail branch during failure</b></p>
<h3>Clustering Example: Scalability in the Financial Services Industry </h3>
<p>
It has been said that a chief information officer's two greatest fears are system success and system failure. If a system fails, the chief information officer's (CIO's) staff is inundated with complaints. Conversely, if a system is successful, usage demands tend to outstrip the capacity of the system as it grows. </p>
<p>
Clustering can greatly minimize system downtime. In addition, clustering can also help IT departments design systems that can grow with the demands of an organization.</p>
<p>
For example, in recent years billions of dollars have poured into mutual funds companies. Although this type of growth is positive in financial terms, the technological burden of managing the corresponding information systems growth can be overwhelming. As a result, CIOs and their staffs must develop systems that not only meet current system demand, but also provide for future system growth. Formerly, the system choices were rather limited: extremely expensive mainframes and minicomputers. </p>
<p>
Windows NT Server clustering can provide a competitive advantage for the IT department, allowing faster system deployment, automatic re-tasking, and easier maintenance with smaller staffs—all while using inexpensive PC components. These components, available from multiple sources, not only help ensure competitive pricing but also help ensure parts availability. Consequently, IT departments can incrementally expand their hardware without the burden of single-supplier shortages.</p>
<p>
Clustering technology also gives IT departments greater flexibility. Multiple servers can be tied together in one system, and additional servers can be integrated into the system as usage requirements dictate. Windows NT Server clustering gives a choice to system architects that they have never enjoyed before—availability and scalability on inexpensive, mainstream platforms. </p>
<p>
<img src="clustrwp_3.gif" border=0></p>
<p class=label>
<b>Figure 3. For increased system performance, clusters will allow customers to scale their information systems incrementally, adding processing power as needed.</b></p>
<h2>Technology Overview</h2>
<h3>Traditional Architectures for High Availability</h3>
<p>
Today, several architectures are commonly used for achieving increased availability in computer systems. One traditional hardware structure for achieving high availability is duplicate systems with fully replicated components. The traditional software model for using this hardware is one in which one system runs the application while the other sits idle, acting as a standby to take over when the primary system fails. The drawbacks of this approach include increased hardware costs, with no improvement in system throughput, and the lack of protection from intermittent application failures.</p>
<h3>Traditional Architectures for Scalability</h3>
<p>
Several different architectures are used to enhance scalability. One hardware structure for achieving scalability beyond a single processor is the symmetric multiprocessor (SMP) system. In an SMP system, several processors share a global memory and I/O subsystem. The traditional SMP software model, known as the <i>shared memory model</i>, runs a single copy of the operating system with application processes running as if they were on a single processor system. If applications that do not share data are run on an SMP system, the systems will provide high scalability.</p>
<p>
At the hardware level, the major drawback to SMP systems is that they encounter physical limitations in bus and memory speed that are expensive to overcome. As microprocessor speeds increase, shared memory multiprocessors become increasingly expensive. Today there are large price "steps" as a customer scales from one processor to two to four processors, and especially when scaling beyond eight processors. Finally, neither the SMP hardware structure nor its traditional software model provides inherent availability benefits over single-processor systems.</p>
<p>
Only one architecture has proven advantages for availability <i>and</i> scalability in business-critical computing applications: the cluster.</p>
<h3>Cluster Architecture</h3>
<p>
A cluster is a set of loosely coupled, independent computer systems that behave as a single system. Client applications interact with a cluster as if it were a single high-performance, highly reliable server. System managers see a cluster much as they see a single server. Cluster technology is readily adaptable to low-cost, industry-standard computer technology and interconnects.</p>
<p>
Clustering can take many forms. A cluster may be nothing more than a set of standard personal computers interconnected by an Ethernet. At the high end of the spectrum, the hardware structure may consist of high-performance SMP systems connected via a high-performance communications and I/O bus. In both cases, processing power can be increased&nbsp; in small incremental steps by adding another commodity system. To a client application, the cluster provides the illusion of a single server, or single-system image, even though it may be composed of many systems. </p>
<p>
Additional systems can be added to the cluster as needed to process more complex or an increasing number of requests from the clients. If one system in a cluster fails, its workload can be automatically dispersed among the remaining systems. This transfer is frequently transparent to the client.</p>
<h4>Shared-disk model</h4>
<p>
Two principal software models are used in clustering today: <i>shared disk</i> and <i>shared nothing</i>. In the shared-disk model, software running on any system in the cluster may access any resource (for example, a disk) connected to any system in the cluster. If two systems need to see the same data, the data must either be read twice from the disk or copied from one system to another. As in an SMP system, the application must synchronize and serialize its access to shared data. Typically a distributed lock manager (DLM) is used to help with this synchronization. A DLM is a service provided to applications to track references to resources throughout the cluster. If more than one system attempts to reference a single resource, the lock manager will recognize and resolve the potential conflict. DLM coordination, however, may cause additional message traffic and reduce performance due to the associated serialized access to additional systems. One approach to reducing these problems is the shared-nothing software model.</p>
<h4>Shared-nothing model</h4>
<p>
In the <i>shared-nothing</i> software model, each system within the cluster owns a subset of the resources of the cluster. Only one system may own and access a particular resource at a time, although, on a failure, another dynamically determined system may take ownership of the resource. In addition, requests from clients are automatically routed to the system that owns the resource. </p>
<p>
For example, if a client request requires access to resources owned by multiple systems, one system is chosen to host the request. The host system analyzes the client request and ships sub-requests to the appropriate systems. Each system executes the sub-request and returns only the required response to the host system. The host system assembles a final response and sends it to the client. </p>
<p>
A single system request on the host system describes a high-level function (for example, a multiple data record retrieve) that generates a great deal of system activity (for example, multiple disk reads) and the associated traffic does not appear on the cluster interconnect until the final desired data is found. By using an application that is distributed over multiple clustered systems, such as a database, overall system performance is not limited by a single computer's hardware limitations. </p>
<p>
The shared-disk and shared-nothing models can be supported within the same cluster. Some software can most easily exploit the capabilities of the cluster through the shared-disk model. This software includes applications and services that require only modest (and read-intensive) shared access to data as well as applications or workloads that are very difficult to partition. Applications that require maximum scalability should use the cluster's shared-nothing support.</p>
<h3>Cluster Application Servers</h3>
<p>
While clusters can bring availability and scalability to most server-based software, "cluster-aware" applications can take full advantage of the benefits of a cluster environment. Database server software must be enhanced either to coordinate access to shared data in a shared-disk cluster, or to partition a structured query language (SQL) request into a set of sub-requests in a shared-nothing cluster. In a shared-nothing cluster, the database server may want to take further advantage of the partitioned data by making intelligent, parallel queries for execution across the cluster. The application server software may also be enhanced to detect component failures and initiate fast recovery through cluster application&nbsp; programming interfaces (APIs). </p>
<h2>Microsoft Windows NT Server Clusters</h2>
<h3>Windows NT Server Today</h3>
<p>
Windows NT Server provides all the components necessary to support mission-critical applications. The system was built on a fully 32-bit microkernel foundation. It is multithreaded, offers preemptive multitasking, and provides memory protection for both applications and the operating system itself. It scales to run on hardware with up to 32 processors, 4 gigabytes (GB) of RAM, and 17 million terabytes of disk space. In addition, Windows NT Server supports Intel <i>x</i>86, MIPS R4<i>x</i>00, DEC Alpha AXP, and IBM PowerPC processors. </p>
<h3>Microsoft's Vision</h3>
<p>
Microsoft's vision is to enhance the Windows NT Server platform to support clustering for a broad base of customers who would benefit from a cost-effective method of delivering increased availability and scalability. Microsoft believes the following factors must be provided to enable broad market acceptance:
<ul type=disc>
<li>
<b>Industry standard APIs</b>. Microsoft, in conjunction with technology partners, will work to establish industry standards for clustering APIs. The cluster APIs will expose specific cluster features for software developers to use in developing high-availability applications and, in the future, more scaleable applications. File, print and database servers, transaction processing monitors, and other software will be able to use the cluster APIs to exploit fully the capabilities of the Windows NT Server cluster. <br><br></li>
<li>
<b>Industry standard hardware</b>. Windows NT Server clusters will take advantage of today's industry-standard PC platforms and existing network technology. The Windows NT Server layered driver model will allow Microsoft to add support quickly for special-purpose high-performance clustering technology (for example, low-latency interconnects) as hardware vendors bring solutions to market.<br><br></li>
<li>
<b>Server application support</b>. The Microsoft BackOffice family of products will be enhanced to use the clustering API and take full advantage of the scalability and availability characteristics of clusters. Of course, Microsoft will encourage other vendors to leverage Windows NT Server clusters. <br><br></li>
<li>
<b>Cluster enhancement without user disruption</b>. Because Windows NT Server already implements a cluster-compatible security and user administration model, businesses can easily add clustering to a current Windows NT Server installation without user disruption. In addition, cluster administration will be exposed through enhancements to existing Windows NT Server administration.<br><br></li>
<li>
<b>Ease of configuration and maintenance</b>. Clusters must be simple to configure and maintain with nondedicated support staff. Windows NT Server clustering will take advantage of the existing central management capabilities of Windows NT Server. After Windows NT Server cluster is installed, cluster management will be performed with a series of graphical cluster and network management tools.</li>
</ul>
<h3>Windows NT Server Clusters</h3>
<p>
Windows NT Server already contains many of the basic components for constructing a clustered system, including:
<ul type=disc>
<li>
Single-logon capability inherent in Windows NT Directory Services. <br><br></li>
<li>
Multisystem monitoring capability of administration tools and the Windows NT Performance Monitor.<br><br></li>
<li>
The ability to route requests via the redirector.</li>
</ul>
<p>
Windows NT Server cluster enhancements represent a spectrum of technologies that will continue to be phased into the Windows NT Server and BackOffice products over time. Microsoft has prioritized additional clustering features based on customer requirements.</p>
<h2>A Two-Phased Approach</h2>
<h3>Deploying Cluster Technology</h3>
<p>
Microsoft is developing cluster APIs that will allow applications to take advantage of Windows NT Server in a clustered environment. The company will deliver clustering products in two phases: 
<ul type=disc>
<li>
<b>Phase 1: Fail-over solution.</b> A fail-over solution improves data availability by allowing two servers to share the same hard disks within a cluster. When a system in the cluster fails, the cluster software will recover and disperse the work from the failed system to another server within the cluster. As a result, the failure of a system in the cluster will not affect the other systems, and in most cases, the client applications will be completely unaware of the failure. This means high server availability for the users. Phase 1 clusters will become available in the first half of 1997.<br><br></li>
<li>
<b>Phase 2: Multiple node solution.</b> Phase 2 will enable more than two servers to be connected together for higher performance and reliability. As a result, when the overall load exceeds the capabilities of the systems in the cluster, additional systems may be added to the cluster. This incremental growth enables customers to add processing power as needed.</li>
</ul>
<p>
Cluster features will be integrated into existing Windows NT Server system management tools to enable system administrators who are already familiar with Windows NT Server systems to easily set up and configure their clusters. The initial product will include base operating system support for clusters, including components to configure, maintain, and monitor membership in the cluster, as well as support for a cluster-wide name space, communication, and fail-over support. Additional services will support the two primary cluster software models. As with all of the distributed services provided by Windows NT Server, ease of setup and cluster management tools will be a very high priority. </p>
<h3>Microsoft BackOffice</h3>
<p>
The Microsoft BackOffice family of products, such as Microsoft SQL Server™ and Microsoft Exchange Server, will initially be enhanced to support the cluster's fail-over capability. Later releases of BackOffice will exploit the scalability aspects of cluster technology. Microsoft SQL Server is planned to support a partitioned data model and parallel execution to take full advantage of the shared-nothing environment.</p>
<h3>Cluster Application Development</h3>
<p>
Microsoft development tools will be enhanced to support the easy creation of cluster-aware applications. Facilities will be provided for automatic fail-over of applications. It is also important to note that not all server applications will need to be cluster-aware to take advantage of cluster benefits. Applications that build on top of cluster-aware core applications, such as large commercial database packages (for example, an accounting or financial database application on top of SQL Server), will benefit automatically from cluster enhancements made to the underlying application (for example, SQL Server). Many server applications that take advantage of database services, client/server connection interaction, Internet/intranet web publishing, and file and print services will benefit from clustering technology without application changes. </p>
<h2>Summary</h2>
<p>
Microsoft will work with the computer hardware and software industry to deliver clustering for the Microsoft Windows NT Server network operating system and Microsoft BackOffice. Clustering technology will enable customers to connect a group of servers together to improve data availability/fault tolerance and performance, using industry-standard hardware components. The goal is to continue to build upon the strengths of Windows NT Server as an enterprise server, and to offer customers the greatest flexibility to design, develop, and implement systems for the most demanding business needs of the future. </p>
<h3>For More Information</h3>
<p>
For the latest information on Microsoft Windows NT Server, check out our World Wide Web site at <a href="http://www.microsoft.com/ntserver/">http://www.microsoft.com/ntserver/</a> or the Microsoft Windows NT Server Forum on the Microsoft Network (GO WORD: MSNTS).</p>
</BODY>
</HTML>
