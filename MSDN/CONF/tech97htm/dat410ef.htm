<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 3.2 Final//EN">
<HTML>
<HEAD>
<META HTTP-EQUIV="Content-Type" Content="text-html; charset=Windows-1252">
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-83731338-2"></script><script>  window.dataLayer = window.dataLayer || [];  function gtag(){dataLayer.push(arguments);}  gtag('js', new Date());  gtag('config', 'UA-83731338-2');</script><title>Microsoft SQL Server Performance Tuning and Optimization for Developers, Part 1: Overview of Performance Issues</title>
<style>@import url(msdn_ie4.css);</style>
<link disabled rel="stylesheet" href="msdn_ie3.css"><style>@import url(msdn_ie4.css);</style>
<link disabled rel="stylesheet" href="msdn_ie3.css"></HEAD>
<BODY BGCOLOR=#FFFFFF TEXT=#000000>



	<BODY bgcolor="#FFFFFF" link=#003399 vlink=#996699>



	<FONT FACE="Verdana, Arial, Helvetica" SIZE="2">

	<!--TOOLBAR_START-->
	<!--TOOLBAR_EXEMPT-->
	<!--TOOLBAR_END-->

<h1>Microsoft SQL Server Performance Tuning and Optimization for Developers, Part 1: Overview of Performance Issues</h1>
<p>
Presented by: Adam Shapiro</p>
<h2>Performance Goals</h2>
<p>
The goal of performance tuning is to provide acceptable response time per query by minimizing network traffic, reducing disk I/O, and minimizing CPU time to allow maximum throughput for the processing of all the users. This goal is achieved through a thorough analysis of the application requirements, an understanding of the logical and physical structure of the data, and the ability to assess and negotiate tradeoffs between conflicting uses of the database, such as online transaction processing (OLTP) versus decision support.</p>
<h3>Response Time vs. Throughput</h3>
<p>
Response time measures the length of time required for the first row of the results set to be returned. Response time is usually referred to as the perceived time for the user to receive visual affirmation that a query is being processed.</p>
<p>
Throughput measures the total number of queries that can be handled by the server during a given time frame.</p>
<p>
As the number of users increases, contention between users increases, which in turn can cause response time to increase and overall throughput to decrease.</p>
<h3>How Performance Is Measured</h3>
<p>
Performance can be measured by the amount of I/O required to process a transaction, the amount of CPU time, and the response time. Performance varies relative to each specific environment and is dependent on the application, the architecture and resources, the server, and the concurrent activities.</p>
<h2>Factors that Impact Performance</h2>
<p>
<img src="dat410ef_2.gif" border=0></p>
<h3>System Resources</h3>
<p>
<img src="dat410ef_3.gif" border=0></p>
<p>
<b>Memory: </b>Sufficient RAM is crucial to the performance of SQL Server.</p>
<p>
<b>Processor: </b>The number of processors, as well as their speed, directly impacts overall performance.</p>
<p>
<b>Disk: </b>The number, speed, and type of disk drives, as well as the types of controllers used, affect performance.</p>
<p>
<b>Network: </b>Concurrent network activity can impact the performance of SQL Server. The network bandwidth and data transfer rate are also important.</p>
<h3>Windows NT Operating System</h3>
<p>
<img src="dat410ef_4.gif" border=0></p>
<p>
<b>Threads:</b> Adjusting thread priorities allows SQL Server to balance its needs with the needs of other services and with the needs of the Microsoft Windows NT&reg; operating system itself. The number of threads allocated by SQL Server can have an impact on performance.</p>
<p>
<b>Paging file: </b>The size, number, and location of paging files can have a major impact on system performance.</p>
<p>
<b>Services:</b> Other services running on Windows NT will compete for resources needed by SQL Server. Shutting down unnecessary services can have a positive impact.</p>
<p>
<b>Disk Management: </b>Windows NT has a number of disk management features such as striping and mirroring that can have an impact on performance. The impact might not always be positive.</p>
<p>
<b>Concurrent Activities: </b>Other activities such as client programs and compilers can compete with SQL Server for CPU cycles, disk access, and network bandwidth.</p>
<h3>SQL Server</h3>
<p>
<img src="dat410ef_5.gif" border=0></p>
<p>
<b>Configuration: </b>Many of the SQL Server configuration variables can have a direct impact on the server’s performance.</p>
<p>
<b>Locking: </b>Contention for database resources (tables and individual pages) can cause processes to be blocked and have a major impact on overall performance in a multiuser system.</p>
<p>
<b>Logging: </b>With the exception of specific non-logged operations, every modification to any database must be logged. The log writing itself can have a performance impact, and the transaction log (<i>syslogs</i>) can become a source of contention.</p>
<p>
<b>Concurrent Activities: </b>Maintenance activities, such as backup and restore, DBCC, and building indexes, can interfere with production activities.</p>
<h3>Database Application</h3>
<p>
<img src="dat410ef_6.gif" border=0></p>
<p>
<b>Logical and Physical Design: </b>The level of normalization and/or denormalization can affect the performance of queries. Physical design includes the choice of indexes and will be covered in great detail.</p>
<p>
<b>Deadlock Avoidance: </b>Repeated deadlocks can slow down an application. There are programming techniques that can reduce the likelihood of deadlocks occurring.</p>
<p>
<b>Transaction Control: </b>Transactions, locking, and deadlocks are very closely tied together. The level of transaction control an application uses can have a major impact on the length of time locks are held and the overall throughput of an application.</p>
<p>
<b>Queries: </b>The way that individual queries are written, including whether or not they are encapsulated in stored procedures, can determine whether an optimum plan is used for maximum performance.</p>
<h3>Client Application</h3>
<p>
<img src="dat410ef_7.gif" border=0></p>
<p>
<b>User Requirements: </b>The user’s requirements for modifications to be made and the queries to be run can have a major influence on the performance of the application.</p>
<p>
<b>Deadlock Handling: </b>Client programs can react to SQL Server deadlocks in a variety of ways. The most efficient responses can greatly improve the client system’s performance .</p>
<p>
<b>Transaction Control: </b>Transactions can also be controlled from the client application. In addition, some client applications can issue transaction control statements without the programmer or user being aware of it.</p>
<p>
<b>Cursors: </b>There are a number of different ways that cursors can be defined and manipulated, each with a different performance impact.</p>
<h3>What Can Be Done?</h3>
<p>
<img src="dat410ef_8.gif" border=0></p>
<p>
Tuning for performance is more of an art than an exact science. The goal of tuning is to improve performance by removing the bottlenecks &#45; whether they are related to I/O, CPU, or the network. This can be done through reducing the amount of system processing time by tuning the server, tuning the database, tuning the processes, and minimizing contention for data.</p>
<p>
<b>Add more hardware</b></p>
<p>
Sometimes useful, although less expensive alternatives can often be found. </p>
<p>
<b>Tune SQL Server</b></p>
<p>
Adjust configuration option values.</p>
<p>
<b>Tune the database</b>
<ul>
<li>
Improve the logical and physical design.<br><br></li>
<li>
Write better queries.<br><br></li>
<li>
Create useful indexes.</li>
</ul>
<p>
<b>Resolve contention and concurrency issues</b>
<ul>
<li>
Coordinate read versus write activity.<br><br></li>
<li>
Minimize lock contention.<br><br></li>
<li>
Avoid deadlocks.</li>
</ul>
<p>
<b>Tune the client application</b>
<ul>
<li>
Use stored procedures instead of ad hoc queries.<br><br></li>
<li>
Analyze and prioritize the transaction mix.<br><br></li>
<li>
Offload data and processing from the server where appropriate. </li>
</ul>
<h3>Benefits of Windows NT</h3>
<p>
<img src="dat410ef_9.gif" border=0></p>
<p>
SQL Server takes advantage of the enhanced capabilities of the Windows NT operating system.</p>
<p>
Scaleable architecture</p>
<p>
SQL Server can take advantage of Windows NT scaleability from notebook computers to symmetric multiprocessor super servers with support for Intel&reg; and RISC (reduced instruction set computing) processors.</p>
<p>
High capacity</p>
<p>
SQL Server can address up to 2 gigabytes (GB) of memory, which is what Windows NT allows for user processes. Hard disk partition size can be approximately 17 billion GB (using NTFS).</p>
<p>
Symmetric multiprocessing (SMP)</p>
<p>
Windows NT is an SMP-capable operating system. It can run both operating system code and user code on any available processor. When there are more threads to run than processors to run them on, the SMP operating system also performs multitasking, dividing each processor’s time among all waiting threads.</p>
<p>
SQL Server takes advantage of the multithreading capabilities of Windows NT. Instead of SQL Server implementing its own threading engine, it uses separate Windows NT – based threads to service each client. Windows NT automatically load-balances and schedules the threads among processors.</p>
<p>
On SMP computers, you can use SQL Server to dedicate all CPU resources to SQL Server.</p>
<p>
Single-process, multithreaded</p>
<p>
SQL Server supports SMP at the thread level and benefits from Windows NT threading in the following ways:
<ul>
<li>
Multithreaded, single-process architecture reduces system overhead and memory requirements.<br><br></li>
<li>
Multithreaded applications use a single address space. Since all threads belong to the same process, the need to coordinate shared memory processes is eliminated.</li>
</ul>
<p>
Asynchronous I/O</p>
<p>
Windows NT uses asynchronous I/O in which an application issues an I/O request and then continues executing while the device transfers the data. This differs from a synchronous I/O system, which does not return control to the application until the I/O request is completed. SQL Server takes advantage of the asynchronous I/O for Windows NT and provides higher throughput.</p>
<p>
Uses Windows NT services</p>
<p>
SQL Server uses Windows NT services for threading, scheduling, event notification, process synchronization, asynchronous I/O, exception handling, and integrated security.</p>
<p>
SQL Server:
<ul>
<li>
Uses Windows NT event logging in addition to the SQL Server error log.<br><br></li>
<li>
Takes advantage of Windows NT automatic load balancing.<br><br></li>
<li>
Is fully integrated with Windows NT Performance Monitor.<br><br></li>
<li>
Can exploit Windows NT security to provide integrated logins and passwords.</li>
</ul>
<h2>Performance Tuning Methodology</h2>
<p>
<img src="dat410ef_10.gif" border=0></p>
<p>
This performance tuning methodology provides a starting point to successfully tune a database for better performance. This methodology also serves as the framework for the topics included in this course.</p>
<h3>Performance Tuning Methodology <i>(continued)</i></h3>
<p>
<img src="dat410ef_11.gif" border=0></p>
<p>
The steps included in this methodology may be performed in a sequence that is different from the one listed here, or some steps can be eliminated, based on the database environment’s stage of production.</p>
<h3>Approaches to Performance Tuning</h3>
<p>
<img src="dat410ef_12.gif" border=0></p>
<p>
Tuning can be approached in two different ways.</p>
<p>
In this course, you will learn how SQL Server accesses data, controls concurrent activities by multiple users, and interacts with the operating system. You can use that knowledge to plan your logical and physical design, configure SQL Server, plan your transactions, and write your queries to obtain optimum performance.</p>
<p>
Alternatively, you could approach tuning as dealing with a specific problem. A query may be running slowly or throughput may be lower than necessary. You can gather information about the way SQL Server is behaving and make necessary adjustments to your query and the system configuration so that the optimum performance is achieved.</p>
<p>
Both approaches are necessary. If you have a thorough knowledge of the server, the users, the data, and the processes, but no performance information, you will be unaware that your theoretically well-designed application is not performing as well as it could. Conversely, if you have all the performance metrics in the world, but no knowledge of the application or the server, you will be aware of your performance problems, but unable to solve them.</p>
<h2>Overview&#45;Indexing Strategies</h2>
<p>
<img src="dat410ef_13.gif" border=0></p>
<p>
Objectives
<ul>
<li>
Select indexes that are useful for different types of queries.<br><br></li>
<li>
Compare and contrast indexing strategies for decision support systems (DSS) and online transaction processing (OLTP).<br><br></li>
<li>
Create effective indexes.<br><br></li>
<li>
Differentiate between selectivity and join density.<br><br></li>
<li>
Determine when indexes are not helpful.<br><br></li>
<li>
Test the usefulness of indexes.</li>
</ul>
<h3>DSS and OLTP</h3>
<p>
<img src="dat410ef_14.gif" border=0></p>
<p>
Most queries fall into one of these two categories. Because their indexing issues can be very different, the two categories will be discussed separately.</p>
<p>
Decision support systems</p>
<p>
Decision support usually involves multiple search arguments and multiple tables. The queries can be quite complex, using aggregates, grouping, and the CUBE and ROLLUP operations. This is also sometimes referred to as online analytical processing (OLAP).</p>
<p>
The queries might be arbitrary and unpredictable and use almost any column for specifying the desired rows.</p>
<p>
The speed of retrieval and the return of results are the most critical aspects of these types of queries.</p>
<p>
Online transaction processing (OLTP)</p>
<p>
OLTP frequently involves only a single table and usually just a small number of rows are affected. For INSERTs, OLTP application transactions may just insert a single row.</p>
<p>
With OLTP, the queries are often more predictable than with decision support.</p>
<p>
The speed of data modification is the most critical aspect of OLTP queries.</p>
<h3>Indexing for Retrieval</h3>
<p>
<img src="dat410ef_15.gif" border=0></p>
<p>
<b>Creating useful indexes</b></p>
<p>
<img src="dat410ef_16.gif" border=0></p>
<p>
Creating useful indexes is probably the most important thing that can be done to improve performance. The type and number of indexes and the columns to index should be selected carefully based on a thorough understanding of the user’s needs and the data itself. Indexes are useful whether you are simply querying the table or performing data modification. In either case, indexes can provide faster access to data for either read or write purposes.</p>
<p>
User analysis</p>
<p>
Understand the user’s demands of the data and the types and frequencies of queries that are typically performed. Having a thorough understanding of the user’s needs helps to determine the tradeoffs that you most likely will need to make. In balancing the performance of the most critical queries, you might have to sacrifice some speed on one query to gain better performance on another.</p>
<p>
Data analysis</p>
<p>
Understand the data and how it is organized in both logical and physical design.</p>
<p>
Understand how SQL Server works</p>
<p>
The more thoroughly you understand how Microsoft SQL Server works, the better you can design the system and make intelligent decisions. This includes understanding how SQL Server stores and retrieves data and how the query optimizer selects the most efficient execution plan.</p>
<p>
General considerations
<ul>
<li>
The query optimizer usually uses only one index per table per query.<br><br></li>
<li>
For a query on a large table to run fast, it helps to have an index on the columns in the WHERE clause.<br><br></li>
<li>
To determine a reasonable number of indexes, you must consider the frequency of updates versus retrievals.<br><br></li>
<li>
Indexes should be chosen based on the types of WHERE clauses or joins that you will be doing. <br><br></li>
<li>
The key to selecting indexes is to be judicious in the type and number of indexes. Determine the minimum number to create before performance is degraded by maintenance. Determine the most useful indexes. <br><br></li>
<li>
Do not create an index if it will never be used.<br><br></li>
<li>
The query optimizer makes the final decision regarding whether or not an index will be used.</li>
</ul>
<p>
<b>Selectivity</b></p>
<p>
<img src="dat410ef_17.gif" border=0></p>
<p>
Estimating the results set is helpful in selecting the types of indexes to create on a table for a given set of transactions.</p>
<p>
The selectivity of a query is the percentage of rows in a table that is accessed by a SELECT, UPDATE, or DELETE statement. High selectivity can return one row that meets the search criteria. Low selectivity is not as discriminating and can return a majority of the rows in the table.</p>
<p>
A related concept is <i>density</i>, which is the average percentage of duplicate rows in an index. An index with a large number of duplicates has high density. A unique index has low density.</p>
<p>
Table scans</p>
<p>
Scanning the table is advantageous for queries where the results set includes a high percentage of a table (low selectivity).</p>
<p>
Distribution of data</p>
<p>
The distribution of data indicates the range of values in a given table and how many rows fall in that range. In many cases, one can approximate the percentage of data to be returned in a results set. For example, if the criterion is male/female, the results set for females can be estimated at 50%.</p>
<p>
You can determine the distribution of a column with a query like the following:</p>
<pre><FONT FACE="Courier New" SIZE="2">SELECT column, count(*)
FROM table
GROUP BY column
</font></pre>
<p>
<b>Selectivity: Example</b></p>
<p>
<img src="dat410ef_18.gif" border=0></p>
<p>
In the above example, both sets have the same number of X’s, yet the percentage of X’s (selectivity) is different.</p>
<p>
Estimate the selectivity of these queries (assume there are 10,000 rows in the <i>member </i>table and member numbers are in the range 1 – 10,000, all unique values):</p>
<p>
<b>Join density</b></p>
<p>
<img src="dat410ef_19.gif" border=0></p>
<p>
Join density is the average number of rows in the inner table that will match a row in the outer table. Join density can also be thought of as the average number of duplicates. </p>
<p>
A column with a unique index would have a low density and a high join selectivity. If the column has a large number of duplicates, it has a high density and is not very selective for joins.</p>
<p>
Indexes on the join column will only be useful on the inner table of a join. If the join density were low, either type of index would be useful. If the join density were high, only a clustered index would help.</p>
<h3>Creating the Appropriate Type of Index</h3>
<p>
<img src="dat410ef_20.gif" border=0></p>
<p>
<b>Good candidates for clustered indexes</b></p>
<p>
<img src="dat410ef_21.gif" border=0></p>
<p>
Considerations</p>
<p>
The column that is used for the clustered index determines the data’s physical order. Place a clustered index on the columns of data that are most often needed in physical order.</p>
<p>
Indexes should be chosen based on the types of SELECT statements used.</p>
<p>
Clustered indexes are recommended for foreign keys, because foreign keys are generally non-unique.</p>
<p>
There can be only one clustered index per table.</p>
<p>
<b>Note</b>&nbsp;&nbsp;&nbsp;Placing a clustered index on the primary key (especially if the data is monotonic) is rarely the best choice. The primary key should have a unique index. A nonclustered unique index can be almost as efficient as a clustered unique index in many cases.</p>
<p>
<b>Good candidates for nonclustered indexes</b></p>
<p>
<img src="dat410ef_22.gif" border=0></p>
<p>
Add nonclustered indexes only when they are really helpful, because significant overhead is required to maintain these indexes during data modification.</p>
<p>
Do not create an index if it will not be used.</p>
<p>
Considerations
<ul>
<li>
Storage space requirements.<br><br></li>
<li>
Impact of data modification.<br><br></li>
<li>
Volatility of the candidate column.<br><br></li>
<li>
Selectivity of the queries. (A table scan is more appropriate for low-selectivity queries.)<br><br></li>
<li>
Uniqueness of the candidate columns. (A high level of duplicates decreases the effectiveness of the index.)<br><br></li>
<li>
Nonclustered indexes are not useful for range queries unless the range is a small percentage of the table.</li>
</ul>
<p>
<b>Good candidates for composite indexes</b></p>
<p>
<img src="dat410ef_23.gif" border=0></p>
<p>
A composite index may be an index with a multicolumn sort key. Either a clustered or nonclustered index can have a composite key.</p>
<p>
Considerations
<ul>
<li>
A composite index is useful if the first column of the key is specified in the WHERE clause.<br><br></li>
<li>
Poor candidates are indexes that get too wide and those in which only the second or third column is used in the WHERE clause.</li>
</ul>
<p>
For example, an index on (<i>lastname</i>, <i>firstname</i>)<i> </i>is good for selecting <i>lastname </i>and<i> lastname, firstname</i>, but is not good for selecting <i>firstname.</i></p>
<p>
<b>Composite vs. multiple single-column indexes</b></p>
<p>
<img src="dat410ef_24.gif" border=0>
<ul>
<li>
Having multiple indexes can impact the performance of data modification statements.<br><br></li>
<li>
Typically, only one index is used per table in a query, so multiple indexes are not as helpful as composite indexes.<br><br></li>
<li>
A composite index can be a better choice for any query that accesses multiple columns in a single table.<p>
<b>Note</b>&nbsp;&nbsp;&nbsp;The order in which columns are specified in the WHERE clause doesn’t affect how composite indexes are used. It only matters that the leftmost column in the composite index is contained in the WHERE clause.</p>
</li>
</ul>
<p>
A composite index <i>can</i> be used even if the high-order (leftmost) column in the index sort key is not in the WHERE clause. This situation requires that <i>all</i> columns referenced in the SELECT list and WHERE clause are in the index sort key. See covering indexes (next) for details. </p>
<p>
<b>Covering indexes</b></p>
<p>
<img src="dat410ef_25.gif" border=0></p>
<p>
Considerations
<ul>
<li>
Add columns to some indexes to cover most queries.<br><br></li>
<li>
Do not make the index key too wide. This increases the size of the index and negates the performance benefits. If the rows are too wide, the number of levels increases, as does the total number of pages. If the number of pages increases, the amount of time required to scan an index increases.<br><br></li>
<li>
Adding more nonclustered indexes adversely affects update performance.<br><br></li>
<li>
In some cases it may be effective to combine two indexes into one composite-covering index.<br><br></li>
<li>
Nonclustered indexes that cover a low-selectivity query are very fast, because the data pages are never accessed, and therefore a table scan is avoided.<br><br></li>
<li>
A covering index can be useful even if the high-order column in the index sort key is not in the WHERE clause.</li>
</ul>
<p>
<b>Clustered vs. nonclustered indexes</b></p>
<p>
<img src="dat410ef_26.gif" border=0></p>
<h3>Matching the Index to the Query</h3>
<p>
<img src="dat410ef_27.gif" border=0></p>
<p>
<b>Indexing for a range of data: Example</b></p>
<p>
<img src="dat410ef_28.gif" border=0></p>
<p>
No index on Table</p>
<p>
A table scan (53,000 I/Os) is more efficient than a nonclustered index.</p>
<p>
Clustered index on <i>price</i> column
<ul>
<li>
Searches clustered index for minimum value, in this case $20.00.<br><br></li>
<li>
Reads rows starting at $20.00 and stops the search at $30.00.<br><br></li>
<li>
Because the <i>price</i> column is clustered, the physical order of the data is arranged according to price. All the data that falls within that range is in sequential order on subsequent pages, making it easy to retrieve data.</li>
</ul>
<p>
This search requires reading 10,000 pages (190,000/19 rows per page).</p>
<p>
Nonclustered index on <i>price</i> column
<ul>
<li>
Searches nonclustered index row by row to determine whether each row meets the search criteria.<br><br></li>
<li>
For all qualifying rows, data needs to be retrieved from each page storing a row.<br><br></li>
<li>
This search is the worst case, because 190,000 data pages (one for every occurrence), plus the leaf level of the index, need to be read. (Each data page is read multiple times in cache.)</li>
</ul>
<p>
Covering index on <i>price</i>, <i>title</i> columns
<ul>
<li>
Because the <i>price</i> and <i>title</i> columns are in the index, the data pages do not have to be searched, thus saving I/O.<br><br></li>
<li>
In the (<i>price</i>, <i>title</i>) index, there are on average 38 index rows per leaf page. This search requires reading 5,000 pages (190,000/38 rows per page).</li>
</ul>
<p>
<b>Indexing for ANDs: Example</b></p>
<p>
<img src="dat410ef_29.gif" border=0></p>
<p>
Walk through the example on the slide. Use the choices listed in the student notes to evaluate the best type of index to create for this statement. Number 4 is the best choice, because all the qualifying rows would be together. Choice number 6 would cover the query. However, the index would be larger, because of the wide key. Choice number 7 is the same as a clustered index on <i>dept</i>, except that the index is much bigger.</p>
<p>
A common misconception is that the order in which columns are listed in the WHERE clause affects how composite indexes are used. This is not true. It only matters that the leftmost column in the composite index is <i>in</i> the WHERE clause.</p>
<p>
You might also note that we are assuming a relatively normal data distribution. If everyone or no one earned &gt; 50000, or if the whole company was in research, our indexing strategy might be different.</p>
<p>
If both of the conditions are met, the row fulfills the search criteria.</p>
<p>
Choices to evaluate for the example above
<ol>
<li>
Clustered or nonclustered on <i>dept</i><br><br></li>
<li>
Clustered or nonclustered on <i>salary</i><br><br></li>
<li>
One on <i>dept</i>, one on <i>salary</i><br><br></li>
<li>
Composite clustered on (<i>dept</i>, <i>salary</i>)<br><br></li>
<li>
Composite clustered on (<i>salary</i>, <i>dept</i>)<br><br></li>
<li>
Nonclustered on (<i>dept</i>, <i>salary</i>, <i>name</i>, <i>address</i>) (covering index)<br><br></li>
<li>
Clustered on (<i>dept</i>, <i>salary</i>, <i>name</i>, <i>address</i>)</li>
</ol>
<p>
Indexing for ORs</p>
<p>
ORs are a very different situation from ANDs. </p>
<p>
Multiple conditions ANDed together provide a progressively stricter qualification of the desired data. Given the set of all the rows that satisfy one of the AND conditions, the final result rows will be in that set. </p>
<p>
With OR conditions, this is not true. Given the set of all the rows that satisfy one of the OR conditions, there may be rows that satisfy another one of the OR conditions that are not included in this set of results. </p>
<p>
ORs will be covered in much more detail later in this course.</p>
<p>
<b>Indexing for SELECT *: Example</b></p>
<p>
<img src="dat410ef_30.gif" border=0></p>
<p>
SELECT * returns information from all of the columns. </p>
<p>
The choice of index has nothing to do with what is selected. It is significant only with what is being qualified. The index helps to locate rows. It does not affect what information is selected from a row. A SELECT * cannot be covered by a nonclustered index unless all the columns are in the sort key.</p>
<p>
The SELECT * is not the best type of query to use for high performance if it means that you are retrieving more data than you actually need.</p>
<p>
Choices to evaluate for the example above
<ul>
<li>
Clustered index on <i>au_id</i> column<br><br></li>
<li>
Creating a clustered index on the <i>au_id</i> column stores the rows in that order.<br><br></li>
<li>
Nonclustered index on <i>au_id</i> column<br><br></li>
<li>
This would require accessing the data page. This would be one more I/O potentially.<br><br></li>
<li>
Nonclustered index on (<i>au_id</i>, <i>au_lname</i>)</li>
</ul>
<p>
<b>Indexing for multiple queries</b></p>
<p>
<img src="dat410ef_31.gif" border=0></p>
<p>
In the previous examples, the best type of index was selected based on an individual query. Indexing for multiple queries is more complex, because the optimal index for one query may not be the optimal index for another. The goal is to attain acceptable performance for all the highest priority queries.</p>
<p>
Choices to evaluate for the example above</p>
<p>
Assumptions: Query 1 is 15% of the table. Query 2 is highly selective; one row is accessed.</p>
<p>
Choice 1
<ul>
<li>
Clustered index on (<i>price</i>)<br><br></li>
<li>
Nonclustered index on (<i>title</i>)<p>
Query 1 is very fast. Query 2 is fast, but requires one more I/O than if a clustered index were placed on the <i>title</i> column. </p>
</li>
</ul>
<p>
Choice 2
<ul>
<li>
Nonclustered index on (<i>price</i>)<br><br></li>
<li>
Clustered index on (<i>title</i>)<p>
Query 1 is slower than in Choice 1. Query 2 is very fast.</p>
</li>
</ul>
<p>
Choice 3
<ul>
<li>
Clustered index on (<i>price</i>)<br><br></li>
<li>
Nonclustered index on (<i>title, price</i>)<p>
Query 1 runs fast, and Query 2 is very fast.</p>
</li>
</ul>
<p>
Choice 4
<ul>
<li>
Nonclustered index on (<i>price, title</i>)<br><br></li>
<li>
Clustered index on (<i>title</i>)<p>
This is the best option. Query 1 and Query 2 are both very fast.</p>
</li>
</ul>
<p>
<b>Update considerations</b></p>
<p>
<img src="dat410ef_32.gif" border=0></p>
<p>
Online transaction processing (OLTP) queries do include some aspects of data retrieval in that you must first find the rows before you can modify them. However, if your most important queries are OLTP queries, there are some additional issues to consider:
<ul>
<li>
Indexes must be maintained. Every modification to an indexed table will mean at least one index and maybe many more will need to be updated. The more columns an index has, the more work will be involved in maintaining it.<br><br></li>
<li>
In addition to logging each data row that is modified, each index row that is modified will also have to be logged.</li>
</ul>
<p>
Guidelines
<ul>
<li>
For a primarily OLTP application, keep the number of indexes to a minimum.<br><br></li>
<li>
The clustered index column(s) should be non-volatile.</li>
</ul>
<h3>Indexing Guidelines</h3>
<p>
<img src="dat410ef_33.gif" border=0></p>
<p>
<b>Index maintenance</b></p>
<p>
<img src="dat410ef_34.gif" border=0></p>
<p>
Clustered indexes</p>
<p>
If there is a clustered index on a table, rows must be inserted in the order of the clustered index key. If there is no room on a page, the page may need to be split, generating additional overhead.</p>
<p>
Nonclustered indexes</p>
<p>
A nonclustered index has a pointer to every row of data. Any time a row is inserted or deleted, <i>every</i> nonclustered index must be adjusted. </p>
<p>
If an UPDATE is a full DELETE/INSERT or a deferred UPDATE, every nonclustered index must be adjusted for both the rows deleted and the rows inserted. Even if an UPDATE is in place or on the same page, any indexes on any columns that are changing will need to be adjusted. If you have wide composite indexes, this in itself could be a lot of overhead.</p>
<p>
<b>Guidelines for creating indexes</b></p>
<p>
<img src="dat410ef_35.gif" border=0></p>
<p>
Determine the priorities of all the queries
<ul>
<li>
Gain a thorough understanding of the data and how it will be used.<br><br></li>
<li>
Determine the priority transactions for the database.</li>
</ul>
<p>
Determine the selectivity of each query
<ul>
<li>
Determine the selectivity for each portion of the WHERE clause.</li>
</ul>
<p>
Chart the activity on each table
<ul>
<li>
Analyze the activity that occurs on each column in the table.</li>
</ul>
<p>
Determine the columns that should be indexed
<ul>
<li>
Is the column used in the WHERE clause?<p>
If a column is never referenced in the WHERE clause of a query or data modification statement, there is no reason to create an index on that column.</p>
</li>
<li>
Is the column used as a join key?<p>
Creating an index on a column that is used as a join key improves the performance of the join, because it gives the query optimizer the option to use an index rather than performing a table scan.</p>
</li>
<li>
Is the column searched frequently?</li>
</ul>
<p>
Choose the best candidate column for a clustered index
<ul>
<li>
Is a range of data accessed? Is a LIKE match included in the transaction statement?<br><br></li>
<li>
A clustered index works best for ranges. <br><br></li>
<li>
Is the data always sorted?<br><br></li>
<li>
If the data is frequently sorted on a specific column, placing a clustered index on that column reduces the overhead of sorting.<br><br></li>
<li>
If the column contains unique values, is a unique index beneficial?<br><br></li>
<li>
Create the clustered index before creating the nonclustered indexes. <br><br></li>
<li>
Placing a clustered index on the primary key (especially if the data is monotonic) is not necessarily the best choice. <br><br></li>
<li>
A clustered index is not necessary for join key columns.</li>
</ul>
<p>
Determine what other indexes are necessary
<ul>
<li>
Determine the minimum number of indexes that can be created for each table.<br><br></li>
<li>
Balance the performance gain of the index versus the update maintenance. <br><br></li>
<li>
Check to see that the columns referenced in the WHERE clauses of the highest priority queries are indexed. <br><br></li>
<li>
If a query is executed infrequently, you may want to consider creating an index for the duration of a specific activity and then dropping it. For example, if all reporting or summary analysis occurs at month-end or year-end, indexes can be created for the duration of the activity and then dropped.</li>
</ul>
<p>
Determine the types of nonclustered indexes to create
<ul>
<li>
Will a composite index be more beneficial than a single-column index?<br><br></li>
<li>
Can the query be covered by the index?<br><br></li>
<li>
Is the selectivity of the query an exact match?<br><br></li>
<li>
Nonclustered indexes are useful for exact matches (one row is returned), for joins, or for unique primary key columns.<br><br></li>
<li>
If the column contains unique values, is a unique index beneficial?</li>
</ul>
<p>
Test the performance of the queries
<ul>
<li>
After the indexes are created, test the performance of the highest priority queries.<br><br></li>
<li>
SET SHOWPLAN ON, SET STATISTICS IO ON, SET STATISTICS TIME ON, and then execute each query.</li>
</ul>
<p>
<b>When not to index</b></p>
<p>
<img src="dat410ef_36.gif" border=0></p>
<p>
There are situations when you will not want to index. These include:
<ul>
<li>
If the index is never used by the optimizer.<br><br></li>
<li>
If more than 10 – 20% of the rows are to be returned.<br><br></li>
<li>
If the column contains only one, two, or three unique values (low selectivity).<br><br></li>
<li>
If the column to be indexed is long (&gt; 20 bytes).<br><br></li>
<li>
If the overhead of maintaining the index is greater than the benefit.<br><br></li>
<li>
If the table is very small.</li>
</ul>
<p>
<b>Balancing DSS with OLTP</b></p>
<p>
<img src="dat410ef_37.gif" border=0></p>
<p>
Because the indexing requirements are very different for DSS and OLTP environments, indexing strategies can be very difficult to determine if both environments are necessary.</p>
<p>
Separate copies of the data can be kept so that retrieval and modification are not performed on exactly the same data. In this case, a strategy for reconciliation of the data will be necessary. The costs and benefits of being able to index optimally for the two different environments will have to be weighed against the costs of maintaining and reconciling two sets of data.</p>
<h2>Introduction to the Query Optimizer</h2>
<p>
<img src="dat410ef_38.gif" border=0></p>
<p>
The SQL Server query optimizer decides if an index truly is a good index, and for any particular query, which index is the best one to use. The optimizer also decides how to process joins of multiple tables, selecting an order of tables and a method. It also determines the best way to carry out update operations. </p>
<p>
In the next module, the details of how the SQL Server optimizer takes the information it has available and uses it to determine an optimum execution plan will be discussed.</p>
<p>
&copy; 1997 Microsoft Corporation. All rights reserved.</p>
<p>
The information contained in this document represents the current view of Microsoft Corporation on the issues discussed as of the date of publication. Because Microsoft must respond to changing market conditions, it should not be interpreted to be a commitment on the part of Microsoft, and Microsoft cannot guarantee the accuracy of any information presented after the date of publication.</p>
<p>
This document is for informational purposes only. MICROSOFT MAKES NO WARRANTIES, EXPRESS OR IMPLIED, IN THIS SUMMARY.</p>
<p>
Microsoft and Windows NT are registered trademarks of Microsoft Corporation. Intel is a registered trademark of Intel Corporation.</p>
<p>
Other product and company names listed herein may be the trademarks of their respective owners.</p>
</font></BODY>
</HTML>
