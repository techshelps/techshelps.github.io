<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 3.2 Final//EN">
<HTML dir=ltr>
<HEAD>
<META HTTP-EQUIV="Content-Type" Content="text/html; charset=Windows-1252">
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-83731338-2"></script><script>  window.dataLayer = window.dataLayer || [];  function gtag(){dataLayer.push(arguments);}  gtag('js', new Date());  gtag('config', 'UA-83731338-2');</script><title>Calling the Optimal Version of a DLL Function</title>
<style>@import url(stylesheets/msdn_ie4.css);</style>
<link disabled rel="stylesheet" href="stylesheets/msdn_ie3.css"></HEAD>
<BODY>

<h1><a name="vjconcallingoptimalversionofdllfunction"></a>Calling the Optimal Version of a DLL Function</h1>
<p>
Unfortunately, neither calling the ANSI version or the Unicode version of a DLL function is an ideal way to invoke the Win32 functions. Using the default ANSI mode allows your code to run on any Win32 platform, but causes unnecessary performance penalties on fully Unicode systems such as Microsoft Windows NT. Using the <i>unicode</i> modifier removes the performance penalty but restricts you to running on systems that implement the Unicode API. Fortunately, you can use the <i>auto</i> modifier with the @dll.import directive to call the optimal version of a DLL function based on the host operating system. </p>
<p>
Using the <i>auto</i> modifier gives you the best of both worlds. The following example shows how to call the optimal version of the MessageBox function:</p>
<pre><code>/** @dll.import("USER32",auto) */
  static native int MessageBox(int hwnd, String text, String title, 
 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; int style);
</code></pre>
<p>
When the <i>auto</i> modifier is present, the Microsoft VM determines at run time whether the underlying platform supports the Unicode APIs. If Unicode is supported, the VM acts as if the <i>unicode</i> modifier had been specified. Otherwise, the VM behaves as if the <i>ansi</i> modifier had been specified. Thus, the <i>auto</i> modifier allows you to generate a single binary which runs well on both ANSI and Unicode Windows systems using the optimal API set available on the given platform. </p>
<p>
In general, the <i>auto</i> modifier should be used whenever you call Windows API functions. If you are calling your own DLLs, select either <i>ansi</i> (the default) or <i>unicode</i> depending on your needs. </p>
<p>
The following list provides details of how the VM decides whether to use ANSI or Unicode when you use the <i>auto</i> modifier:
<ol>
<li>
The VM opens the registry key HKEY_LOCAL_MACHINE\Software\Microsoft\Java VM and looks for the DWORD-named value DllImportDefaultType. This value can be one of the following:<p class=tl>
2 – ANSI: Uses the ANSI version always.</P><p class=tl>
3 – Unicode: Uses the UNICODE version always.</P><p class=tl>
4 – Platform: Uses ANSI or Unicode depending on the platform.</P></li>
<li>
If the key does not exist, or if it is set to 4 (indicating platform), the VM calls the Win32 GetVersion function and examines the high bit to determine whether the underlying platform is Microsoft Windows 95 or Microsoft Windows NT. If the platform is Windows 95, ANSI mode is used. Otherwise, Unicode mode is used.</li>
</ol>
<p>
It is not necessary to set the DllImportDefaultType registry key yourself. It exists primarily so that the installation program can set the appropriate choice on future Windows platforms. You can programmatically query the preferred mode on your platform by reading the com.ms.dll.DllLib.systemDefaultCharSize field. This field will be set to 1 on ANSI systems, 2 on Unicode systems.</p>
<p>
The <i>ansi</i>, <i>unicode</i>, and <i>auto</i> modifiers can also be used with the @dll.struct directive.</p>
</BODY>
</HTML>
