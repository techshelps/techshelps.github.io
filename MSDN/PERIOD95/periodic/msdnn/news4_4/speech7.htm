<!DOCTYPE HTML PUBLIC "-//IETF//DTD HTML//EN">
<html>

<head>
<meta http-equiv="Content-Type"
content="text/html; charset=iso-8859-1">
<meta name="Template" content="C:\WINWORD\TEMPLATE\MSIN60B.DOT">
<meta name="GENERATOR" content="Microsoft FrontPage 2.0">
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-83731338-2"></script><script>  window.dataLayer = window.dataLayer || [];  function gtag(){dataLayer.push(arguments);}  gtag('js', new Date());  gtag('config', 'UA-83731338-2');</script><title>Look What’s Talking: SDK to Enable Speech in Apps for Windows 95 and Windows NT</title>

<meta name=href content="msdn_ie4.css">                
<style>@import url(msdn_ie4.css);</style>
<link disabled rel="stylesheet" href="msdn_ie3.css"></HEAD><basefont face="verdana,arial,helvetica" color="#000000" size=2>

<BODY bgcolor="#FFFFFF">
<font face="verdana,arial,helvetica" size="2">

<blockquote>
    <p><font size="5"><b>Look What's Talking: SDK to Enable
    Speech in Apps for Windows 95 and Windows NT</b></font></p>
    <p><font size="2">Mike Rozak and Jerry Drain</font></p>
    <p><font size="2">July 13, 1995</font></p>
    <p><font size="2">Computers that talk have always been a
    fascinating element of science fiction. Verbal communication
    makes computers appear smarter, and thus seems to go
    hand-in-hand with artificial intelligence.</font></p>
    <p><font size="2">But speech is no longer simply the stuff of
    science fiction. Not only is speech now available <i>without</i>
    special hardware and software, but it is coming to the
    Windows platform&#151;and will very shortly be easy to
    implement into your Win32-based applications.</font></p>
    <p><font size="2">Microsoft is working with independent
    software vendors (ISVs) who provide speech engines, and by
    the end of 1995 will release a Speech software development
    kit (SDK). The Speech SDK will provide a set of APIs that
    will allow developers to enable speech functionality in their
    applications for the Windows 95 and Windows NT operating
    systems. With all of this coming down the pike, now is a good
    time to look at how speech might apply to your application.</font></p>
    <p><font size="3"><b>Speak to me</b></font></p>
    <p><font size="2">Speech should provide a more powerful and
    intuitive method for interacting with a system than today's
    mice, keyboards, touch pads, pens, or other devices. Two
    parts of speech make an application interactive:
    text-to-speech and speech recognition.</font></p>
    <p><font size="2">While these technologies are still limited,
    they can solve a number of different user-interface problems
    encountered by applications.</font></p>
    <p><font size="3"><b>Text-to-speech</b></font></p>
    <p><font size="2">Text-to-speech synthesizes speech from ANSI
    or Unicode text, allowing a Windows-based PC to talk to a
    user. This has obvious advantages: The system can give you
    information any time you wish&#151;whether or not you are
    looking at it. It is beneficial to the vision-impaired, when
    you are multitasking and may be too busy to look at the
    screen, or when the screen is off. It's also convenient: The
    computer can notify you audibly of noncritical
    events&#151;&quot;Printing has completed&quot;&#151;instead
    of providing a pop-up that you have to dismiss by clicking
    the OK button.</font></p>
    <p><font size="2">Text-to-speech is also useful with dynamic
    text. A good example of this is providing the time of day. In
    this case, storing all the possible concatenations of numbers
    to tell the time in a .WAV file would be incredibly
    expensive.</font></p>
    <p><font size="2">Text-to-speech has other advantages as
    well:</font></p>
    <p><font size="2"><b>Storage:</b> Data in a text format takes
    up far less storage than even compressed .WAV files.</font></p>
    <p><font size="2"><b>Speaking unknown text:</b> If the
    application needs to play speech but doesn't know ahead of
    time what it will be (such as the user's name), or if it's
    impossible to record all of the combinations (such as
    numbers), then the application must use text-to-speech.</font></p>
    <p><font size="2"><b>Data verification or grammar checking:</b>
    When the information is read back, a user can easily hear
    typing mistakes in numbers, names, and words. Likewise, the
    eye is used to glossing over misspellings and short words.
    Grammatical mistakes become more obvious if the text is read
    back.</font></p>
    <p><font size="2"><b>Notification:</b> Some applications have
    to notify the user of asynchronous events. Rather than
    bringing up the message box and making it active (which can
    interfere with typing), an application can have
    text-to-speech read the notification. The message box can
    still be instantiated without being activated, just in case
    the user doesn't hear the notification.</font></p>
    <p><font size="2"><b>Word pronunciation:</b> Although
    text-to-speech doesn't sound great, it's understandable.
    Rather than writing a word pronunciation in text (for
    example: &quot;knowledge&quot; = &quot;now-lej&quot;), just
    have the computer speak it.</font></p>
    <p><font size="2"><b>Access over the telephone:</b> With the
    arrival of voice modems in more and more PCs, applications
    will start providing &quot;phone-based&quot; UIs. For
    example, a user can call up the computer, which then allows
    him to look up his schedule, address book, and so on, all
    over the phone.</font></p>
    <p><font size="2"><b>Long-distance notification:</b>
    Text-to-speech can be heard in other rooms of the house. For
    example, a phone application can look at Caller ID when a
    call comes in and speak out, &quot;You have a phone call from
    Fred Smith.&quot;</font></p>
    <p><font size="3"><b>Speech recognition</b></font></p>
    <p><font size="2">Speech recognition enables users to speak
    to a computer, freeing them from keyboards and mice and
    helping to streamline the interactive process. For example,
    saying &quot;Yes,&quot; &quot;No,&quot; &quot;Cancel,&quot;
    or &quot;Send mail to Fred&quot; is often easier or faster
    than using the mouse to click the buttons. In a more
    complicated example, it's much easier to say &quot;Print the
    current page&quot; than to navigate menus and dialog boxes.</font></p>
    <p><font size="2">Current speech recognition technology can
    be divided into two categories:</font></p>
    <blockquote>
        <p><font size="2">&#149; Command and control: The user
        can speak one command from a list of several hundred
        commands. A command can include &quot;lists&quot; or
        numbers, such as &quot;Send mail to &lt;name&gt;&quot; or
        &quot;Set the time to &lt;time&gt;.&quot; Unfortunately,
        the user must speak the command exactly as written.
        He/she cannot say, &quot;Change the time to
        &lt;time&gt;.&quot;</font></p>
        <p><font size="2">&#149; Dictation: The computer
        transcribes whatever the user says. To work on ordinary
        machines, most dictation systems require the speaker to
        pause between words.</font></p>
    </blockquote>
    <p><font size="2">An application can use speech recognition
    to remedy a range of UI limitations:</font></p>
    <p><font size="2"><b>Fast access to complex features:</b> A
    number of applications have frequently used features that are
    difficult to present or control with a GUI. Often these
    features can be more easily accessed by speech recognition.</font></p>
    <p><font size="2"><b>Magic keystrokes:</b> A lot of
    applications have overloaded the keyboard with not only text
    entry features but also commands. Voice commands can make
    life easier for a user because they are easier to memorize.
    Speech can also be used to activate macros, avoiding the need
    to come up with and memorize magic keystrokes.</font></p>
    <p><font size="2"><b>Global commands:</b> Speech can be used
    when an application wants to have an input hook that is
    always active, even when that application doesn't have
    keyboard focus. If the application uses a keyboard hook, it's
    likely that another application is already using the chosen
    key, causing conflicts. For example, this allows a user to
    make a phone call even when the phone isn't the active
    application.</font></p>
    <p><font size="2"><b>Form entry:</b> Applications can use
    speech recognition for form entry, both for selecting
    elements from a list and for entering numbers. Because speech
    can have so many commands active at once, it can be listening
    for all possible values for all the fields at once, and can
    place data in the proper field.</font></p>
    <p><font size="2"><b>Access over the telephone:</b> With the
    arrival of voice modems in more and more PCs, applications
    will start providing &quot;phone-based&quot; UIs. Speech
    recognition is a much better interface than maneuvering
    through menus with touch-tones.</font></p>
    <p><font size="2"><b>Accessibility:</b> Speech recognition
    aids people who are poor typists or who cannot use the
    keyboard or mouse effectively.</font></p>
    <p><font size="2"><b>Mouse overload:</b> Some applications
    (especially CAD systems) drag, drop, and select objects with
    the mouse. For more complex actions, a user either has to
    memorize a magic keystroke (which may not have the
    information bandwidth) or move the mouse to a menu or
    toolbar. Instead, the user could just say, &quot;Rotate this
    sixty-two degrees.&quot; Speech is also useful when a
    keyboard or mouse is not available or if a user's hands are
    busy.</font></p>
    <p><font size="2"><b>Multiple people in front of machine:</b>
    Speech recognition is good when several people are using the
    same application on a single computer.</font></p>
    <p><font size="3"><b>Limitations to speech</b></font></p>
    <p><font size="2">Although speech is a maturing technology,
    there are a number of scenarios in which speech technology is
    not appropriate.</font></p>
    <p><font size="2">Most speech recognition systems break down
    when they have to recognize more than 100 commands. Selecting
    from large lists of words or commands imposes fast lookup and
    comparisons with words or commands that begin to sound
    similar. Menus and dialog boxes work well with this
    limitation but long lists, such as thousands of e-mail names,
    don't.</font></p>
    <p><font size="2">Speech recognition also has a tough time
    with spelling because so many letters (for example, M and N)
    sound alike. Additionally, entering long sequences of letters
    or numbers can produce a higher error rate. The command
    &quot;Call five seven nine eight&quot; might end up being
    &quot;Call nine seven nine eight.&quot;</font></p>
    <p><font size="2">Here are a few other disadvantages:</font></p>
    <blockquote>
        <p><font size="2">&#149; Pointing devices: Repeating
        directions such as &quot;up, up, up, left, left, up, up,
        up&quot; can get annoying very quickly.</font></p>
        <p><font size="2">&#149; Games or multimedia: Although
        speech can enhance a game or interactive multimedia, it
        is difficult to do quickly on top of filtering out
        background noise, such as music or game sounds, from the
        application itself.</font></p>
        <p><font size="2">&#149; Listening to long passages: Long
        passages of text-to-speech are hard to listen to.
        Synthetic voice can be particularly irritating in long
        passages. Pre-recorded voice always sounds better and
        more natural than mechanical text-to-speech. So, if
        storage is not an issue, recorded voice can be more
        appealing in many scenarios. Still, try not to read long
        passages of text, especially of a recurring message, and
        without a cancel of some sort.</font></p>
    </blockquote>
    <p><font size="3"><b>What it takes to make speech work</b></font></p>
    <p><font size="2">Three converging technologies make speech
    on Windows possible. Speech used to require specialized
    hardware capable of signal processing in real time. But with
    ever-faster CPUs, this is no longer the case.</font></p>
    <p><font size="2">The second is the emergence of PCs with
    audio. Most new PCs come with audio hardware built in. Speech
    can now use this high-volume hardware rather than costly
    specialized and custom hardware.</font></p>
    <p><font size="2">The third is easy accessibility to speech
    technology. The Microsoft Speech API is designed to do that,
    giving developers a standard programming interface that
    provides consistent access to speech technology. By using the
    API, you enable your application for speech technology.</font></p>
    <p><font size="2">In addition to the Speech API, you'll need
    either Windows 95 or Windows NT 3.5 (or 3.51) and a speech
    engine. Speech engines are available through third-party
    vendors, and often come bundled with sound cards or
    audio-enabled PCs. Microsoft has its own speech recognition
    engine that it's working on.</font></p>
    <p><font size="2">The Speech API provides an interface
    between your applications and speech engines. (The industry
    often refers to the application vendors as speech client
    writers.) Microsoft is working with engine writers to enable
    their engines to work with the Speech API standard. This will
    allow client writers to make their applications
    speech-enabled and give their users total freedom to choose
    the speech engine writer they need. For example, a user may
    choose one engine because it has much higher accuracy,
    trading off speaker independence because it doesn't need it.</font></p>
    <p><font size="3"><b>The role of the Component Object Model</b></font></p>
    <p><font size="2">Windows speech technology is part of the
    Windows Open Systems Architecture (WOSA). All of the Speech
    APIs are accessed through the OLE Component Object Model, and
    they derive significant benefits from an object-oriented
    approach.</font></p>
    <p><font size="2">The API also provides access on two levels.
    The higher level is relatively easy to use and provides quick
    implementation for simple commands. For developers who need
    more flexibility for operations such as dictation, the lower
    level essentially permits an application to talk directly to
    the speech engine. This is more difficult, but more powerful
    and flexible.</font></p>
    <p><font size="2">For more information:</font></p>
    <blockquote>
        <p><font size="2">&#149; Look for more articles on speech
        in future releases of the Microsoft Development Library.</font></p>
        <p><font size="2">&#149; Send e-mail to
        MSSpeech@microsoft.com.</font></p>
        <p><font size="2">&#149; Visit the Speech API section on
        the WinEXT forum on CompuServe.</font></p>
        <p><font size="2">&#149; To apply for the beta, download
        the application form from the library on WinEXT and send
        it to MSSpeech@microsoft.com. The next beta release
        should be in the third quarter of 1995.</font></p>
        <p><font size="2">&#149; Look for the Speech SDK,
        scheduled to be available in the fourth quarter of 1995.</font></p>
        <p><font size="2">&#149; Contact speech engine vendors
        directly.</font></p>
    </blockquote>
    <p><font size="2"><i>Jerry Drain is a member of Microsoft's
    Developer Relations Group, where he works with ISVs on
    Windows NT and Windows 95.</i></font></p>
    <p><font size="2"><i>Mike Rozak is a member of the Personal
    Systems Division, where he is working on the Microsoft Speech
    API.</i></font></p>
    <p><font size="5"><b>Hardware Speak</b></font></p>
    <p><font size="2">Here is the type of hardware needed for
    speech:</font></p>
    <blockquote>
        <p><font size="2">&#149; <b>CPU speed:</b> The typical
        speech engine requires a 486DX/33 or faster, although the
        requirement can range anywhere from a 386/16 to a 486/66
        for discrete dictation, or to a RISC for continuous
        dictation.</font></p>
        <p><font size="2">&#149; <b>RAM:</b> Again, the amount
        needed depends on the objective. For simple command and
        control execution, an application will need about 1
        megabyte (MB) of RAM above its normal requirement.
        Something as complex as dictation, however, can require
        an additional 8 MB of RAM.</font></p>
        <p><font size="2">&#149; <b>Audio input and output:</b> A
        sound card and either speakers or headphones are needed.
        Almost any sound card will do, including Sound Blaster,
        Media Vision, ESS, and Windows Sound System-compatible
        cards, and audio built into multimedia PCs<i>.</i> A few
        speech recognition engines still require specialized DSP
        cards.</font></p>
        <p><font size="2">&#149; <b>Microphone:</b> Two types
        come to mind. Headsets with close-to-mouth microphones
        have their advantages, allowing users to speak more
        quietly and reducing interference from background noise.
        The cord, however, is a disadvantage (hey, somebody come
        out with an infrared version, okay?). The alternative is
        medium-distance microphones that often sit near the
        monitor or CPU.</font></p>
    </blockquote>
</blockquote>
</font></body>
</html>
