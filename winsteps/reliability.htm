<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
<head>
   <title>Reliability and separation of measures
   </title>
   <meta name="generator" content="Help &amp; Manual">
   <meta name="keywords" content="Winsteps, Rasch Measurement, Rasch Analysis, 1-PL, 1PL">
   <meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
   <meta http-equiv="Content-Style-Type" content="text/css">
   <link type="text/css" href="default.css" rel="stylesheet">
<script type= "text/javascript">   
var min=10;
var max=300;
function increaseFontSize() {
   var p = document.getElementsByTagName('p');
   for(i=0;i<p.length;i++) {
      if(p[i].style.fontSize) {
         var s = parseInt(p[i].style.fontSize.replace("%",""));
      } else {
         var s = 100;
      }
      if(s<max) {
         s += 10;
      }
      p[i].style.fontSize = s+"%"
   }
}
function decreaseFontSize() {
   var p = document.getElementsByTagName('p');
   for(i=0;i<p.length;i++) {
      if(p[i].style.fontSize) {
         var s = parseInt(p[i].style.fontSize.replace("%",""));
      } else {
         var s = 100;
      }
      if(s>min) {
         s -= 10;
      }
      p[i].style.fontSize = s+"%"
   }   
}


</script>
<style type="text/css" media="print">
.printbutton {
  visibility: hidden;
  display: none;
}
</style>   

<script type="text/javascript" src="helpman_topicinit.js"></script>
</head>

<body style="margin: 0px 0px 0px 0px; background: #FFFFFF;">




<table width="100%" border="0" cellspacing="0" cellpadding="5" bgcolor="#FFFFFF">
  <tr valign="middle">
    <td align="left">
      <p class="p_Heading1"><span class="f_Heading1">Reliability and separation of measures</span></p>

    </td>
    <td align="right">
     <a href="controlindex.htm">Top</a>&nbsp;<a href="rectangularcopying.htm">Up</a>&nbsp;<a href="rules.htm">Down</a>&nbsp;
     <a href="javascript:decreaseFontSize();"><font size="-2"><b>A</b></font></a>&nbsp;<a href="javascript:increaseFontSize();"><font size="+2"><b>A</b></font></a><br>
<script  type= "text/javascript">
document.write("<input type='button' " +
"onClick='window.print()' " +
"class='printbutton' " +
"STYLE='background-color:00BFFF' " +
"value='Print This Page'>");
</script>
     

    </td>
  </tr>
</table>




<!-- Placeholder for topic body. -->
<div style="padding: 10px 10px 10px 5px; width: 100%;"> 
<p><span style="font-weight: bold;">Reliability (separation index) means &quot;reproducibility of relative measure location&quot;.</span> It does not report on the quality of the data. So &quot;high reliability&quot; (of persons or items) means that there is a high probability that persons (or items) estimated with high measures actually do have higher measures than persons (or items) estimated with low measures. If you want high reliability, you need a wide sample and/or low measurement error. So, if you want high person (test) reliability, you need a person sample with a large ability (or whatever) range and/or an instrument with many items (or long rating scales). If you want high item reliability, you need a test with a large item difficulty range and/or a large sample of persons. Usually low item reliability is because the person sample size is too small to establish a reproducible item difficulty hierarchy.</p>
<p>&nbsp;</p>
<p>Missing data: if some persons have missing observations, these can considerably reduce precision, and so lower reliability estimates. &nbsp;Suggestion: omit person-records with missing data when estimating reliabilities.</p>
<p>&nbsp;</p>
<p><span style="font-weight: bold;">Person (sample, test) reliability</span> depends chiefly on</p>
<p>1) Sample ability variance. Wider ability range = higher person reliability.</p>
<p>2) Length of test (and rating scale length). Longer test = higher person reliability</p>
<p>3) Number of categories per item. More categories = higher person reliability </p>
<p>4) Sample-item targeting. Better targeting = higher person reliability</p>
<p>It is independent of sample size. It is largely uninfluenced by model fit.</p>
<p>&nbsp;</p>
<p><span style="font-weight: bold;">Item reliability</span> depends chiefly on</p>
<p>1) Item difficulty variance. Wide difficulty range = high item reliability</p>
<p>2) Person sample size. Large sample = high item reliability</p>
<p>It is independent of test length. It is largely uninfluenced by model fit.</p>
<p>&nbsp;</p>
<p><span style="font-weight: bold;">Tentative guidelines:</span></p>
<p><span style="font-weight: bold;">Person reliability:</span> Does your test discriminate the sample into enough levels for your purpose? 0.9 = 3 or 4 levels. 0.8 = 2 or 3 levels. 0.5 = 1 or 2 levels.</p>
<p><span style="font-weight: bold;">Item reliability:</span> Low reliability means that your sample is not big enough to precisely locate the items on the latent variable.</p>
<p><span style="font-weight: bold;">Rater reliability:</span> Low &quot;separation&quot; reliability is better, because we want raters to be reliably the same, not reliably different.</p>
<p>&nbsp;</p>
<p>The Winsteps &quot;person reliability&quot; is equivalent to the traditional &quot;test&quot; reliability. Low values indicate a narrow range of person measures, or a small number of items. To increase person reliability, test persons with more extreme abilities (high and low), lengthen the test. Improving the test targeting may help slightly.</p>
<p>&nbsp;</p>
<p>The Winsteps &quot;item reliability&quot; has no traditional equivalent. Low values indicate a narrow range of item measures, or a small sample. To increase &quot;item reliability&quot;, test more people. In general, low item reliability means that your sample size is too small for stable item estimates based on the current data. If you have anchored values, then it is the item reliability of the source from which the anchor values emanate which is crucial, not the current sample.</p>
<p>&nbsp;</p>
<p>The <span style="font-weight: bold;">&quot;model&quot;</span> person reliability (including measures for extreme scores) is an upper bound to this value, when persons are ordered by measures.</p>
<p>&nbsp;</p>
<p>The <span style="font-weight: bold;">&quot;real&quot;</span> person reliability (including measures for extreme scores) is a lower bound to this value, when persons are ordered by measures</p>
<p>&nbsp;</p>
<p>The traditional &quot;test reliability&quot;, as defined by Charles Spearman in 1904, etc., is the &quot;true person variance / observed person variance&quot; for this sample on these test items. So it is really a &quot;person sample reliability&quot; rather than a &quot;test reliability&quot;, where reliability = reproducibility of person ordering. The &quot;true person variance&quot; cannot be known, but it can be approximated. KR-20 approximates it by summarizing item point-biserials. Cronbach Alpha approximates it with an analysis of variance. Winsteps approximates it using the measure standard errors.</p>
<p>&nbsp;</p>
<p>The separation coefficient and reliability computations are computed with and without any elements with extreme measures. Since the measures for extreme scores are imprecise, reliability statistics which include extreme scores are often lower than their non-extreme equivalents. Conventional computation of a reliability coefficient (KR-20, Cronbach Alpha) includes persons with extreme scores. The classical reliability computation includes extreme scores (if any) is the conventional reliability, and usually produces an estimate between the MODEL and REAL values, closer to the MODEL or even above it.</p>
<p>&nbsp;</p>
<p>KR-20 value is an estimate of the value when persons are ordered by raw scores. CRONBACH ALPHA (KR-20) KID RAW SCORE RELIABILITY is the conventional &quot;test&quot; reliability index. It reports an approximate test reliability based on the raw scores of this sample. It is only reported for complete data. An apparent paradox is that extreme scores have perfect precision, but extreme measures have perfect imprecision.</p>
<p>&nbsp;</p>
<p>Winsteps computes upper and lower boundary values for the True Reliability. The lower boundary is the Real Reliability. The upper boundary is the Model Reliability. The unknowable True Reliability lies somewhere between these two. As contradictory sources of noise are remove from the data, the True Reliability approaches the Model Reliability </p>
<p>&nbsp;</p>
<p>Conventionally, only a Person (&quot;Test&quot;) Reliability is reported. The relationship between raw-score-based reliability (i.e., KR-20, Cronbach Alpha) and measure-based reliability is complex, see <a href="http://www.rasch.org/rmt/rmt113l.htm" class="weblink">www.rasch.org/rmt/rmt113l.htm</a> - in general, Cronbach Alpha overestimates reliability, Rasch underestimates it. So, when it is likely that the Rasch reliability will be compared with conventional KR-20 or Cronbach Alpha reliabilities (which are always computed assuming the data match their assumptions), then include extreme persons and report the higher Rasch reliability, the &quot;Model&quot; reliability, computed on the assumption that all unexpectedness in the data is in accord with Rasch model predictions. The big differences between Score and Measure reliabilities occur when</p>
<p>(a) there are extreme scores. These increase score reliability, but decrease measure reliability.</p>
<p>(b) missing data. Missing data always decreases measure reliability. If the missing data are imputed at their expected values (in order to make conventional reliability formulas computable), they increase score reliability. Winsteps attempts to adjust the raw-score reliability for this inflation in the raw-score reliability, but can only do the adjustment in an approximate way.</p>
<p>&nbsp;</p>
<p>Winsteps also reports an item reliability, &quot;true item variance / observed item variance&quot;. When this value is low, it indicates that the sample size may be too small for stable comparisons between items.</p>
<p>&nbsp;</p>
<p>Anchored values are treated as though they are the &quot;true values&quot; of the MLE estimates. Their local standard errors are estimated using the current data in the same way as unanchored MLE standard error estimates. It is the measures (anchored or unanchored) and local standard errors that are used in the reliability computations. If you wish to compute reliabilities using different standard error estimates (e.g., the ones when the anchor values were generated), then please perform a separate reliability computation (using Excel).</p>
<p>&nbsp;</p>
<p>You can easily check the Winsteps reliability estimate computation yourself.</p>
<p>&nbsp;</p>
<p>Read the Winsteps <a href="pfile.htm">PFILE=</a> into an Excel spreadsheet.</p>
<p>&nbsp;</p>
<p>Compute the STDEVP standard deviation of the person measures. Square it. This is the &quot;Observed variance&quot;.</p>
<p>&nbsp;</p>
<p>&quot;Model&quot; Reliability: Take the <a href="standarderrors.htm">standard ERROR</a> column. Square each entry. Sum the squared entries. Divide that sum by the count of entries. This is the &quot;Model Error variance&quot; estimate. Then,</p>
<p class="p_Ind0Hang020MSReg10ShiftF4"><span class="f_Ind0Hang020MSReg10ShiftF4">Model Reliability = True Variance / Observed Variance = (Observed Variance - Model Error Variance) / Observed Variance.</span></p>
<p>&nbsp;</p>
<p>&quot;Real&quot; Reliability: Take the <a href="standarderrors.htm">standard ERROR</a> column. Square each entry, SE&sup2;. In another column, put SE&sup2;*Maximum [1.0, INFIT mean-square). Divide that sum by the count of entries. This is the &quot;Real Error variance&quot; estimate. Then,</p>
<p class="p_Ind0Hang020MSReg10ShiftF4"><span class="f_Ind0Hang020MSReg10ShiftF4">Real Reliability = True Variance / Observed Variance = (Observed Variance - Real Error Variance) / Observed Variance.</span></p>
<p>&nbsp;</p>
<hr noshade size=1 style="color : #000000"><p style="text-align: center;">&nbsp;</p>
<p style="text-align: center;"><span style="font-weight: bold;">Separation, Strata and Reliability</span></p>
<p>&nbsp;</p>
<p>The crucial elements in the computation of reliability are the &quot;True&quot; variance and the Error variance. These are squared distances and so difficulty to conceptualize directly. It is easier to think of their square-roots, the &quot;True&quot; standard deviation (TSD) and the root-mean-square standard error (RMSE).</p>
<p>&nbsp;</p>
<p>SEPARATION coefficient is the ratio of the PERSON (or ITEM)TRUE S.D., the &quot;true&quot; standard deviation, to RMSE, the error standard deviation. It provides a ratio measure of separation in RMSE units, which is easier to interpret than the reliability correlation. This is analogous to the Fisher Discriminant Ratio. SEPARATION coefficient&sup2; is the signal-to-noise ratio, the ratio of &quot;true&quot; variance to error variance.</p>
<p>&nbsp;</p>
<p>RELIABILITY (separation index) is a separation reliability. The PERSON (or ITEM) reliability is equivalent to KR-20, Cronbach Alpha, and the Generalizability Coefficient. The relationship between SEPARATION coefficent and RELIABILITY (separation index) is</p>
<p> RELIABILITY = SEPARATION coefficient&sup2;/(1+SEPARATION coefficient&sup2;)</p>
<p>or SEPARATION coefficent = square-root(RELIABILITY/(1-RELIABILITY)).</p>
<p>&nbsp;</p>
<p><span style="font-weight: bold;">Separation</span> (if the outlying measures are accidental) or <span style="font-weight: bold;">Strata</span> (if the outlying measures represent true performances). These numbers are statistical abstractions, but there empirical meaning is indicated by locating the Separation or Strata levels in the observed distribution at (3 * &quot;Observed S.D.&quot; / Separation) units apart, centered on the sample mean. </p>
<p>&nbsp;</p>
<div style="text-align: left; text-indent: 0px; padding: 0px 0px 0px 0px; margin: 0px 0px 0px 0px;"><table cellspacing="0" cellpadding="3" border="0" style="border: none; border-spacing:0px; border-collapse: collapse;">
<tr style="text-align:left;vertical-align:top;">
<td valign="middle" style="border: solid 1px #000000;"><p style="text-align: center;">Error</p>
<p style="text-align: center;"> RMSE</p>
</td>
<td valign="middle" style="border: solid 1px #000000;"><p style="text-align: center;">True</p>
<p style="text-align: center;"> SD</p>
</td>
<td valign="middle" style="border: solid 1px #000000;"><p style="text-align: center;">True</p>
<p style="text-align: center;"> Variance</p>
</td>
<td valign="middle" style="border: solid 1px #000000;"><p style="text-align: center;">Observed</p>
<p style="text-align: center;"> Variance</p>
</td>
<td valign="middle" style="border: solid 1px #000000;"><p style="text-align: center;">Signal-</p>
<p style="text-align: center;">to-Noise</p>
<p style="text-align: center;"> Ratio</p>
</td>
<td valign="middle" style="border: solid 1px #000000;"><p style="text-align: center;">Separation </p>
<p style="text-align: center;">= True SD</p>
<p style="text-align: center;"> / RMSE</p>
</td>
<td valign="middle" style="border: solid 1px #000000;"><p style="text-align: center;">Strata &nbsp;= </p>
<p style="text-align: center;">(4*Sep.+1)</p>
<p style="text-align: center;">/ 3</p>
</td>
<td valign="middle" style="border: solid 1px #000000;"><p style="text-align: center;">Reliability</p>
<p style="text-align: center;"> = True Variance /</p>
<p style="text-align: center;">Observed Variance</p>
</td>
</tr>
<tr style="text-align:left;vertical-align:top;">
<td valign="middle" style="height:16px; border: solid 1px #000000;"><p style="text-align: center;">1</p>
</td>
<td valign="middle" style="height:16px; border: solid 1px #000000;"><p style="text-align: center;">0</p>
</td>
<td valign="middle" style="height:16px; border: solid 1px #000000;"><p style="text-align: center;">0</p>
</td>
<td valign="middle" style="height:16px; border: solid 1px #000000;"><p style="text-align: center;">1</p>
</td>
<td valign="middle" style="height:16px; border: solid 1px #000000;"><p style="text-align: center;">0</p>
</td>
<td valign="middle" style="height:16px; border: solid 1px #000000;"><p style="text-align: center;">0</p>
</td>
<td valign="middle" style="height:16px; border: solid 1px #000000;"><p style="text-align: center;">0</p>
</td>
<td valign="middle" style="height:16px; border: solid 1px #000000;"><p style="text-align: center;">0</p>
</td>
</tr>
<tr style="text-align:left;vertical-align:top;">
<td valign="middle" style="border: solid 1px #000000;"><p style="text-align: center;">1</p>
</td>
<td valign="middle" style="border: solid 1px #000000;"><p style="text-align: center;">1</p>
</td>
<td valign="middle" style="border: solid 1px #000000;"><p style="text-align: center;">1</p>
</td>
<td valign="middle" style="border: solid 1px #000000;"><p style="text-align: center;">2</p>
</td>
<td valign="middle" style="border: solid 1px #000000;"><p style="text-align: center;">1</p>
</td>
<td valign="middle" style="border: solid 1px #000000;"><p style="text-align: center;">1</p>
</td>
<td valign="middle" style="border: solid 1px #000000;"><p style="text-align: center;">1.67</p>
</td>
<td valign="middle" style="border: solid 1px #000000;"><p style="text-align: center;">0.5</p>
</td>
</tr>
<tr style="text-align:left;vertical-align:top;">
<td valign="middle" style="border: solid 1px #000000;"><p style="text-align: center;">1</p>
</td>
<td valign="middle" style="border: solid 1px #000000;"><p style="text-align: center;">2</p>
</td>
<td valign="middle" style="border: solid 1px #000000;"><p style="text-align: center;">4</p>
</td>
<td valign="middle" style="border: solid 1px #000000;"><p style="text-align: center;">5</p>
</td>
<td valign="middle" style="border: solid 1px #000000;"><p style="text-align: center;">2</p>
</td>
<td valign="middle" style="border: solid 1px #000000;"><p style="text-align: center;">2</p>
</td>
<td valign="middle" style="border: solid 1px #000000;"><p style="text-align: center;">3</p>
</td>
<td valign="middle" style="border: solid 1px #000000;"><p style="text-align: center;">0.8</p>
</td>
</tr>
<tr style="text-align:left;vertical-align:top;">
<td valign="middle" style="border: solid 1px #000000;"><p style="text-align: center;">1</p>
</td>
<td valign="middle" style="border: solid 1px #000000;"><p style="text-align: center;">3</p>
</td>
<td valign="middle" style="border: solid 1px #000000;"><p style="text-align: center;">9</p>
</td>
<td valign="middle" style="border: solid 1px #000000;"><p style="text-align: center;">10</p>
</td>
<td valign="middle" style="border: solid 1px #000000;"><p style="text-align: center;">3</p>
</td>
<td valign="middle" style="border: solid 1px #000000;"><p style="text-align: center;">3</p>
</td>
<td valign="middle" style="border: solid 1px #000000;"><p style="text-align: center;">4.33</p>
</td>
<td valign="middle" style="border: solid 1px #000000;"><p style="text-align: center;">0.9</p>
</td>
</tr>
<tr style="text-align:left;vertical-align:top;">
<td valign="middle" style="border: solid 1px #000000;"><p style="text-align: center;">1</p>
</td>
<td valign="middle" style="border: solid 1px #000000;"><p style="text-align: center;">4</p>
</td>
<td valign="middle" style="border: solid 1px #000000;"><p style="text-align: center;">16</p>
</td>
<td valign="middle" style="border: solid 1px #000000;"><p style="text-align: center;">17</p>
</td>
<td valign="middle" style="border: solid 1px #000000;"><p style="text-align: center;">4</p>
</td>
<td valign="middle" style="border: solid 1px #000000;"><p style="text-align: center;">4</p>
</td>
<td valign="middle" style="border: solid 1px #000000;"><p style="text-align: center;">5.67</p>
</td>
<td valign="middle" style="border: solid 1px #000000;"><p style="text-align: center;">0.94</p>
</td>
</tr>
</table>
</div>
<p>&nbsp;</p>
<p>There is more at <a href="http://www.rasch.org/rmt/rmt94n.htm" class="weblink">www.rasch.org/rmt/rmt94n.htm</a> and <a href="http://www.rasch.org/rmt/rmt163f.htm" target="_blank" class="weblink">www.rasch.org/rmt/rmt163f.htm</a></p>
<p>&nbsp;</p>
<hr noshade size=2 style="color : #000000"><p>&nbsp;</p>
<p><span style="font-weight: bold;">Spearman-Brown Prophecy Formula</span></p>
<p>&nbsp;</p>
<p>How many items (or persons) are required to produce the reliability I want with the sample of persons and the same type of items (or this test and the same type of persons)?</p>
<p>&nbsp;</p>
<p>T = target number of items, R<span style="font-size: 6pt; vertical-align: sub;">T</span> = target person reliability</p>
<p>C = current number of items, R<span style="font-size: 6pt; vertical-align: sub;">C</span> = current person reliability</p>
<p>&nbsp;</p>
<p>1. Predict number of persons = T = C * R<span style="font-size: 6pt; vertical-align: sub;">T</span> * (1-R<span style="font-size: 6pt; vertical-align: sub;">C</span>) / ( (1-R<span style="font-size: 6pt; vertical-align: sub;">T</span>) * R<span style="font-size: 6pt; vertical-align: sub;">C</span>)</p>
<p>&nbsp;</p>
<p>Example: the current test length is C = 10 items, and the current person reliability is R<span style="font-size: 6pt; vertical-align: sub;">C</span> = 0.3. We want a person reliability of R<span style="font-size: 6pt; vertical-align: sub;">T</span> = 0.8.</p>
<p>Target number of items is T = 10 * 0.8 * (1-0.3) / ( (1-0.8)* 0.3) = 94 items.</p>
<p>&nbsp;</p>
<p>2. Predicted reliability = R<span style="font-size: 6pt; vertical-align: sub;">T</span> = T * R<span style="font-size: 6pt; vertical-align: sub;">C </span>/ ( C *  (1-R<span style="font-size: 6pt; vertical-align: sub;">C</span>) + T * R<span style="font-size: 6pt; vertical-align: sub;">C</span>)</p>
<p>&nbsp;</p>
<p>Example: we have a test of C = 11 items of person reliability R<span style="font-size: 6pt; vertical-align: sub;">C</span> = 0.5, what is the predicted reliability of a test of T = 17 items?</p>
<p>Predicted reliability R<span style="font-size: 6pt; vertical-align: sub;">T</span> = &nbsp;17 * 0.5 / ( 11 * (1-0.5) + 17 * 0.5) = 0.61</p>
<p>&nbsp;</p>
<hr noshade size=2 style="color : #000000"><p>&nbsp;</p>
<p><span style="font-weight: bold;">Test-Retest Reliability</span></p>
<p>&nbsp;</p>
<p>is the correlation between the person measures obtained from two administrations of the same test to the same persons. The expected value of the test-retest reliability is the person reliability of the first administration.</p>
<p>&nbsp;</p>
<p>The &quot;Smallest Detectable Difference&quot; = &quot;Smallest statistically significant difference in a person's measures&quot; when a test is administered twice to a person under normal conditions = 1.96*(person sample S.D.)*(test-retest reliability).</p>
<p>&nbsp;</p>
 
</div>



</body>
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-83731338-2"></script><script>  window.dataLayer = window.dataLayer || [];  function gtag(){dataLayer.push(arguments);}  gtag('js', new Date());  gtag('config', 'UA-83731338-2');</script></html>
