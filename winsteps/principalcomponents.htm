<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
<head>
   <script async src="https://www.googletagmanager.com/gtag/js?id=UA-83731338-2"></script><script>  window.dataLayer = window.dataLayer || [];  function gtag(){dataLayer.push(arguments);}  gtag('js', new Date());  gtag('config', 'UA-83731338-2');</script><TITLE>Dimensionality: contrasts &amp; variances
   </title>
   <meta name="generator" content="Help &amp; Manual">
   <meta name="keywords" content="Winsteps, Rasch Measurement, Rasch Analysis, 1-PL, 1PL">
   <meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
   <meta http-equiv="Content-Style-Type" content="text/css">
   <link type="text/css" href="default.css" rel="stylesheet">
<script type= "text/javascript">   
var min=10;
var max=300;
function increaseFontSize() {
   var p = document.getElementsByTagName('p');
   for(i=0;i<p.length;i++) {
      if(p[i].style.fontSize) {
         var s = parseInt(p[i].style.fontSize.replace("%",""));
      } else {
         var s = 100;
      }
      if(s<max) {
         s += 10;
      }
      p[i].style.fontSize = s+"%"
   }
}
function decreaseFontSize() {
   var p = document.getElementsByTagName('p');
   for(i=0;i<p.length;i++) {
      if(p[i].style.fontSize) {
         var s = parseInt(p[i].style.fontSize.replace("%",""));
      } else {
         var s = 100;
      }
      if(s>min) {
         s -= 10;
      }
      p[i].style.fontSize = s+"%"
   }   
}


</script>
<style type="text/css" media="print">
.printbutton {
  visibility: hidden;
  display: none;
}
</style>   

<script type="text/javascript" src="helpman_topicinit.js"></script>
</head>

<body style="margin: 0px 0px 0px 0px; background: #FFFFFF;">




<table width="100%" border="0" cellspacing="0" cellpadding="5" bgcolor="#FFFFFF">
  <tr valign="middle">
    <td align="left">
      <p class="p_Heading1"><span class="f_Heading1">Dimensionality: contrasts &amp; variances</span></p>

    </td>
    <td align="right">
     <a href="controlindex.htm">Top</a>&nbsp;<a href="dif_for_two_person_groups.htm">Up</a>&nbsp;<a href="dimensionality.htm">Down</a>&nbsp;
     <a href="javascript:decreaseFontSize();"><font size="-2"><b>A</b></font></a>&nbsp;<a href="javascript:increaseFontSize();"><font size="+2"><b>A</b></font></a><br>
<script  type= "text/javascript">
document.write("<input type='button' " +
"onClick='window.print()' " +
"class='printbutton' " +
"STYLE='background-color:00BFFF' " +
"value='Print This Page'>");
</script>
     

    </td>
  </tr>
</table>




<!-- Placeholder for topic body. -->
<div style="padding: 10px 10px 10px 5px; width: 100%;"> 
<p><span style="font-style: italic;">Please explain Rasch PCA of Residuals in plain English for people like me who are not particularly good at mathematical terminology.  </span></p>
<p>&nbsp;</p>
<p>Rasch &quot;PCA of residuals&quot; looks for patterns in the part of the data that does not accord with the Rasch measures. This is the &quot;unexpected&quot; part of the data. We are looking to see if groups of items share the same patterns of unexpectedness. If they do, then those items probably also share a substantive attribute in common, which we call a &quot;secondary dimension&quot;. Then our questions are:</p>
<p>&nbsp;</p>
<p>1. &quot;What is the secondary dimension?&quot; - to discover this we look at the contrast between the content of the items at the top, A,B,C, and the bottom, a,b,c, of the contrast plot in <a href="table23_2.htm">Table 23.2</a>. For instance, if the items at the top are &quot;physical&quot; items and the items at the bottom are &quot;mental&quot; items. Then there is a secondary dimension with &quot;physical&quot; at one end, and &quot;mental&quot; at the other. </p>
<p>&nbsp;</p>
<p>2. &quot;Is the secondary dimension big enough to distort measurement?&quot; - usually the secondary dimension needs to have the strength of at least two items to be above the noise level. We see the strength (eigenvalue) in the first column of numbers in <a href="table23_0.htm">Table 23.0</a>.</p>
<p>&nbsp;</p>
<p>3. &quot;What do we do about it?&quot; - often our decision is &quot;nothing&quot;. &nbsp;On a math test, we will get a big contrast between &quot;algebra&quot; and &quot;word problems&quot;. We know that they are conceptually different, but they are both part of math. We don't want to omit either of them, and we don't want separate &quot;algebra&quot; measures and &quot;word problem&quot; measures. So the best we can do is to verify that the balance between the number of algebra items and the number of word-problem items is in accordance with our test plan.</p>
<p>&nbsp;</p>
<p>But we may see that one end of the contrast is off-dimension. For instance, we may see a contrast between &quot;algebra items using Latin letters&quot; and &quot;algebra items using Greek letters&quot;. We may decide that knowledge of Greek letters is incidental to our purpose of measuring the understanding of algebraic operations, and so we may decide to omit or revise the Greek-letter items.</p>
<p>&nbsp;</p>
<p>In summary: Look at the content (wording) of the items at the top and bottom of the contrast: items A,B,C and &nbsp;items a,b,c. If those items are different enough to be considered different dimensions (similar to &quot;height&quot; and &quot;weight&quot;), then split the items into separate analyses. If the items are part of the same dimension (similar to &quot;addition&quot; and &quot;subtraction&quot; on an arithmetic test), then no action is necessary. You are seeing the expected co-variance of items in the same content area of a dimension.</p>
<p>&nbsp;</p>
<hr noshade size=1 style="color : #000000"><p>&nbsp;</p>
<p><span style="font-weight: bold;">Principal-Components Analysis of Residuals</span> is not interpreted in the same way as Common-Factor Analysis of the original data.</p>
<p>&nbsp;</p>
<p>In Common-Factor analysis, we try to optimize the commonalities, maximization, rotation and obliqueness to give the strongest possible factor structure, where the factor loadings are interpreted as the correlations with the desired latent factors.</p>
<p>&nbsp;</p>
<p>In PCA of residuals, we are trying to falsify the hypothesis that the residuals are random noise by finding the component that explains the largest possible amount of variance in the residuals. This is the &quot;first contrast&quot; (or first PCA component in the correlation matrix of the residuals). If the eigenvalue of the first contrast is small (usually less than 2.0) then the first contrast is &nbsp;at the noise level and the hypothesis of random noise is not falsified in a general way. If not, the loadings on the first contrast indicate that there are contrasting patterns in the residuals. The absolute sizes of the loadings are generally inconsequential. It is the patterns of the loadings that are important. We see the patterns by looking at the plot of the loadings in Winsteps Table 23.2, particularly comparing the top and bottom of the plot. </p>
<p>&nbsp;</p>
<p>So, if we notice that the 1st contrast has an eigenvalue of 3 (the strength of 3 items), and we see on the contrast plot that there is a group of 3 items (more or less) outlying toward the top or the bottom of the plot, then we attribute the first contrast to the fact that their pattern contrasts with the pattern of the other items. We then look at the content of those items to discover what those items share that contrasts with the content of the other items.</p>
<p>&nbsp;</p>
<p>Please do not interpret Rasch-residual-based Principal Components Analysis (PCAR) as a usual factor analysis. These components show contrasts between opposing factors, not loadings on one factor. Criteria have yet to be established for when a deviation becomes a dimension. So PCA is indicative, but not definitive, about secondary dimensions.</p>
<p>&nbsp;</p>
<p>In conventional factor analysis, interpretation may be based only on positive loadings. In the PCA of Residuals, interpretation must be based on the contrast between positive and negative loadings.</p>
<p>&nbsp;</p>
<p>The &quot;first factor&quot; (in the traditional Factor Analysis sense) is the Rasch dimension. By default all items (or persons)are in the &quot;first factor&quot; until proven otherwise. The first contrast plot shows a contrast within the data between two sets of items orthogonal to the Rasch dimension. We usually look at the plot and identify a cluster of items at the top or bottom of the plot which share most strongly some substantive off-Rasch-dimension attribute. These become the &quot;second factor&quot;.</p>
<p>&nbsp;</p>
<p>Winsteps is doing a PCA of residuals, not of the original observations. So, the first component (dimension) has already been removed. We are looking at secondary dimensions, components or contrasts. When interpreting the meaning of a component or a factor, the conventional approach is only to look at the largest positive loadings in order to infer the substantive meaning of the component. In Winsteps PCA this method of interpretation can be misleading, because the component is reflecting opposing response patterns across items by persons. So we need to identify the opposing response patterns and interpret the meaning of the component from those. These are the response patterns to the items at the top and bottom of the plots.</p>
<p>&nbsp;</p>
<hr noshade size=1 style="color : #000000"><p>&nbsp;</p>
<p><span style="font-weight: bold;">Sample size:</span> &nbsp;A useful criterion is 100 persons for PCA of items, and 100 items for PCA of persons, though useful findings can be obtained with 20 persons for PCA of items, and 20 items for PCA of persons. </p>
<p>&nbsp;</p>
<p style="margin: 0px 0px 0px 24px;">Arrindell, W. A., &amp; van der Ende. J. (1985). An empirical test of the utility of the observations-to-variables ratio in factor and components analysis. Applied Psychological Measurement, 9, 165 - 178.</p>
<p>&nbsp;</p>
<hr noshade size=1 style="color : #000000"><p>&nbsp;</p>
<p>Compatibility with earlier computation: The Winsteps algorithm was changed to align more closely with the usual practice in statistics of explaining raw-score variance (parallel to Outfit). The earlier method in Winsteps was explaining the statistical-information variance (parallel to Infit). Since the outlying observations have high raw-score variance, but low statistical-information variance, the previous computation showed Rasch explaining a higher proportion of the variance.</p>
<p>&nbsp;</p>
<hr noshade size=1 style="color : #000000"><p>&nbsp;</p>
<p>If you want to do a more conventional interpretation, then output the <a href="icorfil.htm">ICORFIL=</a> correlation matrix from the Output Files menu. You can read this into a factor analysis program, such as SAS or SPSS. You can then do a PCA or CFA (common factor analysis) of the correlation matrix, with the usual obliquenesses, rotations etc.</p>
<p>&nbsp;</p>
<p>In Winsteps, you can also do a PCA of the original observations by specifying <a href="prcomp.htm">PRCOMP=</a>Obs</p>
<p>&nbsp;</p>
<p>Example from Table 23.0 from <a href="example0.htm">Example0.txt</a>:</p>
<p>&nbsp;</p>
<p class="p_CourierReg8"><span class="f_CourierReg8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Table&nbsp;of&nbsp;STANDARDIZED&nbsp;RESIDUAL&nbsp;variance&nbsp;(in&nbsp;Eigenvalue&nbsp;units)</span></p>
<p class="p_CourierReg8"><span class="f_CourierReg8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;--&nbsp;Empirical&nbsp;--&nbsp;&nbsp;&nbsp;&nbsp;Modeled</span></p>
<p class="p_CourierReg8"><span class="f_CourierReg8">Total&nbsp;raw&nbsp;variance&nbsp;in&nbsp;observations&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;51.0&nbsp;100.0%&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;100.0%</span></p>
<p class="p_CourierReg8"><span class="f_CourierReg8">&nbsp;&nbsp;Raw&nbsp;variance&nbsp;explained&nbsp;by&nbsp;measures&nbsp;&nbsp;&nbsp;=&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;26.0&nbsp;&nbsp;51.0%&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;50.8%</span></p>
<p class="p_CourierReg8"><span class="f_CourierReg8">&nbsp;&nbsp;&nbsp;&nbsp;Raw&nbsp;variance&nbsp;explained&nbsp;by&nbsp;persons&nbsp;&nbsp;=&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;10.8&nbsp;&nbsp;21.2%&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;21.2%</span></p>
<p class="p_CourierReg8"><span class="f_CourierReg8">&nbsp;&nbsp;&nbsp;&nbsp;Raw&nbsp;Variance&nbsp;explained&nbsp;by&nbsp;items&nbsp;&nbsp;&nbsp;&nbsp;=&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;15.1&nbsp;&nbsp;29.7%&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;29.6%</span></p>
<p class="p_CourierReg8"><span class="f_CourierReg8">&nbsp;&nbsp;Raw&nbsp;unexplained&nbsp;variance&nbsp;(total)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;25.0&nbsp;&nbsp;49.0%&nbsp;100.0%&nbsp;&nbsp;&nbsp;49.2%</span></p>
<p class="p_CourierReg8"><span class="f_CourierReg8">&nbsp;&nbsp;&nbsp;&nbsp;Unexplned&nbsp;variance&nbsp;in&nbsp;1st&nbsp;contrast&nbsp;=&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;4.6&nbsp;&nbsp;&nbsp;9.1%&nbsp;&nbsp;18.5%</span></p>
<p class="p_CourierReg8"><span class="f_CourierReg8">&nbsp;&nbsp;&nbsp;&nbsp;Unexplned&nbsp;variance&nbsp;in&nbsp;2nd&nbsp;contrast&nbsp;=&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2.9&nbsp;&nbsp;&nbsp;5.8%&nbsp;&nbsp;11.8%</span></p>
<p class="p_CourierReg8"><span class="f_CourierReg8">&nbsp;&nbsp;&nbsp;&nbsp;Unexplned&nbsp;variance&nbsp;in&nbsp;3rd&nbsp;contrast&nbsp;=&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2.3&nbsp;&nbsp;&nbsp;4.5%&nbsp;&nbsp;&nbsp;9.2%</span></p>
<p class="p_CourierReg8"><span class="f_CourierReg8">&nbsp;&nbsp;&nbsp;&nbsp;Unexplned&nbsp;variance&nbsp;in&nbsp;4th&nbsp;contrast&nbsp;=&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1.7&nbsp;&nbsp;&nbsp;3.4%&nbsp;&nbsp;&nbsp;6.9%</span></p>
<p class="p_CourierReg8"><span class="f_CourierReg8">&nbsp;&nbsp;&nbsp;&nbsp;Unexplned&nbsp;variance&nbsp;in&nbsp;5th&nbsp;contrast&nbsp;=&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1.6&nbsp;&nbsp;&nbsp;3.2%&nbsp;&nbsp;&nbsp;6.5%</span></p>
<p>&nbsp;</p>
<p>The Rasch dimension explains 51.0% of the variance in the data: good! The largest secondary dimension, &quot;the first contrast in the residuals&quot; explains 9.1% of the variance - somewhat greater than around 4% that would be observed in data like these simulated to fit the Rasch model. Check this by using the <a href="sifile.htm">SIMUL=</a> option in Winsteps to simulate a Rasch-fitting dataset with same characteristics as this dataset. Then produce this Table 23 for it. Also see: <a href="http://www.rasch.org/rmt/rmt191h.htm" class="weblink">www.rasch.org/rmt/rmt191h.htm</a></p>
<p>&nbsp;</p>
<p>In these data, the variance explained by the items, 29.7% is only three times the variance explained by the first contrast 9.1%, so there is a noticeable secondary dimension in the items. The eigenvalue of the first contrast is 4.6 - this indicates that it has the strength of about 5 items (4.6 rounded to 5, out of 25), somewhat bigger than the strength of two items (an eigenvalue of 2), the smallest amount that could be considered a &quot;dimension&quot;. Contrast the content of the items at the top and bottom of the plot in Table 23.2 to identify what this secondary dimension reflects.</p>
<p>&nbsp;</p>
<p>Tentative guidelines:</p>
<p>1. Is your person measure S.D. in <a href="table3_1.htm">Table 3</a> what you expect (or better)?</p>
<p> Yes, then your &quot;variance explained by persons&quot;is also good.</p>
<p>&nbsp;</p>
<p>2. 1. Is your item difficulty S.D. in Table 3 what you expect (or better)?</p>
<p>Yes, then your &quot;variance explained by the items&quot; is also good.</p>
<p>&nbsp;</p>
<p>3. Is your unexplained variance explained by 1st contrast (eigenvalue size) &lt; 2.0 ?</p>
<p>Yes, then your biggest secondary dimension has the strength of less than 2 items. Good. For the expected size of the unexplained variance:</p>
<p>&nbsp;</p>
<p style="text-align: center;"><img src="clip0157.png" width="500" height="253" border="0" alt="" style="margin:0 auto;margin:0px;"></p>
<p style="text-align: center;">&nbsp;</p>
<p style="text-align: center;"><img src="clip0158.png" width="500" height="289" border="0" alt="" style="margin:0 auto;margin:0px;"></p>
<p>&nbsp;</p>
<p>4. Now, please <a href="simulated.htm">simulate</a> Rasch-fitting data like yours, and compare <a href="table23_0.htm">Table 23</a> and <a href="table24_0.htm">Table 24</a> with it.</p>
<p>&nbsp;</p>
<p>There is a paradox: &quot;more variance explained&quot; &reg; &quot;more unidimensional&quot; in the Guttman sense - where all unexplained variance is viewed as degrading the perfect Guttman uni-dimension. But &quot;more unidimensional&quot; (in the stochastic Rasch sense) depends on the size of the second dimension in the data, not on the variance explained by the first (Rasch) dimension. This is because most unexplained variance is hypothesized to be the random noise predicted by the Rasch model, rather than a degradation of the unidimensionality of the Rasch measures</p>
<p>&nbsp;</p>
<p>Analytical Note:</p>
<p>Winsteps performs an unrotated &quot;principal components&quot; factor analysis. (using Hotelling's terminology). If you would like to rotate axes, have oblique axes, or perform a &quot;common factor&quot; factor analysis of the residuals, Winsteps can write out the matrices of residual item (or person) correlations, see the &quot;Output Files&quot; pull down menu or <a href="icorfil.htm">ICORFIL=</a> and <a href="pcorfil.htm">PCORFIL=.</a> You can import these into any statistics software package.</p>
<p>&nbsp;</p>
<p>The purpose of PCA of residuals is not to construct variables (as it is with &quot;common factor&quot; analysis), but to explain variance. First off, we are looking for the contrast in the residuals that explains the most variance. If this contrast is at the &quot;noise&quot; level, then we have no shared second dimension. If it does, then this contrast is the &quot;second&quot; dimension in the data. (The Rasch dimension is hypothesized to be the first). Similarly we look for a third dimension, etc. Rotation, oblique axes, the &quot;common factor&quot; approach, all reapportion variance, usually in an attempt to make the factor structure more clearly align with the items, but, in so doing, the actual variance structure and dimensionality of the data is masked.</p>
<p>&nbsp;</p>
<p>In Rasch analysis, we are trying to do the opposite of what is usually happening in factor analysis. In Rasch analysis of residuals, we want not to find contrasts, and, if we do, we want to find the least number of contrasts above the noise level, each, in turn, explaining as much variance as possible. This is exactly what unrotated PCA does. </p>
<p>&nbsp;</p>
<p>In conventional factor analysis of observations, we are hoping desperately to find shared factors, and to assign the items to them as clearly and meaningfully as possible. In this endeavor, we use a whole toolbox of rotations, obliquenesses and choices of diagonal self-correlations (i.e., the &quot;common factor&quot; approach).</p>
<p>&nbsp;</p>
<p>But, different analysts have different aims, and so Winsteps provides the matrix of <a href="icorfil.htm">residual correlations</a> to enable the analyst to perform whatever factor analysis is desired!</p>
<p>&nbsp;</p>
<p>The Rasch Model: Expected values, Model Variances, and Standardized Residuals</p>
<p>The Rasch model constructs additive measures from ordinal observations. It uses disordering of the observations across persons and items to construct the additive frame of reference. Perfectly ordered observations would accord with the ideal model of Louis <a href="guttmanpattern.htm">Guttman</a>, but lack information as to the distances involved.</p>
<p>&nbsp;</p>
<p>Since the Rasch model uses disordering in the data to construct distances, it predicts that this disordering will have a particular ideal form. Of course, empirical data never exactly accord with this ideal, so a major focus of Rasch fit analysis is to discover where and in what ways the disordering departs from the ideal. If the departures have substantive implications, then they may indicate that the quality of the measures is compromised.</p>
<p>&nbsp;</p>
<p>A typical Rasch model is:</p>
<p> log (Pnik / Pni(k-1) ) = Bn - Di - Fk</p>
<p>&nbsp;</p>
<p>where</p>
<p> Pnik = the probability that person n on item i is observed in category k, where k=0,m</p>
<p> Pni(k-1) = the probability that person n on item i is observed in category k-1</p>
<p> Bn = the ability measure of person n</p>
<p> Di = the difficulty measure of item i</p>
<p> Fk = the structure calibration from category k-1 to category k</p>
<p>&nbsp;</p>
<p>This predicts the observation Xni. Then</p>
<p> Xni = Eni &plusmn; sqrt(Vni)</p>
<p>&nbsp;</p>
<p>where</p>
<p> Eni = sum (kPnik) for k=0,m. </p>
<p> &nbsp;This is the expected value of the observation.</p>
<p> Vni = sum (k&sup2;Pnik) - (Eni)&sup2; for k=0,m. </p>
<p> &nbsp;This is the model variance of the observation about its expectation, i.e., the predicted randomness in the data.</p>
<p>&nbsp;</p>
<p>The Rasch model is based on the specification of &quot;local independence&quot;. This asserts that, after the contribution of the measures to the data has been removed, all that will be left is random, normally distributed. noise. This implies that when a residual, (Xni - Eni), is divided by its model standard deviation, it will have the characteristics of being sampled from a unit normal distribution. That is:</p>
<p> (Xni - Eni) / sqrt (Vni), the standardized residual of an observation, is specified to be N(0,1)</p>
<p>&nbsp;</p>
<p>The bias in a measure estimate due to the misfit in an observation approximates (Xni - Eni) * S.E.&sup2;(measure)</p>
<p>&nbsp;</p>
<p>Principal Components Analysis of Residuals</p>
<p>&quot;Principal Component Analysis (PCA) is a powerful technique for extracting structure from possibly high-dimensional data sets. It is readily performed by solving an eigenvalue problem, or by using iterative algorithms which estimate principal components [as in Winsteps]. ... some of the classical papers are due to Pearson (1901); Hotelling (1933); ... PCA is an orthogonal transformation of the coordinate system in which we describe our data. The new coordinate values by which we represent the data are called principal components. It is often the case that a small number of principal components is sufficient to account for most of the structure in the data. These are sometimes called factors or latent variables of the data.&quot; (Sch&ouml;lkopf, D., Smola A.J., M&uuml;ller K.-R., 1999, Kernel Principal Component Analysis, in Sch&ouml;lkopf at al. &quot;Advances in Kernel Methods&quot;, London: MIT Press).</p>
<p>Pearson, K. (1901) On lines and planes of closest fit to points in space. Philosophical Magazine, 2:559-572.</p>
<p>Hotelling, H. (1933) Analysis of a complex of statistical variables into principal components. Journal of Educational Psychology, 24:417-441, 498-520.</p>
<p>&nbsp;</p>
<p>The standardized residuals are modeled to have unit normal distributions which are independent and so uncorrelated. A PCA of Rasch standardized residuals should look like a PCA of random normal deviates. Simulation studies indicate that the largest component would have an eigenvalue of about 1.4 and they get smaller from there. But there is usually something else going on in the data, so, since we are looking at residuals, each component contrasts deviations in one direction (&quot;positive loading&quot;) against deviation in the other direction (&quot;negative loading&quot;). As always with factor analysis, positive and negative loading directions are arbitrary. Each component in the residuals only has substantive meaning when its two ends are contrasted. This is a little different from PCA of raw observations where the component is thought of as capturing the &quot;thing&quot;.</p>
<p>&nbsp;</p>
<p>Loadings are plotted against Rasch measures because deviation in the data from the Rasch model is often not uniform along the variable (which is actually the &quot;first&quot; dimension). It can be localized in easy or hard items, high or low ability people. The Wright and Masters &quot;Liking for Science&quot; data is an excellent example of this.</p>
<p>&nbsp;</p>
<p>Total, Explained and Unexplained Variances</p>
<p>The decomposition of the total variance in the data set proceeds as follows for the standardized residual, <a href="prcomp.htm">PRCOMP=</a>S and raw score residual <a href="prcomp.htm">PRCOMP=</a>R, option. </p>
<p>&nbsp;</p>
<p>(i) The average person ability measure, b, and the average item difficulty measure, d, are computed.</p>
<p>&nbsp;</p>
<p>(ii) The expected response, Ebd, by a person of average ability measure to an item of average difficulty measure is computed. (If there are multiple rating or partial credit scales, then this is done for each rating or partial credit scale.)</p>
<p>&nbsp;</p>
<p>(iii) Each observed interaction of person n, of estimated measure Bn, with item i, of estimated measure Di, produces an observation Xni, with an expected value, Eni, and model variance, Vni. </p>
<p> The raw-score residual, Zni, of each Xni is Zni = Xni-Eni.</p>
<p> The standardized residual, Zni, of each Xni is Zni = (Xni-Eni)/sqrt(Vni).</p>
<p>&nbsp;</p>
<p>Empirically:</p>
<p>(iv) The piece of the observation available for explanation by Bn and Di is approximately Xni - Ebd. </p>
<p> In raw-score residual units, this is Cni = Xni-Ebd</p>
<p> In standardized residual units, this is Cni = (Xni-Ebd)/sqrt(Vni)</p>
<p> The total variance sum-of-squares in the data set available for explanation by the measures is: VAvailable = sum(Cni&sup2;)</p>
<p>&nbsp;</p>
<p>(v) The total variance sum of squares predicted to be unexplained by the measures is: VUnexplained = sum(Zni&sup2;)</p>
<p>&nbsp;</p>
<p>(vi) The total variance sum of squares explained by the measures is: VExplained = VAvailable - VUnexplained</p>
<p> If VEXplained is negative, see below.</p>
<p>&nbsp;</p>
<p>Under model conditions:</p>
<p>(viii) The total variance sum of squares explained by the measures is: </p>
<p> Raw-score residuals: VMexplained = sum((Eni-Ebd)&sup2;)</p>
<p> Standardized residuals: VMexplained = sum((Eni-Ebd)&sup2;/Vni)</p>
<p>&nbsp;</p>
<p>(ix) The total variance sum of squares predicted to be unexplained by the measures is: </p>
<p> Raw score residuals: VMunexplained = sum(Vni)</p>
<p> Standardized residuals: VMunexplained = sum(Vni/Vni) = sum(1)</p>
<p>&nbsp;</p>
<p>x) total variance sum-of-squares in the data set predicted to be available for explanation by the measures is: VMAvailable = VMexplained + VMUnexplained </p>
<p>&nbsp;</p>
<p><span style="font-weight: bold;">Negative Variance Explained</span></p>
<p>&nbsp;</p>
<p class="p_CourierReg8"><span class="f_CourierReg8">Table&nbsp;of&nbsp;STANDARDIZED&nbsp;RESIDUAL&nbsp;variance&nbsp;(in&nbsp;Eigenvalue&nbsp;units)</span></p>
<p class="p_CourierReg8"><span class="f_CourierReg8">Total&nbsp;variance&nbsp;in&nbsp;observations&nbsp;=&nbsp;&nbsp;20.3&nbsp;&nbsp;100.0%</span></p>
<p class="p_CourierReg8"><span class="f_CourierReg8">Variance&nbsp;explained&nbsp;by&nbsp;measures&nbsp;=&nbsp;-23.7&nbsp;-116.2%</span></p>
<p>&nbsp;</p>
<p>According to this Table, the variance explained by the measures is less than the theoretical minimum of 0.00. This &quot;negative variance&quot; arises when there is unmodeled covariance in the data. In Rasch situations this happens when the randomness in the data, though normally distributed when considered overall, is skewed when partitioned by measure difference. A likely explanation is that some items are reverse-coded. Check that all correlations are positive by viewing the <a href="diagnosismenu.htm">Diagnosis Menu</a>, Table A. If necessary, use <a href="irefer.htm">IREFER=</a> to recode items. If there is no obvious explanation, please email your control and data file to <a href="http://www.winsteps.com/" class="weblink">www.winsteps.com</a></p>
<p>&nbsp;</p>
<p>Principal Components Analysis of Standardized Residuals</p>
<p>(i) The standardized residuals for all observations are computed. Missing observations are imputed to have a standardized residual of 0, i.e., to fit the model.</p>
<p>&nbsp;</p>
<p>(ii) Correlation matrices of standardized residuals across items and across persons are computed. The correlations furthest from 0 (uncorrelated) are reported in Tables <a href="table23_99.htm">23.99</a> and 24.99.</p>
<p>&nbsp;</p>
<p>(iii) In order to test the specification that the standardized residuals are uncorrelated, it is asserted that all randomness in the data is shared across the items and persons. This is done by placing 1's in the main diagonal of the correlation matrix. This accords with the &quot;Principal Components&quot; approach to Factor Analysis. (&quot;General&quot; Factor Analysis attempts to estimate what proportion of the variance is shared across items and persons, and reduces the diagonal values from 1's accordingly. This approach contradicts our purpose here.)</p>
<p>&nbsp;</p>
<p>(iv) The correlation matrices are decomposed. In principal, if there are L items (or N persons), and they are locally independent, then there are L item components (or N person components) each of size (i.e., eigenvalue) 1, the value in the main diagonal. But there are expected to be random fluctuations in the structure of the randomness. However, eigenvalues of less than 2 indicate that the implied substructure (dimension) in these data has less than the strength of 2 items (or 2 persons), and so, however powerful it may be diagnostically, it has little strength in these data.</p>
<p>&nbsp;</p>
<p>(v) If items (or persons) do have commonalities beyond those predicted by the Rasch model, then these may appear as shared fluctuations in their residuals. These will inflate the correlations between those items (or persons) and result in components with eigenvalues greater than 1. The largest of these components is shown in Table 23.2 and 24.3, and sequentially smaller ones in later subtables.</p>
<p>&nbsp;</p>
<p>(vi) In the Principal Components Analysis, the total variance is expressed as the sum of cells along the main diagonal, which is the number of items, L, (or number of persons, N). This corresponds to the total unexplained variance in the dataset, VUnexplained.</p>
<p>&nbsp;</p>
<p>(vii) The variance explained by the current contrast is its eigenvalue.</p>
<p>&nbsp;</p>
<p>Sample size: The more, the better .,...</p>
<p>&quot;There are diminishing returns, but even at large subject to item ratios and Ns (such as 201 ratio or N &gt; 1000) and with unrealistically strong factor loadings and clear factor structures, EFA and PCA can produce error rates up to 30%, leaving room for improvement via larger samples.&quot; Osborne, Jason W. &amp; Anna B. Costello (2004). Sample size and subject to item ratio in principal components analysis. <a href="http://pareonline.net/getvn.asp?v=9&n=11" target="_blank" class="weblink">Practical Assessment, Research &amp; Evaluation, 9(11)</a></p>
<p>&nbsp;</p>
<p>Example: Item Decomposition</p>
<p>From Table 23.2: The Principal Components decomposition of the standardized residuals for the items, correlated across persons. Winsteps reports:</p>
<p>&nbsp;</p>
<p class="p_CourierReg8"><span class="f_CourierReg8">Table&nbsp;of&nbsp;STANDARDIZED&nbsp;RESIDUAL&nbsp;variance&nbsp;(in&nbsp;Eigenvalue&nbsp;units)</span></p>
<p class="p_CourierReg8"><span class="f_CourierReg8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Empirical&nbsp;&nbsp;&nbsp;&nbsp;Modeled</span></p>
<p class="p_CourierReg8"><span class="f_CourierReg8">Total&nbsp;variance&nbsp;in&nbsp;observations&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1452.0&nbsp;&nbsp;100.0%&nbsp;&nbsp;100.0%</span></p>
<p class="p_CourierReg8"><span class="f_CourierReg8">Variance&nbsp;explained&nbsp;by&nbsp;measures&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1438.0&nbsp;&nbsp;&nbsp;99.0%&nbsp;&nbsp;&nbsp;98.6%</span></p>
<p class="p_CourierReg8"><span class="f_CourierReg8">Unexplained&nbsp;variance&nbsp;(total)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;14.0&nbsp;&nbsp;&nbsp;&nbsp;1.0%&nbsp;&nbsp;&nbsp;&nbsp;1.4%</span></p>
<p class="p_CourierReg8"><span class="f_CourierReg8">Unexpl&nbsp;var&nbsp;explained&nbsp;by&nbsp;1st&nbsp;contrast&nbsp;=&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2.7&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;.2%</span></p>
<p>&nbsp;</p>
<p>The first contrast has an eigenvalue size of 2.7 This corresponds to 2.7 items.</p>
<p>There are 14 active items, so that the total unexplained variance in the correlation matrix is 14 units.</p>
<p>&nbsp;</p>
<p>The &quot;Modeled&quot; column shows what this would have looked like if these data fit the model exactly.</p>
<p>&nbsp;</p>
<p>Conclusion: Though this contrast has the strength of 3 items, and so might be independently constructed from these data, its strength is so small that it is barely a ripple on the total measurement structure.</p>
<p>&nbsp;</p>
<p>Caution: The 1st contrast may be an extra dimension, or it may be a local change in the intensity of this dimension:</p>
<p>&nbsp;</p>
<p class="p_CourierReg8"><span class="f_CourierReg8">Table&nbsp;of&nbsp;STANDARDIZED&nbsp;RESIDUAL&nbsp;variance&nbsp;(in&nbsp;Eigenvalue&nbsp;units)</span></p>
<p class="p_CourierReg8"><span class="f_CourierReg8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Empirical&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Modeled</span></p>
<p class="p_CourierReg8"><span class="f_CourierReg8">Total&nbsp;variance&nbsp;in&nbsp;observations&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;97.1&nbsp;100.0%&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;100.0%</span></p>
<p class="p_CourierReg8"><span class="f_CourierReg8">Variance&nbsp;explained&nbsp;by&nbsp;measures&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;58.1&nbsp;&nbsp;59.8%&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;59.0%</span></p>
<p class="p_CourierReg8"><span class="f_CourierReg8">Unexplained&nbsp;variance&nbsp;(total)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;39.0&nbsp;&nbsp;40.2%&nbsp;100.0%&nbsp;&nbsp;&nbsp;41.0%</span></p>
<p class="p_CourierReg8"><span class="f_CourierReg8">Unexpl&nbsp;var&nbsp;explained&nbsp;by&nbsp;1st&nbsp;contrast&nbsp;=&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2.8&nbsp;&nbsp;&nbsp;2.9%&nbsp;&nbsp;&nbsp;7.2%</span></p>
<p>&nbsp;</p>
<p class="p_CourierReg8"><span class="f_CourierReg8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-3&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-2&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-1&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;3</span></p>
<p class="p_CourierReg8"><span class="f_CourierReg8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;++----------+----------+----------+----------+----------+----------++&nbsp;COUNT</span></p>
<p class="p_CourierReg8"><span class="f_CourierReg8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;A&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;1</span></p>
<p class="p_CourierReg8"><span class="f_CourierReg8">&nbsp;&nbsp;&nbsp;.7&nbsp;+&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;+</span></p>
<p class="p_CourierReg8"><span class="f_CourierReg8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;B&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;C&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;2</span></p>
<p class="p_CourierReg8"><span class="f_CourierReg8">F&nbsp;&nbsp;.6&nbsp;+&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;+</span></p>
<p class="p_CourierReg8"><span class="f_CourierReg8">A&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;D&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;1</span></p>
<p class="p_CourierReg8"><span class="f_CourierReg8">C&nbsp;&nbsp;.5&nbsp;+&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;E&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;+&nbsp;1</span></p>
<p class="p_CourierReg8"><span class="f_CourierReg8">T&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|</span></p>
<p class="p_CourierReg8"><span class="f_CourierReg8">O&nbsp;&nbsp;.4&nbsp;+&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;+</span></p>
<p class="p_CourierReg8"><span class="f_CourierReg8">R&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|</span></p>
<p class="p_CourierReg8"><span class="f_CourierReg8">&nbsp;&nbsp;&nbsp;.3&nbsp;+&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;+</span></p>
<p class="p_CourierReg8"><span class="f_CourierReg8">1&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;F&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;1</span></p>
<p class="p_CourierReg8"><span class="f_CourierReg8">&nbsp;&nbsp;&nbsp;.2&nbsp;+&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;+</span></p>
<p class="p_CourierReg8"><span class="f_CourierReg8">L&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;G&nbsp;&nbsp;&nbsp;|&nbsp;1</span></p>
<p class="p_CourierReg8"><span class="f_CourierReg8">O&nbsp;&nbsp;.1&nbsp;+&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;H&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;+&nbsp;1</span></p>
<p class="p_CourierReg8"><span class="f_CourierReg8">A&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;L&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;I&nbsp;|&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;J&nbsp;&nbsp;K&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;4</span></p>
<p class="p_CourierReg8"><span class="f_CourierReg8">D&nbsp;&nbsp;.0&nbsp;+----------M-----------------N----|-O-------------------------------+&nbsp;3</span></p>
<p class="p_CourierReg8"><span class="f_CourierReg8">I&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;T&nbsp;S&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;QR&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;P&nbsp;&nbsp;&nbsp;&nbsp;s&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;6</span></p>
<p class="p_CourierReg8"><span class="f_CourierReg8">N&nbsp;-.1&nbsp;+&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;p&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;o|&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;q&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;r&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;+&nbsp;4</span></p>
<p class="p_CourierReg8"><span class="f_CourierReg8">G&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;l&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;m&nbsp;&nbsp;&nbsp;&nbsp;n&nbsp;k&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;4</span></p>
<p class="p_CourierReg8"><span class="f_CourierReg8">&nbsp;&nbsp;-.2&nbsp;+&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;i&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;g&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;jh&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;+&nbsp;4</span></p>
<p class="p_CourierReg8"><span class="f_CourierReg8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;f&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;c&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;e&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|b&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;d&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;5</span></p>
<p class="p_CourierReg8"><span class="f_CourierReg8">&nbsp;&nbsp;-.3&nbsp;+&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;+</span></p>
<p class="p_CourierReg8"><span class="f_CourierReg8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;a&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;1</span></p>
<p class="p_CourierReg8"><span class="f_CourierReg8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;++----------+----------+----------+----------+----------+----------++</span></p>
<p class="p_CourierReg8"><span class="f_CourierReg8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-3&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-2&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-1&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;3</span></p>
<p class="p_CourierReg8"><span class="f_CourierReg8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Item&nbsp;MEASURE</span></p>
<p class="p_CourierReg8"><span class="f_CourierReg8">&nbsp;</span></p>
<p class="p_CourierReg8"><span class="f_CourierReg8">+-----------------------------------------</span></p>
<p class="p_CourierReg8"><span class="f_CourierReg8">|CON-&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;INFIT&nbsp;OUTFIT|&nbsp;ENTRY</span></p>
<p class="p_CourierReg8"><span class="f_CourierReg8">|&nbsp;TRAST|LOADING|MEASURE&nbsp;&nbsp;MNSQ&nbsp;MNSQ&nbsp;|NUMBER</span></p>
<p class="p_CourierReg8"><span class="f_CourierReg8">|------+-------+-------------------+------</span></p>
<p class="p_CourierReg8"><span class="f_CourierReg8">|&nbsp;&nbsp;1&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;.74&nbsp;|&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;.71&nbsp;&nbsp;.78&nbsp;&nbsp;.70&nbsp;|A&nbsp;&nbsp;&nbsp;26</span></p>
<p class="p_CourierReg8"><span class="f_CourierReg8">|&nbsp;&nbsp;1&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;.65&nbsp;|&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;.26&nbsp;&nbsp;.79&nbsp;&nbsp;.68&nbsp;|B&nbsp;&nbsp;&nbsp;23</span></p>
<p class="p_CourierReg8"><span class="f_CourierReg8">|&nbsp;&nbsp;1&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;.64&nbsp;|&nbsp;&nbsp;&nbsp;&nbsp;1.34&nbsp;&nbsp;.87&nbsp;&nbsp;.84&nbsp;|C&nbsp;&nbsp;&nbsp;25</span></p>
<p class="p_CourierReg8"><span class="f_CourierReg8">|&nbsp;&nbsp;1&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;.56&nbsp;|&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;.64&nbsp;&nbsp;.85&nbsp;&nbsp;.80&nbsp;|D&nbsp;&nbsp;&nbsp;24</span></p>
<p class="p_CourierReg8"><span class="f_CourierReg8">|&nbsp;&nbsp;1&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;.51&nbsp;|&nbsp;&nbsp;&nbsp;&nbsp;-.85&nbsp;&nbsp;.84&nbsp;&nbsp;.60&nbsp;|E&nbsp;&nbsp;&nbsp;22</span></p>
<p>&nbsp;</p>
<p>The first contrast comprises items A-E. But their mean-squares are all less than 1.0, indicating they do not contradict the Rasch variable, but are rather too predictable. They appear to represent a local intensification of the Rasch dimension, rather than a contradictory dimension.</p>
<p>&nbsp;</p>
<p><span style="font-weight: bold;">Comparison with Rasch-fitting data</span></p>
<p>Winsteps makes it easy to compare empirical PCA results with the results for an equivalent Rasch-fitting data set. </p>
<p>From the Output Files menu, make a &quot;Simulated Data&quot; file, call it, say, test.txt</p>
<p>From the Files menu, Restart Winsteps. Under &quot;Extra specifications&quot;, type in &quot;data=test.txt&quot;.</p>
<p>Exactly the same analysis is performed, but with Rasch-fitting data. Look at the Dimensionality table:</p>
<p>&nbsp;</p>
<p class="p_CourierReg8"><span class="f_CourierReg8">Table&nbsp;of&nbsp;STANDARDIZED&nbsp;RESIDUAL&nbsp;variance&nbsp;(in&nbsp;Eigenvalue&nbsp;units)</span></p>
<p class="p_CourierReg8"><span class="f_CourierReg8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Empirical&nbsp;&nbsp;&nbsp;&nbsp;Modeled</span></p>
<p class="p_CourierReg8"><span class="f_CourierReg8">Total&nbsp;variance&nbsp;in&nbsp;observations&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;576.8&nbsp;&nbsp;100.0%&nbsp;&nbsp;100.0%</span></p>
<p class="p_CourierReg8"><span class="f_CourierReg8">Variance&nbsp;explained&nbsp;by&nbsp;measures&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;562.8&nbsp;&nbsp;&nbsp;97.6%&nbsp;&nbsp;&nbsp;97.1%</span></p>
<p class="p_CourierReg8"><span class="f_CourierReg8">Unexplained&nbsp;variance&nbsp;(total)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;14.0&nbsp;&nbsp;&nbsp;&nbsp;2.4%&nbsp;&nbsp;&nbsp;&nbsp;2.9%</span></p>
<p class="p_CourierReg8"><span class="f_CourierReg8">Unexpl&nbsp;var&nbsp;explained&nbsp;by&nbsp;1st&nbsp;contrast&nbsp;=&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2.2&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;.4%</span></p>
<p>&nbsp;</p>
<p>Repeat this process several times, simulating a new dataset each time. If they all look like this, we can conclude that the value of 2.7 for the 1st contrast in the residuals is negligibly bigger than the 2.2 expected by chance.</p>
<p>&nbsp;</p>
<p>General Advice</p>
<p>A question here is &quot;how big is big&quot;? Much depends on what you are looking for. If you expect your instrument to have a wide spread of items and a wide spread of persons, then your measures should explain most of the variance. But if your items are of almost equal difficulty (as recommended, for instance, by G-Theory) and your persons are of similar ability (e.g., hospital nurses at the end of their training) then the measures will only explain a small amount of the variance.</p>
<p>&nbsp;</p>
<p>Ben Wright recommends that the analyst split the test into two halves, assigning the items, top vs. bottom of the first component in the residuals. Measure the persons on both halves of the test. Cross-plot the person measures. If the plot would lead you to different conclusions about the persons depending on test half, then there is a multidimensionality. If the plot is just a fuzzy straight line, then there is one, perhaps somewhat vague, dimension.</p>
<p>&nbsp;</p>
<p>Tentative guidelines:</p>
<p>&quot;Reliability&quot; (= Reproducibility) is &quot;True&quot; variance divided by Observed variance. If an acceptable, &quot;test reliability&quot; (i.e., reproducibility of this sample of person measures on these items) is 0.8, then an acceptable Rasch &quot;data reliability&quot; is also 0.8, i.e., &quot;variance explained by measures&quot; is 4 times &quot;total unexplained variance&quot;.</p>
<p>&nbsp;</p>
<p>In the unexplained variance, a &quot;secondary dimension&quot; must have the strength of at least 3 items, so if the first contrast has &quot;units&quot; (i.e., eigenvalue) less than 3 (for a reasonable length test) then the test is probably unidimensional. (Of course, individual items can still misfit).</p>
<p>&nbsp;</p>
<p>Negative variance can occur when the unexpectedness in the data is not random. An example is people who flatline an attitude survey. Their unexpected responses are always biased towards one category of the rating (or partial credit) scale.</p>
<p>&nbsp;</p>
<p>Simulation studies indicate that eigenvalues less than 1.4 are at the random level. Smith RM, Miao CY (1994) Assessing unidimensionality for Rasch measurement. Chapter 18 in M. Wilson (Ed.) Objective Measurement: Theory into Practice. Vol. 2. Norwood NJ: Ablex.) On occasion, values as high as 2.0 are at the random level. (Critical Eigenvalue Sizes in Standardized Residual Principal Components Analysis, Ra&icirc;che G., Rasch Measurement Transactions, 2005, 19:1 p. 1012.)</p>
<p>&nbsp;</p>
<hr noshade size=1 style="color : #000000"><p>&nbsp;</p>
<p><span style="font-weight: bold;">To compute these numbers yourself ...</span></p>
<p>&nbsp;</p>
<p class="p_Ind0Hang020MSReg10ShiftF4"><span class="f_Ind0Hang020MSReg10ShiftF4">Let's assume we have a complete dichotomous dataset of N persons and L items. Then, in summary,</span></p>
<p class="p_Ind0Hang020MSReg10ShiftF4"><span class="f_Ind0Hang020MSReg10ShiftF4">&nbsp;</span></p>
<p class="p_Ind0Hang020MSReg10ShiftF4"><span class="f_Ind0Hang020MSReg10ShiftF4">1. Do the Rasch analysis. Write out the raw observations, the raw residuals, and the standardized residuals</span></p>
<p class="p_Ind0Hang020MSReg10ShiftF4"><span class="f_Ind0Hang020MSReg10ShiftF4">2. Compute the observed variance of the raw observations = OV = 100% of the variance in the data</span></p>
<p class="p_Ind0Hang020MSReg10ShiftF4"><span class="f_Ind0Hang020MSReg10ShiftF4">3. Compute the unexplained variance = mean-square (raw residuals) = UV = Unexplained %</span></p>
<p class="p_Ind0Hang020MSReg10ShiftF4"><span class="f_Ind0Hang020MSReg10ShiftF4">4. Compute the explained variance in the raw observations = OV-UV = EV = Explained % (can go negative!)</span></p>
<p class="p_Ind0Hang020MSReg10ShiftF4"><span class="f_Ind0Hang020MSReg10ShiftF4">5. The eigenvalue of the item inter-correlation matrix of the standardized residuals = L = UV (rescaled) = Unexplained %</span></p>
<p class="p_Ind0Hang020MSReg10ShiftF4"><span class="f_Ind0Hang020MSReg10ShiftF4">6. In the decomposition of the correlation matrix: Eigenvalue of the component (factor) = G = &quot;strength in item units&quot; = Unexplained% * G / L</span></p>
<p class="p_Ind0Hang020MSReg10ShiftF4"><span class="f_Ind0Hang020MSReg10ShiftF4">&nbsp;</span></p>
<p>For the plots, the item difficulties are the x-axis, and the component loadings as the y-axis. This is a reminder that the Rasch dimension is the implicit first dimension in the original observations.</p>
<p>&nbsp;</p>
<p>You will notice that some of this is statistically approximate, but more exact statistics have produced less meaningful findings. Together with Albert Einstein, trust the meaning more than the numbers!</p>
 
</div>



</body>
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-83731338-2"></script><script>  window.dataLayer = window.dataLayer || [];  function gtag(){dataLayer.push(arguments);}  gtag('js', new Date());  gtag('config', 'UA-83731338-2');</script></html>
